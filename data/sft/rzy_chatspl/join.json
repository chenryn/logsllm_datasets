{"input": "按每5分钟分桶统计epay_耗时峰值趋势图", "instruction": "支付聚合_epay数据，编写查询语句实现如下分析场景", "output": "tag:epay epay.action:应答 epay.response.externalRefNumber:* \n|eval id=epay.response.externalRefNumber |eval response_time = timestamp\n|table id,response_time\n|join type=left id\n[[tag:epay epay.action:请求 \n|eval id=epay.request.externalRefNumber |eval request_time = timestamp\n|table request_time,id ]] |eval duration = response_time-request_time |bucket request_time span=5m as ts |stats max(duration) as duration by ts "}
{"input": "", "instruction": "改名的可执行文件", "output": "event_simpleName:\"NewExecutableRenamed\"| rename TargetFileName as \"ImageFileName\" | join ImageFileName [[ event_simpleName:\"ProcessRollup2\" ]] | table ComputerName SourceFileName ImageFileName CommandLine"}
{"input": "", "instruction": "LOL(Living-Off-the-Land) Binaries with Network", "output": "event_simpleName:\"DnsRequest\" | rename ContextProcessId as \"TargetProcessId\" | join TargetProcess [[ event_simpleName:\"ProcessRollup2\" FileName:'Atbroker.exe,Bash.exe,Bitsadmin.exe,Certutil.exe,Cmd.exe,Cmstp.exe,Control.exe,Cscript.exe,Csc.exe,Dfsvc.exe,Diskshadow.exe,Dnscmd.exe,Esentutl.exe,Eventvwr.exe,Expand.exe,Extexport.exe,Extrac32.exe,Findstr.exe,Forfiles.exe,Ftp.exe,Gpscript.exe,Hh.exe,Ie4uinit.exe,Ieexec.exe,Infdefaultinstall.exe,Installutil.exe,Jsc.exe,Makecab.exe,Mavinject.exe,Mmc.exe,Msconfig.exe,Msdt.exe,Mshta.exe,Msiexec.exe,Odbcconf.exe,Pcalua.exe,Pcwrun.exe,Presentationhost.exe,Print.exe,Regasm.exe,Regedit.exe,Register-cimprovider.exe,Regsvcs.exe,Regsvr32.exe,Reg.exe,Replace.exe,Rpcping.exe,Rundll32.exe,Runonce.exe,Runscripthelper.exe,Schtasks.exe,Scriptrunner.exe,Sc.exe,SyncAppvPublishingServer.exe,Verclsid.exe,Wab.exe,Wmic.exe,Wscript.exe,Wsreset.exe,Xwizard.exe' ]]"}
{"input": "", "instruction": "Static Behavior Model", "output": "event_simpleName:ProcessRollup2 | join aid,TargetProcessId_decimal [[ DetectName:SuspiciousFileWindows ]]| eval ProcessStartTime=ProcessStartTime_decimal| eval ProcessStartTime=formatdate(ProcessStartTime,\"MM/dd/yyyy HH:mm:ss\")| table ProcessStartTime aid ComputerName UserName ImageFileName OriginalFilename SHA256HashData ParentBaseFileName"}
{"input": "跟踪树--流程拓扑", "instruction": "业务链分析-数据，编写查询语句实现如下分析场景", "output": "|inputlookup tracing.csv | eval duration=tolong(elapsedTime) | sort by +startTime,-duration | fields startTime,serviceName,pid,id,indicators_n,duration | eval indicators_from =  indicators_n | eval connectid = id | join type = left connectid[[|inputlookup tracing.csv | eval connectid = pid | eval indicators_to = indicators_n | fields connectid,indicators_to]]|eval group =\"xxxxx\"|where !empty(indicators_to)"}
{"input": "epay_交易明细查询", "instruction": "支付聚合_epay数据，编写查询语句实现如下分析场景", "output": "tag:epay epay.action:请求|eval requesttime=timestamp|eval id=epay.request.externalRefNumber|table id,epay.request.cardHolderName,epay.trans_code,requesttime|join type=left id[[tag:epay epay.action:应答|eval id=epay.response.externalRefNumber|eval responsetime=timestamp|table id,responsetime,epay.response.responseTextMessage]]|eval requesttime=formatdate(requesttime)|eval responsetime=formatdate(responsetime)|rename id as \"交易ID\",epay.request.cardHolderName as \"姓名\",epay.trans_code as \"渠道\",requesttime as \"请求\",responsetime as \"响应\",epay.response.responseTextMessage as \"交易结果\""}
{"input": "最新 1 条网络接口实时状态", "instruction": "网关_koal_ssl数据，编写查询语句实现如下分析场景", "output": "tag:koal_ssl IF\\-MIB ifDescr |table ssl.ifindex,ssl.oidvalue |rename ssl.oidvalue as \"接口名称\"\n|join  type=left ssl.ifindex\n[[tag:koal_ssl IF\\-MIB ifAdminStatus  |table ssl.ifindex,ssl.oidvalue |rename ssl.oidvalue as \"Admin状态\"]]|join  type=left ssl.ifindex\n[[tag:koal_ssl IF\\-MIB ifOperStatus  |table ssl.ifindex,ssl.oidvalue |rename ssl.oidvalue as \"Oper状态\"]] |limit 1"}
{"input": "告警趋势对比", "instruction": "综合态势感知数据，编写查询语句实现如下分析场景", "output": "_index:monitor * NOT issue_alert:false|stats sparkline(count(), 10m) as a by alert_level|rename a as \"今天告警趋势\"|join type=left alert_level [[starttime=\"-1d/d\" endtime=\"now/d\" _index:monitor * NOT issue_alert:false|stats sparkline(count(), 10m) as a by alert_level|rename a as \"昨天告警趋势\"]]"}
{"input": "告警趋势昨天和今天的对比", "instruction": "日志易告警监控数据，编写查询语句实现如下分析场景", "output": "_index:monitor * NOT issue_alert:false|stats sparkline(count(), 10m) as a by alert_level|rename a as \"今天告警趋势\"|join type=left alert_level [[starttime=\"-1d/d\" endtime=\"now/d\" _index:monitor * NOT issue_alert:false|stats sparkline(count(), 10m) as a by alert_level|rename a as \"昨天告警趋势\"]]"}
{"input": "新HAC-工单申请资源数量", "instruction": "新HAC堡垒机审计数据，编写查询语句实现如下分析场景", "output": "tag:hac \"申请\" NOT hac.det.det1.worknoteName:\"值班\"\n|stats count() by hac.applyer,hac.worknote,hac.worknotedetail.worknotename,hac.worknotedetail.apply_count\n|join type=left hac.worknote [[\n\ttag:hac \"审批\" NOT hac.det.det1.worknoteName:\"值班\"\n\t|stats count() by hac.worknotedetail.approver,hac.worknote\n]]\n|fields hac.applyer,hac.worknotedetail.approver,hac.worknote,hac.worknotedetail.worknotename,hac.worknotedetail.apply_count\n|rename hac.applyer as \"申请人\",hac.worknotedetail.approver as \"审批人\",hac.worknote as \"工单号\",hac.worknotedetail.worknotename as \"工单名称\",hac.worknotedetail.apply_count as \"申请资源数量\""}
{"input": "", "instruction": "查找最近一周内登录失败次数超过 10 次的用户，并关联他们的 IP 地址和地理位置", "output": " starttime=\"now-7d\" _index:auth| search action:failure | stats count() as cnt by user | where cnt > 10 | join user [[ starttime=\"now-7d\" _index:auth | stats values(src_ip) by user | iplocation src_ip]]"}
{"input": "", "instruction": "查找最近一周内访问量最高的 10 个网页，并按照客户端类型进行分类", "output": " starttime=\"now-7d\" _index:web | stats count() by uri | head 10 | join uri [[ starttime=\"now-7d\" _index:web | stats count() by uri, client_type]]"}
{"input": "统计每个 IP 在一个小时前到十分钟前的日志量，通过 IP 地址管理到各机器十分钟到当前的日志量，如果最近十分钟的日志量为 0，过滤出来，并拼一个描述，内容是 ip 地址后面跟上\"最近10分钟日志量为0，heka可能存在积压现象，请关注排查。\"。最后把各字段重命名为服务器 ip、最近 1 小时日志量、最近 10 分钟日志量、描述。", "instruction": "日志堆积在Agent端情况", "output": "starttime=\"-1h/h\" endtime=\"-10m/m\" *  |stats count() as cnt1 by ip  |join type=left ip [[  starttime=\"-10m/m\" endtime=\"now\" *  |stats count() as cnt2 by ip ]] |where empty(cnt2) |eval desc = ip + \"最近10分钟日志量为0，heka可能存在积压现象，请关注排查。\" |rename ip as \"服务器IP\",cnt1 as \"最近1小时日志量\",cnt2 as \"最近10分钟日志量\",desc as \"描述\""}
{"input": "总体健康度", "instruction": "综合态势感知数据，编写查询语句实现如下分析场景", "output": "_index:monitor  issue_alert:true alert_level:high|stats count() as cnt_high|eval a=1|join type=left a [[_index:monitor issue_alert:true alert_level:mid|stats count() as cnt_mid|eval a=1]] | join type=left a [[_index:monitor issue_alert:true alert_level:low|stats count() as cnt_low|eval a=1]]|eval health=abs(100-1*cnt_high-0.1*cnt_mid-0.01*cnt_low)/100"}
{"input": "日志易Agent断采监控。统计前两个小时的 IP，和近一个小时的 IP 关联，过滤两小时前有而一小时内没有的 IP", "instruction": "日志易agent监控数据，编写查询语句实现如下分析场景", "output": "starttime=\"-2h/h\" endtime=\"now/h\" source:*|stats count() as count_1 by ip | join type=left ip [[starttime=\"-1h/h\" endtime=\"now/h\" source:*|stats count() as count_2 by ip]] | where empty(count_2)"}
{"input": "系统健康度", "instruction": "日志易告警监控数据，编写查询语句实现如下分析场景", "output": "_index:monitor * NOT issue_alert:false alert_level:high|stats count() as cnt_high|eval a=1|join type=left a [[_index:monitor * NOT issue_alert:false alert_level:mid|stats count() as cnt_mid|eval a=1]] | join type=left a [[_index:monitor * NOT issue_alert:false alert_level:low|stats count() as cnt_low|eval a=1]]|eval health=abs(100-1*cnt_high-0.1*cnt_mid-0.01*cnt_low)/100"}
{"input": "实时交易指标分析", "instruction": "支付聚合_epay数据，编写查询语句实现如下分析场景", "output": "tag:epay epay.action:应答 epay.response.responseTextMessage:*|eval result=case( epay.response.responseTextMessage==\"交易成功\",\"成功\",default,\"异常\" ) |stats count(*) as sucess by result,tag|join type=left tag[[tag:epay epay.action:应答 epay.response.responseTextMessage:*|stats count(*) as total by tag ]]|eval rate=format(\"%.2f\",todouble(sucess/total))|where result==\"成功\" |table tag,sucess,total,rate|rename tag as \"系统\",sucess as \"成功交易数\",total as \"交易总数\",rate as \"交易成功率\""}
{"input": "epay_耗时大于3s的交易分布", "instruction": "支付聚合_epay数据，编写查询语句实现如下分析场景", "output": "tag:epay epay.action:应答 epay.response.externalRefNumber:* \n|eval id=epay.response.externalRefNumber |eval response_time = timestamp\n|table id,response_time,epay.response.storablePan,epay.response.terminalId,epay.response.responseTextMessage\n|join type=left id\n[[tag:epay epay.action:请求 \n|eval id=epay.request.externalRefNumber |eval request_time = timestamp\n|table request_time,id,epay.request.cardHolderName,epay.request.customerId ]] |eval duration = response_time-request_time \n|where duration > 3000 \n|stats count() as tally by epay.response.responseTextMessage"}
{"input": "工单状态详情。统计方法如下：\n1. 首先查询tag为hac且不等于“值班”的工单,并统计count by 工单事由、工单名称、工单内容和申请人\n2. 然后使用match判断工单名称是否为2个或2个以上中文字符,如果是则status为“规范”,否则为“不规范”\n3. 再次按工单事由、工单名称、工单内容、申请人和status统计count,得到cnt\n4. left join查询tag为hac且不等于“值班”的工单,获取工单内容hac.worknote\n5. 最后对结果进行重命名,选取需要的字段,将cnt重命名为“统计”,hac.applyer重命名为“申请人”,hac.worknotedetail.approver重命名为“审批人”,hac.worknote重命名为“工单号”,status重命名为“工单状态”\n", "instruction": "新HAC堡垒机审计数据，编写查询语句实现如下分析场景", "output": "tag:hac hac.applyer:* NOT hac.worknotename:\"值班\"\n|stats count() by hac.worknotereason,hac.worknotename,hac.worknote,hac.applyer\n|eval status=match(hac.worknotename,\"^[\\\\u4e00-\\\\u9fa5]{2}\")\n|eval status=if(status==true, \"规范\", \"不规范\")\n|stats count() as cnt by hac.worknotereason,hac.worknotename,hac.worknote,hac.applyer,status\n|join type=left hac.worknote [[\n\ttag:hac NOT hac.worknotename:\"值班\" AND hac.worknotedetail.approver:*\n\t|eval hac.worknote=hac.worknote\n]]\n|fields hac.worknotename,hac.worknotereason,hac.worknote,status,hac.worknotedetail.approver,hac.applyer| rename hac.worknotename as \"工单名称\",cnt as \"统计\",hac.applyer as \"申请人\",hac.worknotedetail.approver as \"审批人\",hac.worknote as \"工单号\", status as \"工单状态\",hac.worknotereason as \"事由\""}
{"input": "新HAC-上班时间使用应用账号的情况，查询方法如下：1. 搜索tag为hac,class为SESSION_CMD,secondary_user不为vlog的事件。2. 按primary_user,devname,dst_ip,secondary_user,worknote分组,取每组的最新时间戳。3. 从worknote字段中提取名称为worknote的capture group。4. 将ts时间戳格式化为时间字符串time。5. 从time字符串中提取日期date和小时h_time的capture group。6. 将h_time转换为整数。7. 过滤工作时间外的数据,只保留工作时间内9点到17点的数据。8. 左连接worknote这张表。9. 过滤worknotename为空的行。10. 选择需要的最终输出字段，重命名为中文字段名", "instruction": "新HAC堡垒机审计数据，编写查询语句实现如下分析场景", "output": "tag:hac AND hac.det.class:SESSION_CMD NOT hac.det.secondary_user:vlog \n|stats latest(timestamp) as ts by hac.det.primary_user,hac.devname,hac.det.dst_ip,hac.det.secondary_user,hac.det.worknote \n|parse field=hac.det.worknote \"(?<worknote>.*)\\\"\" \n|eval time=formatdate(ts,\"yyyy-MM-dd HH:mm\") \n|parse field=time \"(?<date>[^\\s]+)\\s(?<h_time>\\d{2}):\\d{2}\" \n|eval h_time=tolong(h_time) \n|where h_time>=9 && h_time<17 \n|fields date,hac.det.primary_user,hac.det.dst_ip,hac.det.secondary_user,time,worknote \n|join type=left worknote [[tag:hac \"申请\" \n\t|stats count() by hac.worknote,hac.worknotereason,hac.worknotename \n\t|rename hac.worknote as worknote \n\t|join type=left worknote [[tag:hac \"审批\" \n\t\t|stats count() by hac.worknote,hac.worknotedetail.approver \n\t\t|rename hac.worknote as worknote]]]] \n|where !empty(hac.worknotename) \n|fields date,hac.worknotename,worknote,hac.worknotereason,hac.worknotedetail.approver,hac.det.primary_user,hac.det.dst_ip,hac.det.secondary_user,time \n| rename date as \"日期\",worknote as \"工单号\",hac.det.primary_user as \"访问人\",hac.devname as \"设备名\",hac.det.dst_ip as \"被访问ip\",hac.det.secondary_user as \"使用账号\",time as \"详细时间\",hac.worknotename as \"工单名\",hac.worknotereason as \"申请事由\",hac.worknotedetail.approver as \"审批人\""}
{"input": "新HAC-用户会话审计。查询方法如下：1. 查询tag为hac且class为SESSION_START的数据,并统计count(*)以及一些字段值。2. 然后左连接tag为hac且class为SESSION_END的数据,目的是获取SESSION_END事件的时长duration和结束时间end_time。如果没有SESSION_END事件,则duration设为当前时间减去SESSION_START的开始时间start_time。3. 接着计算status字段,如果有SESSION_END事件,则status为“操作已结束”,否则为“操作中”。4. 最后对一些字段重命名,选择感兴趣的字段展示。", "instruction": "新HAC堡垒机审计数据，编写查询语句实现如下分析场景", "output": "tag:hac hac.det.class:SESSION_START\n| stats count() by hac.det.primary_user,hac.det.session_id,hac.det.worknote,hac.det.start_time,hac.det.dst_ip,hac.det.protocol,hac.det.secondary_user,hac.det.SYSTEMSLIST,hac.det.src_ip\n|join type=left hac.det.session_id [[tag:hac hac.det.class:SESSION_END\n\t| eval start_time=parsedate(hac.det.start_time, \"yyyy-MM-dd HH:mm:ss\", \"UTC\"),end_time=parsedate(hac.det.end_time, \"yyyy-MM-dd HH:mm:ss\", \"UTC\"),duration=(end_time-start_time)/1000/60\n\t| stats count() by hac.det.session_id,duration,hac.det.start_time, hac.det.end_time]]\n|eval duration =if(!empty(duration),duration,format(\"%.2f\",(now()-parsedate(hac.det.start_time, \"yyyy-MM-dd HH:mm:ss\" ))/1000/60))\n|eval status=if(empty(hac.det.end_time),\"操作中\",\"操作已结束\")\n| fields hac.det.primary_user, hac.det.session_id,hac.det.worknote,duration,hac.det.start_time, hac.det.end_time,hac.det.dst_ip,hac.det.secondary_user,hac.det.SYSTEMSLIST,hac.det.src_ip,hac.det.protocol,status\n| rename hac.det.primary_user as \"操作人\", hac.det.session_id as \"会话ID\", hac.det.worknote as \"工单号\",duration as \"时长/min\", hac.det.start_time as \"开始时间\" ,hac.det.end_time as \"结束时间\",hac.det.protocol as \"使用协议\",hac.det.dst_ip as \"访问IP\",hac.det.secondary_user as \"使用账号\",hac.det.SYSTEMSLIST as \"系统名称\" ,hac.det.src_ip as \"登录终端\",status as \"状态\""}
{"input": "1. 从日志中提取交易编码为BUP03059的请求日志,取msgNa字段,如果为空则取msgtype字段的值,存储在msgNa字段 ；2. 取chnlNa字段,如果为空则取chnlcode字段的值,存储在chnlNa字段 ；3. 取sendBankNa字段,如果为空则取origsender字段的值,存储在sendBankNa字段 ；4. 统计每个交易请求的次数cnt,以及交易时间timestamp、交易编码msgNa、渠道编码chnlNa、发起方银行sendBankNa、交易IDmsgid和接收系统sysid ；5. 重命名timestamp为reqTime,表示交易请求时间 ；6. 左连接同一交易ID的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间,以及响应状态respstatus和响应编码respNa；7. 计算交易响应时间与请求时间的差cost,表示交易耗时 ；8. 格式化交易描述desc,包含渠道编码和响应信息 ；9. 重命名reqTime为time", "instruction": "在支付清算系统日志里关联贷记来账的请求和响应两条日志,计算交易耗时,实现监控系统交易执行情况的场景,最终输出每个交易的请求时间、响应时间、交易编码、发起方、接收方和交易描述。按照如下要求编写 SPL 语句分析 mps 日志", "output": "tranCode:BUP03059 msgid:${msgid}| eval msgNa=if(empty(msgNa),msgtype,msgNa)| eval chnlNa=if(empty(chnlNa),chnlcode,chnlNa)| eval sendBankNa=if(empty(sendBankNa),origsender,sendBankNa)| stats count() as cnt by timestamp,msgNa,chnlNa,sendBankNa,msgid,sysid| rename timestamp as reqTime| join type=left msgid [[ tranCode:BUP03059 origmsgid1:${msgid} | stats count() as cnt by timestamp,origmsgid,respstatus,respNa | rename timestamp as respTime,origmsgid as msgid]]| eval cost=respTime-reqTime| eval desc=format(\"%s::respstatus:%s_%s_%sms\",chnlNa,respstatus,respNa,cost)| rename reqTime as time,msgNa as tranCode,sendBankNa as send,sysid as recver| fields time,tranCode,send,recver,desc"}
{"input": "1. 从交易日志中提取异步交易请求日志,交易编码tranCode为BUP03059和交易子编码TC为100503s,取otpserialno、sysid、workseqid、交易编码TxCd和序列号seqNo字段 ；2. 重命名timestamp为reqTime,表示交易请求时间 ；3. 左连接同一序列号seqNo的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间,以及响应码rtncode和响应信息rtnmsg；4. 计算交易响应时间与请求时间的差cost,表示交易耗时 ；5. 格式化交易描述desc,包含交易序列号、工作序列号和响应信息 ；6. 重命名相关字段", "instruction": "根据如下要求编写 SPL 语句分析 mps 日志", "output": "tranCode:BUP03059 seqNo:${seqNo} TC:100503s otpserialno:* | stats count() as cnt by timestamp,otpserialno,sysid,workseqid,TxCd,seqNo | rename timestamp as reqTime | join type=left seqNo [[  tranCode:BUP03059 seqNo:${seqNo} TC:100503s rtncode:*  | stats count() as cnt by timestamp,seqNo,rtncode,rtnmsg  | rename timestamp as rspTime ]] | eval cost=rspTime-reqTime | eval recver=\"渠道\" | eval desc=format(\"otpserialno:%s:workseqid:%s::rtncode:%s_%s_%sms\",otpserialno,workseqid,rtncode,rtnmsg,cost) | rename reqTime as time,TxCd as tranCode,sysid as send | fields time,tranCode,send,recver,desc"}
{"input": "1. 从日志中提取交易请求日志,交易编码TC为PYS040,取otpserialno、TC、工作序列号workseqid、接收系统sysid和序列号seqNo ；2. 重命名timestamp为reqTime,表示交易请求时间 ；3. 左连接同一序列号seqNo的响应日志,统计响应时间timestamp并重命名为rspTime,表示交易响应时间,以及响应码rtncode、响应信息rtnmsg和错误信息errNa ；4. 计算交易响应时间与请求时间的差cost,表示交易耗时；5. 格式化交易描述desc,包含交易编码和响应信息；6. 重命名相关字段", "instruction": "根据如下要求编写 SPL 语句分析 mps 日志", "output": "tranCode:BUP03059 seqNo:${seqNo} TC:PYS040 otpserialno:* | stats count() as cnt by timestamp,otpserialno,TC,workseqid,sysid,seqNo | rename timestamp as reqTime | join type=left seqNo [[  tranCode:BUP03059 seqNo:${seqNo} TC:PYS040 rtncode:*  | stats count() as cnt by timestamp,rtncode,rtnmsg,errNa,TC,seqNo  | rename timestamp as rspTime ]] | eval cost=rspTime-reqTime | eval recver=\"核心\" | eval desc=format(\"otpserialno:%s_workseqid:%s::rtncode:%s_%s_%s_%sms\",otpserialno,workseqid,rtncode,rtnmsg,errNa,cost) | rename reqTime as time,TC as tranCode,sysid as send | fields time,tranCode,send,recver,desc"}
{"input": "跟踪树-链路梳理", "instruction": "业务链分析-数据，编写查询语句实现如下分析场景", "output": "|inputlookup tracing.csv | eval duration=tolong(elapsedTime) | sort by +startTime,-duration | fields startTime,serviceName,pid,id,indicators_n,duration | eval indicators_from =  indicators_n | eval connectid = id | join type = left connectid[[|inputlookup tracing.csv | eval connectid = pid | eval indicators_to = indicators_n | fields connectid,indicators_to]]|stats count() by  indicators_from,indicators_to"}
{"input": "", "instruction": "询问关于以下事件的相关信息：1. 有关计算机名为 `ComputerName`、用户名称为 `UserName` 和映像文件名为 `ImageFileName` 的进程的启动时间的信息；2. 有关与哈希数据（SHA-256）相匹配的文件的相关信息，包括父基本文件名和原始文件名等；3. 有关具有易于识别特征的可疑文件（例如 SuspiciousFileWindows）的信息。", "output": "event_simpleName:ProcessRollup2 | join aid,TargetProcessId_decimal [[ DetectName:SuspiciousFileWindows ]]| eval ProcessStartTime=ProcessStartTime_decimal| eval ProcessStartTime=formatdate(ProcessStartTime,\"MM/dd/yyyy HH:mm:ss\")| table ProcessStartTime aid ComputerName UserName ImageFileName OriginalFilename SHA256HashData ParentBaseFileName"}
{"input": "", "instruction": "我想问如何编写 日志易 查询语句以获取某些条件下的告警数量和严重程度的分布情况。这个查询首先从 `monitor` index 中检索所有满足 `issue_alert` 字段为 `true` 的文档，然后使用 `stats` 命令计算每个分级（`high`, `mid`，`low`）下的告警数量，并将其保存在相应的变量中。接着，通过 `eval` 命令对三个分量进行加权平均得到总体健康值，最后使用 `sort` 命令按倒序排列 `_count` 来显示结果。", "output": "_index:monitor  issue_alert:true alert_level:high|stats count() as cnt_high|eval a=1|join type=left a [[_index:monitor issue_alert:true alert_level:mid|stats count() as cnt_mid|eval a=1]] | join type=left a [[_index:monitor issue_alert:true alert_level:low|stats count() as cnt_low|eval a=1]]|eval health=abs(100-1*cnt_high-0.1*cnt_mid-0.01*cnt_low)/100"}
{"input": "", "instruction": "我想要知道某些指标从何时开始到何时结束的持续时间。请帮我找出这些信息。", "output": "|inputlookup tracing.csv | eval duration=tolong(elapsedTime) | sort by +startTime,-duration | fields startTime,serviceName,pid,id,indicators_n,duration | eval indicators_from =  indicators_n | eval connectid = id | join type = left connectid[[|inputlookup tracing.csv | eval connectid = pid | eval indicators_to = indicators_n | fields connectid,indicators_to]]|stats count() by  indicators_from,indicators_to"}
{"input": "", "instruction": "1. 找出过去一周内用户失败登录次数超过十次的用户；2. 根据这些用户的IP地址，通过GeoIP技术获取地理位置信息；3. 将上述结果与用户相关的其他数据进行关联和分析，例如用户注册时间、姓名等信息。", "output": " starttime=\"now-7d\" _index:auth| search action:failure | stats count() as cnt by user | where cnt > 10 | join user [[ starttime=\"now-7d\" _index:auth | stats values(src_ip) by user | iplocation src_ip]]"}
{"input": "", "instruction": "我想问如何编写 日志易 查询语句。根据这个答案，我可以理解出用户在询问他们最近一周内访问网站时，按总请求数从高到低排列前十个页面以及每个页面对应的浏览器类型信息。", "output": " starttime=\"now-7d\" _index:web | stats count() by uri | head 10 | join uri [[ starttime=\"now-7d\" _index:web | stats count() by uri, client_type]]"}
{"input": "", "instruction": "最近一小时的访问量为0的主机ip, 最近十分钟没有发送任何数据包的主机ip", "output": "starttime=\"-1h\" endtime=\"-10m/m\" *  |stats count() as cnt1 by ip  |join type=left ip [[  starttime=\"-10m/m\" endtime=\"now\" *  |stats count() as cnt2 by ip ]] |where empty(cnt2) |eval desc = ip + \"最近10分钟日志量为0，heka可能存在积压现象，请关注排查。\" |rename ip as \"服务器IP\",cnt1 as \"最近1小时日志量\",cnt2 as \"最近10分钟日志量\",desc as \"描述\""}
{"input": "", "instruction": "我想问的是，上一个小时内有没有访问过其他网站的用户呢？", "output": "starttime=\"-2h/h\" endtime=\"now/h\" source:*|stats count() as count_1 by ip | join type=left ip [[starttime=\"-1h/h\" endtime=\"now/h\" source:*|stats count() as count_2 by ip]] | where empty(count_2)"}
{"input": "最近5分钟的端口管理状态。索引可用字段有：switchperf.devip,switchperf.ifindex,switchperf.value,switchperf.type。请仅使用所需要的字段", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND switchperf.type:ifAdminStatus | stats count() by switchperf.ifindex,switchperf.value\n| join type=left switchperf.ifindex [[starttime=\"now-5m\" endtime=\"now\" appname:switchperf AND switchperf.type:ifDescr | stats count() by switchperf.ifindex,switchperf.value | rename switchperf.value as ifdescr]]  | fields ifdescr,switchperf.value| sort by +switchperf.value | rename  ifdescr as \"端口\",switchperf.value as \"管理状态\""}
{"input": "按每小时分桶统计all_table_虚拟机", "instruction": "VMware_Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:app2 source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:app2 source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f %%\",memory/json.memory.total.guest.bytes * 100) |eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:app2 source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by -time|where cpu_Mhz >0"}
{"input": "按每小时分桶统计all虚拟机cpu", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t | stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name|eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by +time|where cpu_Mhz >0| rename memory as \"已使用内存(Mb)\", storage as \"已使用磁盘(Gb)\""}
{"input": "按每小时分桶统计all虚拟机磁盘", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master  source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t | stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name|eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by +time|where cpu_Mhz >0| rename memory as \"已使用内存(Mb)\", storage as \"已使用磁盘(Gb)\""}
{"input": "按每小时分桶统计all_table_虚拟机", "instruction": "主中心Esxi监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_master  source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_master source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f %%\",memory/json.memory.total.guest.bytes * 100) |eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_master source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by -time|where cpu_Mhz >0"}
{"input": "按每小时分桶统计all虚拟机cpu", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_backup  source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t | stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name|eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_backup  source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by +time|where cpu_Mhz >0| rename memory as \"已使用内存(Mb)\", storage as \"已使用磁盘(Gb)\""}
{"input": "按每小时分桶统计all虚拟机磁盘", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup  source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_backup  source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t | stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name|eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_backup  source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by +time|where cpu_Mhz >0| rename memory as \"已使用内存(Mb)\", storage as \"已使用磁盘(Gb)\""}
{"input": "按每小时分桶统计all_table_虚拟机", "instruction": "Esxi性能监控数据，编写查询语句实现如下分析场景", "output": "appname:vsphere tag:dmz_backup  source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_backup source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f %%\",memory/json.memory.total.guest.bytes * 100) |eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_backup source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")\t| stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by -time|where cpu_Mhz >0"}
{"input": "当天新建且删除的帐户", "instruction": "Windows_AD数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" appname:windows   json.event_id:4720 NOT (json.username:*$ OR json.username:SYSTEM)\n|eval time1=formatdate(timestamp,\"MM-dd HH:mm\")\n|join json.username [[\n\tstarttime=\"now/d\"  appname:windows   json.event_id:4726 NOT (json.username:*$ OR json.username:SYSTEM)\n\t|eval time2=formatdate(timestamp,\"MM-dd HH:mm\")\n]]\n|eval desc=\"用户\"+json.username+\"在\"+time1+\"创建后，又在\"+time2+\"删除，属于异常行为\""}
{"input": "", "instruction": "数据库主机上个月的内存和SWAP使用率详细信息", "output": "starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats avg(json.Mem.used_percent) as avg_ by ip,hostname,json.os_type |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats max(json.Mem.used_percent) as max_ by ip,hostname,json.os_type ]] |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats avg(json.Swap.used_percent) as savg_ by ip,hostname,json.os_type ]] |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats max(json.Swap.used_percent) as smax_ by ip,hostname,json.os_type ]] |eval avg_=format(\"%.2f%%\",avg_) |eval max_=format(\"%.2f%%\",max_) |eval savg_=format(\"%.2f%%\",savg_) |eval smax_=format(\"%.2f%%\",smax_) |sort by + ip "}
{"input": "", "instruction": "数据库主机CPU使用率上个月的详细信息", "output": "starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |eval per=(100-json.cpu.idle_percent)/100 |stats avg(per) as avg_ by ip,hostname,json.os_type |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * | eval per=(100-json.cpu.idle_percent)/100 |stats max(per) as max_ by  ip,hostname,json.os_type ]] |eval avg_=format(\"%.2f%%\",avg_) |eval max_=format(\"%.2f%%\",max_) |sort by + ip "}
{"input": "从 monitor 索引中搜索 issue_alert不为 false 的数据，然后过滤 run_timestamp 字段值在当前时刻往前 600001 毫秒之内，保留timestamp、alert_name、 alert_level和 alert_id 字段，并根据 alert_level 英文值转换为中文低中高。然后通过 alert_id 字段左关联 appname 为 alertoperation 的数据，如果 action 为空，视作未处理，否则是已处理。", "instruction": "日志易告警监控-查询分析实现如下场景", "output": "_index:monitor * NOT issue_alert:false  alert_level:* | where run_timestamp > now() - 600001 |table timestamp,alert_name, alert_level, alert_id|eval level=case(alert_level==\"high\",\"高\", alert_level==\"mid\",\"中\",default,\"低\")|join type=left alert_id [[appname:alertoperation |table json.alert_id|rename json.alert_id as alert_id]] |eval action=if(empty(alert_id),\"未处理\",\"已处理\")"}
{"input": "按每5分钟分桶统计主机内存健康度", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats  \n| stats count() as _ct by ip\n| stats count(ip) as _sum \n| eval a=1 \n| join type=left a \n[[ appname:top_info_win_system_stats \n| bucket timestamp span=5m as ts\n| stats avg(json.Mem.used_percent) as _avg by ip,hostname \n| where _avg >= 80 \n| stats dc(ip) as _bad \n| eval a=1\n]]\n| eval health=abs(_sum-_bad)/_sum\n"}
{"input": "按每5分钟分桶统计主机CPU健康度", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats \n|stats count() as ct by ip\n|stats count(ip) as _sum\n|eval a=1\n|join type=left a \n[[ appname:top_info_win_system_stats \n| bucket timestamp span=5m as ts\n| stats avg(json.cpu.idle_percent) as _avg by ts,ip,hostname\n| where _avg <=20\n| stats dc(ip) as _bad \n|eval a=1\n]]\n|eval health=abs(_sum-_bad)/_sum"}
{"input": "疑似暴力破解成功", "instruction": "Windows_AD数据，编写查询语句实现如下分析场景", "output": "appname:windows   json.event_id:4625 NOT (json.username:*$ OR json.username:SYSTEM)\n|stats count() as cnt by ip,json.username\n|where cnt >2\n|join json.username [[appname:windows   json.event_id:4624 NOT (json.username:*$ OR json.username:SYSTEM)\n\t|stats count() as cnt1 by ip,json.username]]\n|eval desc=\"用户\"+json.username+\"在\"+ip+\"上多次登录失败后，成功登录，疑似暴力破解成功\"\n"}
{"input": "与1小时前相比新增进程", "instruction": "linux性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1h by json.cmdline |join type=left json.cmdline [[starttime=\"-2h\" endtime=\"-1h\" appname:top_info_proc_stats |stats count() as cnt_1d by json.cmdline]] |where empty(cnt_1d)|fields json.cmdline |rename json.cmdline as \"新增进程名\""}
{"input": "与1小时前相比减少进程", "instruction": "linux性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-2h\" endtime=\"-1h\" appname:top_info_proc_stats |stats count() as cnt_1h by json.cmdline |join type=left json.cmdline [[starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1d by json.cmdline]] |where empty(cnt_1d)|fields json.cmdline |rename json.cmdline as \"减少进程名\""}
{"input": "与1天前相比新增进程", "instruction": "linux性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1h by json.cmdline |join type=left json.cmdline [[starttime=\"-1h-1d\" endtime=\"-1h\" appname:top_info_proc_stats |stats count() as cnt_1d by json.cmdline]] |where empty(cnt_1d)|fields json.cmdline |rename json.cmdline as \"新增进程名\""}
{"input": "与1天前相比减少进程", "instruction": "linux性能数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1h-1d\" endtime=\"-1h\" appname:top_info_proc_stats |stats count() as cnt_1h by json.cmdline |join type=left json.cmdline [[starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1d by json.cmdline]] |where empty(cnt_1d)|fields json.cmdline |rename json.cmdline as \"减少进程名\""}
{"input": "", "instruction": "我想问的是，最近一分钟内有没有告警信息被标记为“未处理”的情况吗？如果有的话，可以把它们列出来吗？", "output": "_index:monitor * NOT issue_alert:false  alert_level:* | where run_timestamp > now() - 600001 |table timestamp,alert_name, alert_level, alert_id|eval level=case(alert_level==\"high\",\"高\", alert_level==\"mid\",\"中\",default,\"低\")|join type=left alert_id [[appname:alertoperation |table json.alert_id|rename json.alert_id as alert_id]] |eval action=if(empty(alert_id),\"未处理\",\"已处理\")"}
{"input": "", "instruction": "我的问题可能涉及到 Windows 系统的安全事件监控和分析，具体来说，寻找某些特定应用（appname：windows）在特定的时间范围内（starttime=\"now/d\"）生成的安全事件（event_id = 4720）中发生的异常情况，其中不包括具有特殊字符（*$）或系统用户名（SYSTEM）的用户帐户。此外，该查询还使用 join 命令将另一个类似的查询结果与当前查询进行匹配，以确定是否存在与期望的异常相对应的用户帐号名称和时间戳。", "output": "starttime=\"now/d\" appname:windows   json.event_id:4720 NOT (json.username:*$ OR json.username:SYSTEM)|eval time1=formatdate(timestamp,\"MM-dd HH:mm\")|join json.username [[ starttime=\"now/d\"  appname:windows   json.event_id:4726 NOT (json.username:*$ OR json.username:SYSTEM) |eval time2=formatdate(timestamp,\"MM-dd HH:mm\")]]|eval desc=\"用户\"+json.username+\"在\"+time1+\"创建后，又在\"+time2+\"删除，属于异常行为\""}
{"input": "", "instruction": "检索最近一个月内的系统统计信息和内存、交换空间使用率最高的主机的信息。", "output": "starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats avg(json.Mem.used_percent) as avg_ by ip,hostname,json.os_type |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats max(json.Mem.used_percent) as max_ by ip,hostname,json.os_type ]] |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats avg(json.Swap.used_percent) as savg_ by ip,hostname,json.os_type ]] |join type=left hostname [[ starttime=\"-1M/M\" endtime=\"now/M\" appname:top_info_system_stats tag:top_info AND * |stats max(json.Swap.used_percent) as smax_ by ip,hostname,json.os_type ]] |eval avg_=format(\"%.2f%%\",avg_) |eval max_=format(\"%.2f%%\",max_) |eval savg_=format(\"%.2f%%\",savg_) |eval smax_=format(\"%.2f%%\",smax_) |sort by + ip "}
{"input": "", "instruction": "我想问如何编写一个日志易查询语句，以获取过去一小时和过去一天内启动的应用中排名前十的 CPU 使用率最高的进程名称。", "output": "starttime=\"-2h\" endtime=\"-1h\" appname:top_info_proc_stats |stats count() as cnt_1h by json.cmdline |join type=left json.cmdline [[starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1d by json.cmdline]] |where empty(cnt_1d)|fields json.cmdline |rename json.cmdline as \"减少进程名\""}
{"input": "", "instruction": "我想问的是，过去一小时内有没有新启动的程序吗？如果有的话，那它们的命令行参数是什么呢？", "output": "starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1h by json.cmdline |join type=left json.cmdline [[starttime=\"-1h-1d\" endtime=\"-1h\" appname:top_info_proc_stats |stats count() as cnt_1d by json.cmdline]] |where empty(cnt_1d)|fields json.cmdline |rename json.cmdline as \"新增进程名\""}
{"input": "", "instruction": "查找虚拟机在数据中心中的资源利用情况（CPU、内存和存储空间）。它首先从 vSphere 中检索具有指定标签（dmz_master）和来源（VirtualMachine）的所有事件，并将它们分组为每小时一个桶。然后，它计算每个桶中最后一秒钟的 CPU 使用率和内存使用量，并将结果与主机名和虚拟机名称进行匹配。接着，它使用另一个左联接来获取虚拟机的 IOPS 和存储空间使用量，并将这些值与前面的结果进行组合。最终，它对所有字段排序，仅保留那些 CPU 使用率大于 0 的记录，并重命名列标题以反映所需信息。", "output": "appname:vsphere tag:dmz_master  source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")  | stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name|eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\") | stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by +time|where cpu_Mhz >0| rename memory as \"已使用内存(Mb)\", storage as \"已使用磁盘(Gb)\""}
{"input": "", "instruction": "我想询问如何使用日志易SPL（Search Processing Language）编写查询以分析 VMware vSphere 数据。在这个查询中，我们首先从指定的索引和数据类型开始搜索。然后，我们将结果分组并计算每个时间段内有多少个虚拟机被备份到DMZ区域。最后，我们只保留那些总共有虚拟机的数据行，并按时间排序。这就是一个简单的示例，你可以根据自己的需求进行修改。", "output": "appname:vsphere tag:dmz_backup  source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_backup source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")  |  stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name,json.memory.total.guest.bytes|eval usage=format(\"%.3f %%\",memory/json.memory.total.guest.bytes * 100) |eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_backup source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\") | stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by -time|where cpu_Mhz >0"}
{"input": "", "instruction": "我想询问关于 vSphere 数据存储的性能问题，并且希望通过分析数据发现哪些 VM 使用率较高或下降较快，以便进行相应的优化和调优。以下是我的理解：1. 用户在过去一天内对虚拟机执行备份操作；2. 查询涉及到的时间范围为过去一天；3. 需要从虚拟机所在的数据中心中检索相关信息；4. 想要了解每个虚拟机的磁盘使用量、 IOPS 和吞吐量等指标；5. 对比不同时刻的指标变化程度，找出出现变动最大的 10 个虚拟机。", "output": "starttime=\"-1d/d\" endtime=\"now/d\" appname:vsphere tag:dmz_backup json.fstype:VMFS   |bucket timestamp span=1h as ts| stats count() as count_1 by ts,json.name,json.capacity.used.pct|eval time=formatdate(ts,\"HH:mm\")|eval ago_value=json.capacity.used.pct|join type=left json.name [[starttime=\"now/d\" endtime=\"now\" appname:vsphere tag:dmz_backup json.fstype:VMFS   |bucket timestamp span=1h as ts| stats count() as count_2 by json.name,json.capacity.used.pct|eval last_value=json.capacity.used.pct|eval time=formatdate(ts,\"HH:mm\")]]|eval cent=(last_value-ago_value)/ago_value*100|eval percent=format(\"%.2f\",cent)|eval percents=todouble(percent)| sort by +percents|limit 10"}
{"input": "", "instruction": "我想询问如何在 vSphere 中查询 CPU、内存和存储使用情况的相关趋势。", "output": "appname:vsphere tag:dmz_master source:VirtualMachine*   |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")| stats last(json.cpu.used.mhz) as cpu_Mhz by time,json.hostname,json.name | join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine*  |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\")  | stats last(json.memory.used.guest.bytes) as memory by time,json.hostname,json.name|eval memory=memory/1024/1024]]|join type=left time,json.name [[appname:vsphere tag:dmz_master  source:VirtualMachine* |bucket timestamp span=1h as ts |eval time=formatdate(ts,\"HH:mm\") | stats last(json.storage.used.bytes) as storage by time,json.hostname,json.name | eval storage=format(\"%.3f\",storage/1024/1024/1024)]] |sort by +time|where cpu_Mhz >0| rename memory as \"已使用内存(Mb)\", storage as \"已使用磁盘(Gb)\""}
{"input": "", "instruction": "我想问的是，系统内存使用率高于80%的主机有哪些？请列出IP地址和主机名，并给出它们的健康程度评分。", "output": "appname:top_info_win_system_stats  | stats count() as _ct by ip| stats count(ip) as _sum | eval a=1 | join type=left a [[ appname:top_info_win_system_stats | bucket timestamp span=5m as ts| stats avg(json.Mem.used_percent) as _avg by ip,hostname | where _avg >= 80 | stats dc(ip) as _bad | eval a=1]]| eval health=abs(_sum-_bad)/_sum"}
{"input": "十分钟内频繁掉线客户端前 10 名。索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "h3c无线AC数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:h3c ac.status:online \n| table ac.time,timestamp,ac.client,ac.ap_name\n|rename ac.* as *\n|rename timestamp as time1,time as online_time\n|sort by cnt\n|join type=inner client,ap_name[[\n\tappname:ac tag:h3c ac.status:offline \n\t| table ac.time,timestamp,ac.client,ac.ap_name\n\t|rename ac.* as *\n\t|rename timestamp as time2,time as offline_time\n\t|sort by cnt]]\n|eval time3=time2-time1\n|where time3>=0\n|stats count(client) as cnt by client\n|sort by cnt\n|limit 10"}
{"input": "客户端异常连接情况，根据 client 和 ap_name 字段值关联 online 和 offline 状态日志，计算二者的时间差，过滤时间差大于 0 的数据，然后按 client 分组计算 ap_name 和 ssid 的去重数，并保留 前 10 条结果。索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "h3c无线AC数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:h3c ac.status:online \n| table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid\n|rename ac.* as *\n|rename timestamp as time1,time as online_time\n|sort by cnt\n|join type=inner client,ap_name[[\n\tappname:ac tag:h3c ac.status:offline \n\t| table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid\n\t|rename ac.* as *\n\t|rename timestamp as time2,time as offline_time\n\t|sort by cnt]]\n|eval time3=time2-time1\n|where time3>=0\n|stats count(client) as cnt,dc(ap_name) as apcnt,dc(ssid) as sscnt by client\n|sort by cnt\n|limit 10\n|rename client as \"客户端\",cnt as \"频繁连接掉线次数\",apcnt as \"连接AP数量\",sscnt as \"连接ssid数量\""}
{"input": "攻击明细。索引可用字段有：firewall.action, firewall.alarm_ip, firewall.app, firewall.app_name, firewall.app_type, firewall.appcat, firewall.application_type, firewall.apprisk, firewall.attack, firewall.attack_message, firewall.attack_name, firewall.brief, firewall.dip, firewall.dst.geo.city, firewall.dst.geo.country, firewall.dst.geo.ip, firewall.dst.geo.province, firewall.dst.geo.latitude, firewall.dst.geo.longitude, firewall.dst_ip, firewall.dst_port, firewall.dst_zone, firewall.dup_add, firewall.event_level, firewall.event_name, firewall.event_type, firewall.facility, firewall.flow.application, firewall.flow.dst_ip.geo.city, firewall.flow.policy, firewall.flow.proto, firewall.fw_ip, firewall.grade, firewall.host, firewall.ingress_if, firewall.interface, firewall.kv.proto, firewall.kv.rule, firewall.level, firewall.locip, firewall.log_level, firewall.message, firewall.mod, firewall.module, firewall.msg, firewall.msg.CloseReason, firewall.msg.PolicyName, firewall.msg.RcvBytes, firewall.msg.SendBytes, firewall.msg.action, firewall.msg.command, firewall.msg.description, firewall.msg.dst_addr.geo.city, firewall.msg.dst_addr.geo.latitude, firewall.msg.dst_addr.geo.longitude, firewall.msg.dst_port, firewall.msg.fw, firewall.msg.method, firewall.msg.msg, firewall.msg.op, firewall.msg.pri, firewall.msg.proto, firewall.msg.reason, firewall.msg.result, firewall.msg.rule, firewall.msg.src_addr.geo.city, firewall.msg.src_addr.geo.country, firewall.msg.src_addr.geo.latitude, firewall.msg.src_addr.geo.longitude, firewall.msg.user, firewall.op, firewall.policy, firewall.policy_id, firewall.pri, firewall.pri_cn, firewall.proto, firewall.rcvd_pkt, firewall.reason, firewall.receive_byte, firewall.recorder, firewall.rem_ip.geo.city, firewall.rem_ip.geo.country, firewall.rem_ip.geo.province, firewall.remip, firewall.result, firewall.rule, firewall.rule_name, firewall.send_byte, firewall.sent, firewall.service, firewall.session_type, firewall.severity, firewall.severity_level, firewall.sip, firewall.source, firewall.src.geo.city, firewall.src.geo.country, firewall.src.geo.ip, firewall.src.geo.province, firewall.src.geo.latitude, firewall.src.geo.longitude, firewall.src_ip, firewall.src_port, firewall.src_zone, firewall.status, firewall.subtype, firewall.sys_info_id, firewall.sys_notify_traffic, firewall.threat_name, firewall.threat_subtype, firewall.threat_type, firewall.time, firewall.transport, firewall.type, firewall.url, firewall.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "firewall_神州数码数据，编写查询语句实现如下分析场景", "output": "appname:firewall tag:dc   firewall.event_level:Security|eval time=formatdate(timestamp,\"MM-dd HH:mm\")|table time,firewall.src_ip,firewall.dst_ip,firewall.event_name,firewall.action|join type=inner firewall.src_ip[[appname:firewall tag:dc  firewall.event_level:Security|table firewall.src_ip,firewall.attack_message]]|rename firewall.src_ip as \"攻击源IP\",firewall.dst_ip as \"目的IP\",firewall.event_name as \"事件名称\",firewall.action as \"动作\",firewall.attack_message as \"攻击信息\""}
{"input": "流量与APM关联查询详情。", "instruction": "广电运通关联数据，编写查询语句实现如下分析场景", "output": "*  appname:npm grg.src_ip:*\n|eval time=formatdate(timestamp,\"HH:mm\")\n| table time,grg.src_ip,grg.dst_ip,grg.message.total_bytes\n|rename grg.dst_ip as host\n|join type=inner host[[\n\t*   appname:apm \n\t|eval time1=formatdate(timestamp,\"HH:mm\")\n\t| table time1,grg.src_ip,grg.host.hostname,grg.process.title,grg.process.pid\n\t|rename grg.src_ip as host]]\n|rename grg.src_ip as \"源地址\",host as \"目的地址\",time as \"流量监测时间\",time1 as \"apm监测时间\",grg.host.hostname as  \"主机名\",grg.process.title as \"程序名\",grg.process.pid as \"程序PID\""}
{"input": "单位时段整机错误包占比_进出方向总合。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND (switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts OR switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.devip,switchperf.type,switchperf.ifindex | eval totalpkts=_max-_min | stats sum(totalpkts) as _total| eval \n data=\"errors_ratio\"\n| join data  [[appname:switchperf AND (switchperf.type:ifInErrors OR switchperf.type:ifOutErrors) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.devip,switchperf.type,switchperf.ifindex | eval totalerrors=_max-_min | stats sum(totalerrors) as _errors| eval data=\"errors_ratio\"]] \n| eval errors_ratio=_errors/_total"}
{"input": "单位时段整机丢包占比_进出方向总合。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND (switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts OR switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.type,switchperf.ifindex | eval totalpkts=_max-_min | stats sum(totalpkts) as _total| eval data=\"discards_ratio\"\n| join data  [[appname:switchperf AND (switchperf.type:ifInDiscards OR switchperf.type:ifOutDiscards) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.type,switchperf.ifindex | eval totaldiscards=_max-_min | stats sum(totaldiscards) as _discards| eval data=\"discards_ratio\"]] \n| eval discards_ratio=_discards/_total"}
{"input": "最近10分钟网络设备端口流量速率。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "starttime=\"now-10m\" endtime=\"now\" appname:switchperf AND (switchperf.type:ifInOctets OR switchperf.type:ifOutOctets) | table timestamp,switchperf.devip,switchperf.ifindex,switchperf.type,switchperf.value |  sort by switchperf.ifindex,switchperf.type,+timestamp| autoregress switchperf.value as lastvalue p=1 | autoregress switchperf.type as lasttype p=1 | autoregress switchperf.ifindex as lastifindex p=1 | where switchperf.ifindex==lastifindex | where switchperf.type==lasttype | eval bps=case(switchperf.value-lastvalue<0,(switchperf.value-lastvalue+4294967296)/300,default,(switchperf.value-lastvalue)/300) |where bps>0| eval bps=tolong(bps) | fields timestamp,switchperf.devip,switchperf.ifindex,switchperf.type,bps\n| join type=inner switchperf.ifindex [[starttime=\"now-10m\" endtime=\"now\" appname:switchperf switchperf.type:ifDescr NOT vlan NOT NULL0 | table switchperf.ifindex,switchperf.value | rename switchperf.value as ifdescr]]"}
{"input": "今天_平均阻塞数与阻塞耗时按每 15 分钟统计趋势。", "instruction": "informix日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" appname:informix tag:online_log |  bucket timestamp span=15m as ts| stats avg(informix.block) as avg_block by ts\n|join type=left ts\n[[\nstarttime=\"now/d\" appname:informix tag:online_log informix.block_time:<100| bucket timestamp span=15m as ts |stats avg(informix.block_time) as avg_block_time by ts\n]]"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux主机新增账号短期内又被删除，按 ip 和账户名做 join 关联，分别列出事件发生的时间", "output": "appname:linux tag:secure event_name:创建用户事件 |table timestamp,ip,user |join type=left ip,user [[ appname:linux tag:secure event_name:删除用户事件 |table timestamp,ip,user ]] "}
{"input": "发帖内容关注。", "instruction": "深信服上网行为审计数据，编写查询语句实现如下分析场景", "output": "access_control.appname:发帖|table access_control.record_time, access_control.host_ip, access_control.record_id|join type=left access_control.record_id [[ tag:upload access_control.result.x.title:*|table access_control.result.x.title, access_control.result.x.body, access_control.record_id]]"}
{"input": "kafka_各topic各partition拥塞情况。索引可用字段有：kafka.count_partition, kafka.count_topic, kafka.event_name, kafka.event_type, kafka.lag, kafka.partition, kafka.reson, kafka.topic, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "kafka_数据，编写查询语句实现如下分析场景", "output": "appname:kafka tag:performance\n| stats sum(kafka.lag) as lag by kafka.topic|join type=left kafka.topic [[appname:kafka tag:cnt_topic kafka.count_partition:*|table kafka.topic,kafka.count_partition]]"}
{"input": "前 20 条进程连接明细。索引可用字段有：windows.EventData.Data, windows.IpAddress, windows.System.EventID.text, windows.System.Level, windows.System.Provider.Name, windows.event_type, windows.level, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "windows_process数据，编写查询语句实现如下分析场景", "output": "appname:windows tag:process process.local_addr:* process.proto:TCP process.state:ESTABLISHED |limit 20 | table process.foreign_addr,process.foreign_port,process.local_addr,process.local_port,process.pid|rename process.pid as pid |join type = left pid [[tag:tasklist |table tasklist.pid,tasklist.taskname|rename tasklist.pid as pid]] |rename process.foreign_addr as foreign_addr,process.foreign_port as foreign_port,process.local_addr as local_addr,process.local_port as local_port,tasklist.taskname as taskname"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux主机新增账号短期被删除，分别查找 event_name 为创建用户事件和删除用户事件的日志，按 ip, user 关联后，时间戳相减得到耗时的毫秒数，除以 1000 转换成秒。表格列出主机 IP、用户名、创建时间(时分秒)、删除时间(时分秒)和用户存在时长。", "output": "appname:linux tag:secure event_name:创建用户事件 |table timestamp,ip,user |rename timestamp as ctime  |join type=left ip,user [[ appname:linux tag:secure event_name:删除用户事件 |table timestamp,ip,user |rename timestamp as dtime ]] |eval cost=(dtime-ctime)/1000 |eval createtime=formatdate(ctime,\"HH:mm:ss\") |eval deletetime=formatdate(dtime,\"HH:mm:ss\") |fields ip,user,createtime,deletetime,cost |rename ip as \"主机IP\",user as \"用户\",createtime as \"用户创建时间\",deletetime as \"用户删除时间\",cost as \"用户存在时长(秒)\""}
{"input": "fortress_leadsec_用户登录时长。从前 7 天的数据中查询adlg_type为 1 的数据，和今天为 3 的数据，按 session_guid 关联，将两份数据的 timestamp 相减，再减去 28800000，得到登录时长，将其格式化为HH:mm:ss格式。索引可用字段有：fortress.action, fortress.dst_ip, fortress.facility, fortress.host_ip, fortress.input, fortress.ip, fortress.level, fortress.log_type, fortress.loginOK, fortress.login_user, fortress.message, fortress.msg.action, fortress.msg.adlg_type, fortress.msg.begin_time, fortress.msg.command, fortress.msg.date, fortress.msg.mode, fortress.msg.module, fortress.msg.session_guid, fortress.msg.src_ip, fortress.msg.srcip, fortress.msg.srvaddr, fortress.msg.system_user, fortress.msg.sysuser, fortress.node, fortress.protocol, fortress.reason, fortress.remote_addr, fortress.request_msg, fortress.result, fortress.secondary_user, fortress.server, fortress.severity, fortress.src_ip, fortress.src_port, fortress.status, fortress.system_user, fortress.type, fortress.user, fortress.user_agent, fortress.user_name, fortress.username, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "fortress_leadsec仪表盘数据，编写查询语句实现如下分析场景", "output": "appname:fortress tag:leadsec fortress.msg.adlg_type:3 |table timestamp,fortress.msg.session_guid | rename timestamp as e_time | join type=left fortress.msg.session_guid  [[ starttime=\"-7d/d\" endtime=\"now/d\" appname:fortress tag:leadsec fortress.msg.adlg_type:1 | table timestamp,fortress.msg.session_guid ,fortress.msg.login_user | rename timestamp as s_time]]|eval total_time = formatdate(e_time-s_time-28800000,\"HH:mm:ss\")|rename total_time as \"登录时长\",fortress.login_user as \"用户名\""}
{"input": "kafka_今天新出现错误报告明细。索引可用字段有：kafka.count_partition, kafka.count_topic, kafka.event_name, kafka.event_type, kafka.lag, kafka.partition, kafka.reson, kafka.topic, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "kafka数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" endtime=\"now\" (appname:kafka kafka.event_type:ERROR)\n|eval time=formatdate(timestamp,\"MM/dd HH:mm\")\n|table time,kafka.event_name,kafka.reson|rename kafka.reson as newErrorReson\n|join type=left kafka.reson[[ starttime=\"-7d/d\" endtime=\"-1d/d\" (appname:kafka kafka.event_type:ERROR)|eval time=formatdate(timestamp,\"MM/dd HH:mm\")|table time,kafka.event_name,kafka.reson]]|fields time,kafka.event_name,newErrorReson"}
{"input": "上下线详情。索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "h3c无线AC数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:h3c ac.status:online\nac.client:${client} \n| table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid\n|rename ac.* as *\n|rename timestamp as time1,time as online_time\n|sort by cnt\n|join type=inner client,ap_name[[\n\tappname:ac tag:h3c ac.status:offline \n\t| table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid\n\t|rename ac.* as *\n\t|rename timestamp as time2,time as offline_time\n\t|sort by cnt]]\n|eval time3=(time2-time1)/1000\n|where time3>=0\n|fields online_time,offline_time,client,appname,ssid,time3|rename online_time as \"上线时间\",offline_time as \"下线时间\",client as \"客户端\",time3 as \"登录时长/s\""}
{"input": "", "instruction": "Linux操作系统审计_七天内主机CPU使用率指标详情", "output": "starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats AND tag:top_info |eval per=(100-cpu.idle_percent) |stats avg(per) as avg_ by ip,hostname |join type=left hostname [[ starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats AND tag:top_info | eval per=(100-cpu.idle_percent) |stats max(per) as max_ by ip,hostname]] |eval avg_=format(\"%.2f%%\",avg_) |eval max_=format(\"%.2f%%\",max_) "}
{"input": "", "instruction": "Linux操作系统审计_最近 7 天内的主机内存使用率指标和SWAP使用率详情", "output": "starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats |stats avg(Mem.used_percent) as avg_ by ip,hostname |join type=left hostname [[ starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats |stats max(Mem.used_percent) as max_ by ip,hostname]] |join type=left hostname [[ starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats |stats avg(Swap.used_percent) as savg_ by ip,hostname]] |join type=left hostname [[ starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats |stats max(Swap.used_percent) as smax_ by ip,hostname]] |eval avg_=format(\"%.2f%%\",avg_) |eval max_=format(\"%.2f%%\",max_) |eval savg_=format(\"%.2f%%\",savg_) |eval smax_=format(\"%.2f%%\",smax_) |rename ip as \"主机IP地址\",hostname as \"主机名\",avg_ as \"内存平均使用率\",max_ as \"内存最大使用率\",savg_ as \"SWAP平均使用率\",smax_ as \"SWAP最大使用率\""}
{"input": "索引可用字段有：middleware.Error_info, middleware.System_errinfo, middleware.System_errno, middleware.actconn, middleware.action, middleware.backend_queue, middleware.beconn, middleware.clientip, middleware.desc, middleware.dst_ip, middleware.error_level, middleware.error_no, middleware.event_name, middleware.event_type, middleware.feconn, middleware.func_no, middleware.geo.city, middleware.geo.isp, middleware.geo.province, middleware.http_hostname, middleware.http_method, middleware.http_referer, middleware.http_user_agent.browser, middleware.http_user_agent.os, middleware.level, middleware.message, middleware.method, middleware.middleware.nursery_free_after, middleware.module, middleware.msg, middleware.nursery_free_before, middleware.nursery_total, middleware.referer, middleware.referrer, middleware.req_time, middleware.request, middleware.request_method, middleware.request_path, middleware.request_status, middleware.response, middleware.response_code, middleware.retries, middleware.rsp, middleware.server, middleware.severity, middleware.src.geo.country, middleware.src.geo.isp, middleware.src_ip, middleware.src_ip.geo.city, middleware.srv_conn, middleware.srv_queue, middleware.status, middleware.subsystem, middleware.tc, middleware.tenure_free_after, middleware.tenure_free_before, middleware.thread, middleware.tt, middleware.tw, middleware.type, middleware.ua.browser, middleware.ua.device, middleware.ua.os, middleware.uri_query, middleware.uri_stem, middleware.url, middleware.zkmsg.zk_followers, middleware.zkmsg.zk_packets_received, middleware.zkmsg.zk_packets_sent, middleware.zkmsg.zk_server_state, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "从应用日志量统计的定时任务结果中，统计过去三十天内应用日志增长量的TOP10", "output": "starttime=\"-30d/d\" endtime=\"-1d/d\" _index:schedule schedule_name:日志易运营报告-应用日志量统计  |stats max(day_usage_in_bytes) as max_bytes by appname  |join type=left appname [[ starttime=\"-1d/d\" endtime=\"now/d\" _index:schedule schedule_name:日志易运营报告-应用日志量统计  |stats max(day_usage_in_bytes) as max_bytes_now by appname ]]  |eval gorwthrate=todouble(format(\"%.2f\",max_bytes_now/max_bytes)) |sort by gorwthrate |limit 10 |rename appname as \"应用名称\",max_bytes as \"30天前最大日志量(MB)\",max_bytes_now as \"昨天日志量(MB)\",gorwthrate as \"增长率\""}
{"input": "NSFOCUS本日访问的accept比例。索引可用字段有：firewall.action, firewall.alarm_ip, firewall.app, firewall.app_name, firewall.app_type, firewall.appcat, firewall.application_type, firewall.apprisk, firewall.attack, firewall.attack_message, firewall.attack_name, firewall.brief, firewall.dip, firewall.dst.geo.city, firewall.dst.geo.country, firewall.dst.geo.ip, firewall.dst.geo.province, firewall.dst.geo.latitude, firewall.dst.geo.longitude, firewall.dst_ip, firewall.dst_port, firewall.dst_zone, firewall.dup_add, firewall.event_level, firewall.event_name, firewall.event_type, firewall.facility, firewall.flow.application, firewall.flow.dst_ip.geo.city, firewall.flow.policy, firewall.flow.proto, firewall.fw_ip, firewall.grade, firewall.host, firewall.ingress_if, firewall.interface, firewall.kv.proto, firewall.kv.rule, firewall.level, firewall.locip, firewall.log_level, firewall.message, firewall.mod, firewall.module, firewall.msg, firewall.msg.CloseReason, firewall.msg.PolicyName, firewall.msg.RcvBytes, firewall.msg.SendBytes, firewall.msg.action, firewall.msg.command, firewall.msg.description, firewall.msg.dst_addr.geo.city, firewall.msg.dst_addr.geo.latitude, firewall.msg.dst_addr.geo.longitude, firewall.msg.dst_port, firewall.msg.fw, firewall.msg.method, firewall.msg.msg, firewall.msg.op, firewall.msg.pri, firewall.msg.proto, firewall.msg.reason, firewall.msg.result, firewall.msg.rule, firewall.msg.src_addr.geo.city, firewall.msg.src_addr.geo.country, firewall.msg.src_addr.geo.latitude, firewall.msg.src_addr.geo.longitude, firewall.msg.user, firewall.op, firewall.policy, firewall.policy_id, firewall.pri, firewall.pri_cn, firewall.proto, firewall.rcvd_pkt, firewall.reason, firewall.receive_byte, firewall.recorder, firewall.rem_ip.geo.city, firewall.rem_ip.geo.country, firewall.rem_ip.geo.province, firewall.remip, firewall.result, firewall.rule, firewall.rule_name, firewall.send_byte, firewall.sent, firewall.service, firewall.session_type, firewall.severity, firewall.severity_level, firewall.sip, firewall.source, firewall.src.geo.city, firewall.src.geo.country, firewall.src.geo.ip, firewall.src.geo.province, firewall.src.geo.latitude, firewall.src.geo.longitude, firewall.src_ip, firewall.src_port, firewall.src_zone, firewall.status, firewall.subtype, firewall.sys_info_id, firewall.sys_notify_traffic, firewall.threat_name, firewall.threat_subtype, firewall.threat_type, firewall.time, firewall.transport, firewall.type, firewall.url, firewall.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "绿盟防火墙日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" endtime=\"now\" appname:firewall  firewall.msg.action:accept |stats count() as count_accept  by appname |join type=left  appname [[starttime=\"now/d\" endtime=\"now\" appname:firewall    |stats count() as \n count_all by appname ]] |eval precent= count_accept/count_all"}
{"input": "NSFOCUS_近10分钟accept比例。索引可用字段有：firewall.action, firewall.alarm_ip, firewall.app, firewall.app_name, firewall.app_type, firewall.appcat, firewall.application_type, firewall.apprisk, firewall.attack, firewall.attack_message, firewall.attack_name, firewall.brief, firewall.dip, firewall.dst.geo.city, firewall.dst.geo.country, firewall.dst.geo.ip, firewall.dst.geo.province, firewall.dst.geo.latitude, firewall.dst.geo.longitude, firewall.dst_ip, firewall.dst_port, firewall.dst_zone, firewall.dup_add, firewall.event_level, firewall.event_name, firewall.event_type, firewall.facility, firewall.flow.application, firewall.flow.dst_ip.geo.city, firewall.flow.policy, firewall.flow.proto, firewall.fw_ip, firewall.grade, firewall.host, firewall.ingress_if, firewall.interface, firewall.kv.proto, firewall.kv.rule, firewall.level, firewall.locip, firewall.log_level, firewall.message, firewall.mod, firewall.module, firewall.msg, firewall.msg.CloseReason, firewall.msg.PolicyName, firewall.msg.RcvBytes, firewall.msg.SendBytes, firewall.msg.action, firewall.msg.command, firewall.msg.description, firewall.msg.dst_addr.geo.city, firewall.msg.dst_addr.geo.latitude, firewall.msg.dst_addr.geo.longitude, firewall.msg.dst_port, firewall.msg.fw, firewall.msg.method, firewall.msg.msg, firewall.msg.op, firewall.msg.pri, firewall.msg.proto, firewall.msg.reason, firewall.msg.result, firewall.msg.rule, firewall.msg.src_addr.geo.city, firewall.msg.src_addr.geo.country, firewall.msg.src_addr.geo.latitude, firewall.msg.src_addr.geo.longitude, firewall.msg.user, firewall.op, firewall.policy, firewall.policy_id, firewall.pri, firewall.pri_cn, firewall.proto, firewall.rcvd_pkt, firewall.reason, firewall.receive_byte, firewall.recorder, firewall.rem_ip.geo.city, firewall.rem_ip.geo.country, firewall.rem_ip.geo.province, firewall.remip, firewall.result, firewall.rule, firewall.rule_name, firewall.send_byte, firewall.sent, firewall.service, firewall.session_type, firewall.severity, firewall.severity_level, firewall.sip, firewall.source, firewall.src.geo.city, firewall.src.geo.country, firewall.src.geo.ip, firewall.src.geo.province, firewall.src.geo.latitude, firewall.src.geo.longitude, firewall.src_ip, firewall.src_port, firewall.src_zone, firewall.status, firewall.subtype, firewall.sys_info_id, firewall.sys_notify_traffic, firewall.threat_name, firewall.threat_subtype, firewall.threat_type, firewall.time, firewall.transport, firewall.type, firewall.url, firewall.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "绿盟防火墙日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now-10m/m\" endtime=\"now\" appname:firewall tag:nsfocus firewall.msg.action:accept |stats count() as count_accept  by appname |join type=left  appname [[starttime=\"now-10m/m\" endtime=\"now\" appname:firewall tag:nsfocus |stats count() as count_all by appname ]] |eval precent= count_accept/count_all"}
{"input": "点播业务命中率最高节点TOP10。点播域名包括：vod.hcs.yottabyte.cn, hlsspvod.rizhiyi.com, sp.vod.rizhiyi.com, hlszbvod.rizhiyi.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:vod.hcs.yottabyte.cn OR cdn.domain:hlsspvod.rizhiyi.com OR  cdn.domain:sp.vod.rizhiyi.com OR cdn.domain:hlszbvod.rizhiyi.com)  | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei    | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "图片业务命中率最高节点TOP10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei   AND cdn.cdn_status:*HIT  AND (cdn.domain:wapx.yottabyte.cn OR cdn.domain:img.yottabyte.cn OR  cdn.domain:yy0.tv.yottabyte.cn OR cdn.domain:yy1.tv.yottabyte.cn OR cdn.domain:yy2.tv.yottabyte.cn)  | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei  | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "查找1小时内单个IP的访问次数占这1小时内总IP数的百分比。", "output": "appname:apache | bucket timestamp span=1h as ts |stats count() as ip_count by apache.clientip,ts | join type=left ts [[appname:apache | bucket timestamp span=1h as ts |stats count() as aip_count by ts ]]|eval prent_ = format(\"%.2f%%\",ip_count / aip_count *100)"}
{"input": "服务器受攻击30分钟趋势_Top3服务器地址。索引可用字段有：waf.action, waf.attack_name, waf.attack_type, waf.bytes_in, waf.cost, waf.cve_id, waf.dst_city, waf.dst_domain, waf.dst_ip, waf.dst_latitude, waf.dst_longitude, waf.dst_port, waf.error_msg, waf.event_level, waf.event_log_level, waf.event_name, waf.event_type, waf.http_method, waf.http_refer, waf.is_truncated, waf.kv.Evt_level, waf.kv.Evt_type, waf.kv.event_name, waf.kv.http_method, waf.kv.http_refer, waf.kv.http_url, waf.kv.msg, waf.kv.owasp_top, waf.kv.pri, waf.kv.severity_level, waf.kv.status, waf.kv.type, waf.level, waf.log_category, waf.message, waf.message.action, waf.message.event, waf.message.method, waf.message.policy, waf.message.src_ip.geo.ip, waf.message.src_ip.geo.province, waf.message.src_port, waf.message.status, waf.message.threaten, waf.method, waf.module, waf.msg.act, waf.msg.cs, waf.msg.policy_id, waf.msg.src.geo.country, waf.policy_name, waf.proto, waf.referer, waf.risk_level, waf.severity, waf.src.geo.city, waf.src.geo.country, waf.src.geo.ip, waf.src.geo.isp, waf.src.geo.latitude, waf.src.geo.longitude, waf.src.geo.province, waf.src_ip, waf.src_port, waf.status, waf.status_code, waf.threat_level, waf.time, waf.ua_browser, waf.ua_device, waf.ua_os, waf.uri, waf.url, waf.user_agent.browser, waf.user_agent.os, waf.website_name, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Imperva_waf数据，编写查询语句实现如下分析场景", "output": "appname:waf  tag:imperva |bucket timestamp span=30m as ts |stats count() as ct  by ts,waf.dst_ip | join type=left waf.dst_ip  [[appname:waf  tag:imperva |top 3 waf.dst_ip]] |where count>0"}
{"input": "流总数。索引可用字段有：stb_vixtel_sotthas.district, stb_vixtel_sotthas.downloadTime, stb_vixtel_sotthas.freezeTime, stb_vixtel_sotthas.geo.city, stb_vixtel_sotthas.geo.province, stb_vixtel_sotthas.hasQoE, stb_vixtel_sotthas.programName, stb_vixtel_sotthas.stbId, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "机顶盒数据，编写查询语句实现如下分析场景", "output": "\nappname:stb_vixtel_sotthas |eval aaa=stb_vixtel_sotthas.stbId+\"|\"+stb_vixtel_sotthas.hasId|stats count() by aaa\n|eval line=\"count_\"\n|stats count() as count_dc_1 by line\n\n|join type=left line\n\n[[ \nappname:stb_vixtel_smpegts |eval bbb=stb_vixtel_smpegts.stbId+\"|\"+stb_vixtel_smpegts.iptvId|stats count() by bbb\n|eval line=\"count_\"\n|stats count() as count_dc_2 by line\n]]\n\n|eval count_1=count_dc_1+count_dc_2"}
{"input": "非内网ip访问资源情况，展示最近 50 条。索引可用字段有：vpn.action, vpn.actor.displayName, vpn.actype, vpn.app.upstream.host, vpn.app.upstream.port, vpn.app.web.request.url, vpn.auth_dst, vpn.dst.geo.city, vpn.dst.geo.country, vpn.dst.geo.ip, vpn.dst.geo.isp, vpn.dst.geo.latitude, vpn.dst.geo.longitude, vpn.dst.geo.province, vpn.dst_ip, vpn.dst_nt_host, vpn.dst_port, vpn.event_level, vpn.event_name, vpn.kv.dst.geo.country, vpn.kv.dst.geo.latitude, vpn.kv.dst.geo.longitude, vpn.kv.msg, vpn.kv.proto, vpn.kv.src.geo.city, vpn.kv.src.geo.country, vpn.kv.src.geo.latitude, vpn.kv.src.geo.longitude, vpn.kv.user, vpn.login_user, vpn.msg, vpn.msg.virtual_ip, vpn.proto, vpn.reason, vpn.resource_name, vpn.result, vpn.seconds, vpn.src._ip, vpn.src.geo.city, vpn.src.geo.country, vpn.src.geo.ip, vpn.src.geo.isp, vpn.src.geo.latitude, vpn.src.geo.longitude, vpn.src.geo.province, vpn.src_ip, vpn.src_ip.geo.city, vpn.src_ip.geo.country, vpn.src_port, vpn.state, vpn.target.displayName, vpn.time, vpn.transport, vpn.user, vpn.user_name, vpn.vpn.login_user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "sslvpn日志数据，编写查询语句实现如下分析场景", "output": "appname:vpn tag:cisco (NOT \"authentication\") AND (NOT vpn.src.geo.province:private ) AND vpn.user:*\n|eval time = formatdate(timestamp)\n|table time,vpn.user,vpn.src._ip,vpn.dst_ip,vpn.dst_port,vpn.transport\n|join type = inner vpn.user[[\n\tappname:vpn tag:cisco (\"authentication\") AND (NOT vpn.src.geo.province:private ) \n\t|stats count() by vpn.user,vpn.src_ip,vpn.src.geo.province,vpn.src.geo.city\n\t|fields vpn.src_ip,vpn.user,vpn.src.geo.province,vpn.src.geo.city]]\n|rename time as \"时间\",vpn.user as \"用户\",vpn.src_ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.transport as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\"\n|limit 50"}
{"input": "健康度。索引可用字段有：switch.IP, switch.action, switch.auth_method, switch.bandwidth, switch.brief, switch.cmd, switch.count, switch.desc, switch.desc.cmd, switch.desc.user, switch.describe, switch.ethernet, switch.event_type, switch.facility, switch.host, switch.host_ip, switch.interface_name, switch.ip, switch.kv.COMMAND, switch.kv.TTY, switch.kv.USER, switch.kvmsg.IpAddress, switch.kvmsg.UserName, switch.level, switch.log_message, switch.log_type, switch.login_method, switch.mode, switch.module, switch.port, switch.port_channel, switch.reason, switch.result, switch.severity, switch.speed, switch.src_ip, switch.src_mac, switch.state, switch.terminal, switch.time, switch.user, switch.vlan, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "交换机_华为数据，编写查询语句实现如下分析场景", "output": "appname:switch tag:huawei \n| stats count() as count_ by switch.severity \n| eval tmp=switch.severity*count_\n|join type=left switch.severity [[\n\tappname:switch tag:huawei switch.severity:>3\n\t| stats count() as count1 by switch.severity \n\t| eval tmp=switch.severity*count1]]|stats sum(count_) as sum_,sum(count1) as sum1|eval health=(sum1)/sum_"}
{"input": "收发成功率。索引可用字段有：exchange.client_hostname, exchange.clientip.geo.ip, exchange.dst.geo.city, exchange.dst.geo.country, exchange.dst_ip, exchange.event_id, exchange.message_subject, exchange.recipient_address, exchange.recipient_count, exchange.recipient_status, exchange.sender_address, exchange.server_hostname, exchange.source, exchange.src_ip, exchange.status, exchange.total_bytes, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "exchange前端日志数据，编写查询语句实现如下分析场景", "output": "appname:exchange tag:front  |stats count()  as count_all | eval a=1 | join type=left a  [[ appname:exchange tag:front  AND exchange.status:200 | stats count() as count_200 | eval a=1 ]] | eval cnt_all = tolong(count_all) | eval cnt_200=tolong(count_200) | eval rate=if(empty(cnt_200),0,cnt_200/cnt_all) |eval rate=format(\"%.4f\",rate) |fields rate"}
{"input": "按每小时分桶统计平均耗时趋势。", "instruction": "zsns 应用的tomcat业务数据，编写查询语句实现如下分析场景", "output": "appname:zsns tomcat.event_type:*请求报文 | stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp\n|rename  timestamp as t1\n|join tomcat.service.head.origCstSeqNo [[\n\tappname:zsns tomcat.event_type:*响应报文\n\t| stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp\n\t|eval t2=timestamp\n]]\n| eval cost= tolong(t2)-tolong(t1)\n|bucket timestamp span=1h as ts|stats avg(cost) as avg_cost by ts"}
{"input": "按每30分钟分桶统计接口失败率趋势图。", "instruction": "Thinkbus接口访问数据，编写查询语句实现如下分析场景", "output": "appname:thinkive_works_web_log AND middleware.action: \"Response\" |bucket timestamp span=30m as ts | stats count() as total by ts, middleware.func_no | join type=left ts, middleware.func_no [[appname:thinkive_works_web_log AND middleware.action: \"Response\" AND NOT middleware.response:0 |bucket timestamp span=30m as ts | stats count() as failed_ by ts, middleware.func_no]] |table ts, middleware.func_no,total,failed_|eval failed=if(empty(failed_),0,failed_)|eval failed_pct=failed/total |table ts, middleware.func_no, failed_pct|rename middleware.func_no as '接口', failed_pct as '失败率'"}
{"input": "离职预测分值。索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "深信服行为感知数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:sangfor ac.msg.serv:访问网站 ac.msg.app:*招聘*  \n|stats count() as times,dc(ac.msg.app) as type by ac.msg.user \n|eval timeslevel=tolong(case(times<=5,\"1\",times>5&&times<=20,\"2\",times>20&&times<=50,\"3\",times>50,\"4\"))\n| eval typelevel=tolong(case(type==1,\"1\",type>1&&type<=2,\"2\",type>2&&type<=4,\"3\",type>4,\"4\"))\n| join ac.msg.user[[\n\tappname:ac tag:sangfor ac.msg.serv:访问网站 ac.msg.app:* \n\t|bucket timestamp span=1d as ts\n\t|stats dc(ts) as days by ac.msg.user\n\t|eval dayslevel=tolong(case(days==1,\"1\",days>1&&days<=3,\"2\",days==4,\"3\",days>4,\"4\"))]]\n|eval score=timeslevel*0.3+typelevel*0.2+dayslevel*0.5\n|fields ac.msg.user,times,timeslevel,type,typelevel,days,dayslevel,score\n|rename ac.msg.user as \"访问用户\",times as \"访问次数\",timeslevel as \"次数等级\",type as \"访问网站类型数\",typelevel as \"类型等级\",days as \"出现访问天数\",dayslevel as \"天数等级\",score as \"离职预测分值\""}
{"input": "预测离职分值。索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奇安信AC数据，编写查询语句实现如下分析场景", "output": "appname:ac tag:qianxin ac.log_type:* ac.web_app:*招聘* OR ac.web_app:*求职*\n|stats count() as times,dc(ac.request_url) as type by ac.src_ip\n|eval timeslevel=tolong(case(times<=5,\"1\",times>5&&times<=20,\"2\",times>20&&times<=50,\"3\",times>50,\"4\"))\n| eval typelevel=tolong(case(type<8,\"1\",type>7&&type<=10,\"2\",type>10&&type<=20,\"3\",type>20,\"4\"))\n| join ac.src_ip[[\n\tappname:ac tag:qianxin ac.log_type:web ac.web_app:*招聘* OR ac.web_app:*求职*\n\t|bucket timestamp span=1d as ts\n\t|stats dc(ts) as days by ac.client,ac.src_ip\n\t|eval dayslevel=tolong(case(days==1,\"1\",days>1&&days<=3,\"2\",days==4,\"3\",days>4,\"4\"))]]\n|eval score=timeslevel*0.3+typelevel*0.2+dayslevel*0.5"}
{"input": "", "instruction": "假冒APP手动上报查询", "output": "appname:sdc AND pipeline:\"钓鱼网站/假冒APP数据上报\" data[].fake_app_download:* | stats count() as ct by pipelineid,data[].time,data[].institution_code,data[].institution_short,data[].fake_app_download,data[].befaked_app  |join type=left pipelineid [[tag:sdc AND pipeline:\"钓鱼网站/假冒APP数据上报\"  |stats count() as ct by pipelineid,msg ]]  |fields data[].time,data[].institution_code,data[].institution_short,data[].fake_app_download,data[].befaked_app,msg  |rename data[].time as \"发生时间\",data[].institution_code as \"机构代码\",data[].institution_short as \"机构简称\",data[].fake_app_download as \"假冒APP下载地址\",data[].befaked_app as \"被仿冒APP\",msg as \"上报状态\""}
{"input": "", "instruction": "垃圾邮件数人工上报查询", "output": "appname:sdc AND pipeline:\"垃圾邮件数人工上报\" |stats count() as ct by pipelineid,data[].time,data[].institution_code,data[].institution_short,data[].intercept_total |join type=left pipelineid [[appname:sdc AND pipeline:\"垃圾邮件数人工上报\"  |stats count() as ct by pipelineid,msg]]  |fields data[].time,data[].institution_code,data[].institution_short,data[].intercept_total,msg  |rename data[].time as \"发生时间\",data[].institution_code as \"机构代码\",data[].institution_short as \"机构简称\",data[].intercept_total as \"垃圾邮件总数\",msg as \"上报状态\""}
{"input": "", "instruction": "钓鱼网站手动上报查询", "output": "appname:sdc AND pipeline:\"钓鱼网站/假冒APP数据上报\"  | stats count() as ct by pipelineid,data[].time,data[].institution_code,data[].institution_short,data[].fake_domain_name,data[].fake_url,data[].fake_ip,data[].befaked_domain_name  |join type=left pipelineid [[tag:sdc AND pipeline:\"钓鱼网站/假冒APP数据上报\"  |stats count() as ct by pipelineid,msg ]] "}
{"input": "在 linux 日志中搜索标签为 crond，事件名称为定时任务事件的日志，按 ip、user、command 分组统计，并把三个字段的值用下划线拼接在一起作为 total 字段。然后求 total 的 MD5 值。接着把 ip 重命名为 today_ip、user 重命名为 today_user、command 重命名为 today_command。然后从 cron_list.csv 中读取数据，按 total_md5字段之前的数据做左连接。最后，判断 command 字段是否为空，如果为空，给 command 字段赋值一句话：该条记录不在定时任务列表中。。索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "linux_定时任务列表执行情况", "output": "appname:linux tag:crond event_name:定时任务事件 |stats count() as ct by ip,user,command |eval total=ip+\"_\"+user+\"_\"+command |eval total_md5=md5(total) |rename ip as today_ip,user as today_user,command as today_command | join type=left total_md5 [[ |inputlookup cron_list.csv | eval total_md5=md5(total) ]] |fields total_md5,today_ip,today_user,today_command,command,ct |eval command=if(empty(command),\"该条记录不在定时任务列表中\",command)"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "linux_定时任务清单当天新增数量", "output": "starttime=\"now/d\" appname:linux tag:crond event_name:定时任务列表 duration:* |stats count() as ct by ip,user,duration,command |eval total=ip+\"_\"+user+\"_\"+command |eval total_md5=md5(total) |rename ip as today_ip,user as today_user,command as today_command | join type=left total_md5 [[ |inputlookup cron_list.csv | eval total_md5=md5(total) ]] |eval status=if(empty(command),\"该条记录为新增记录\",command) |stats count() as ct"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "linux_当天新增定时任务", "output": "starttime=\"now/d\" appname:linux tag:crond event_name:定时任务列表 duration:* |stats count() as ct by ip,user,duration,command |eval total=ip+\"_\"+user+\"_\"+command |eval total_md5=md5(total) |rename ip as today_ip,user as today_user,command as today_command | join type=left total_md5 [[ |inputlookup cron_list.csv | eval total_md5=md5(total) ]] |eval status=if(empty(command),\"该条记录为新增记录\",command) |fields today_ip,today_user,duration,today_command,status"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux主机新增账号短期被删除事件数统计", "output": "appname:linux tag:secure event_name:创建用户事件 |table timestamp,ip,user |join type=left ip,user [[ appname:linux tag:secure event_name:删除用户事件 |table timestamp,ip,user ]] |stats count() as cnt  "}
{"input": "aofei_cdn命中率。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT  | stats count()  as _count_1 by appname | join type = left appname [[ \nappname:cdn tag:aofei   | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_cdn命中次数。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT  | stats count()  as _count_1 by appname | join type = left appname [[ \nappname:cdn tag:aofei | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_cdn访问次数。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT  | stats count()  as _count_1 by appname | join type = left appname [[ \nappname:cdn tag:aofei | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_直播业务命中率。直播平台域名包括：live1.video.cn, live2.video.com, live3.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:aofei     (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_直播业务命中次数。直播平台域名包括：live1.video.cn, live2.video.com, live3.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_直播业务访问次数。直播平台域名包括：live1.video.cn, live2.video.com, live3.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:aofei    (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_点播业务命中率。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei(cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:aofei  (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_点播业务访问次数。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei(cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:aofei  (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "aofei_点播业务命中次数。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:aofei(cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "CDN分应用计算命中率。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  | stats count() as _count_1 by appname | join type = left appname [[ \nappname:cdn tag:huawei    | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "直播业务命中率。直播平台域名包括：live1.video.cn, live2.video.com, live3.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei    (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "点播业务命中率。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei    (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "点播业务命中次数。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "点播业务访问次数。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "图片业务命中率。图片业务域名包括：wapx.example.cn,img.example.cn,tv.example.cn。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei   (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)| stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "图片业务命中次数。图片业务域名包括：wapx.example.cn,img.example.cn,tv.example.cn。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei    (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn) | stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "图片业务访问次数。图片业务域名包括：wapx.example.cn,img.example.cn,tv.example.cn。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ \nappname:cdn tag:huawei   (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)| stats count()  as _count_2 by appname ]]\n| eval per = _count_1 / _count_2"}
{"input": "dns解析成功率。索引可用字段有：dns.dhcp_ip, dns.dhcp_mac, dns.dhcp_req_type, dns.domain, dns.gateway, dns.level, dns.query, dns.rcode, dns.search_type, dns.src_ip, dns.type, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "ZDNS日志数据，编写查询语句实现如下分析场景", "output": "appname:dns tag:zdns dns.rcode:* | stats count() as count_1 by appname | join type = left appname[[\nappname:dns tag:zdns dns.rcode:NOERROR   | stats count()  as count_2 by appname]] | eval per = count_2 / count_1"}
{"input": "各敏感资源被各用户访问情况。", "instruction": "h_poc数据，编写查询语句实现如下分析场景", "output": "appname:h_2 tag:h_2 \n| stats count() as cnt by h_1.uri,h_1.database_user,h_1.database_name,h_1.table_name\n|rename h_1.uri as url \n| join url[[\n\tappname:apache tag:access\n\t| rename middleware.referer as url \n\t|stats count() as cnt1 by url,middleware.clientip ]] \n| rename url as uri \n|lookup desc,u_ip h_url.csv on uri=url\n| fields url,h_1.database_user,middleware.clientip,desc,u_ip,h_1.database_name,h_1.table_name,cnt\n| rename h_1.database_user as \"用户\",middleware.clientip as \"源地址\",desc as \"系统名称\",u_ip as \"系统IP\",h_1.database_name as \"数据库名\",h_1.table_name as \"敏感表表名\""}
{"input": "各系统被访问敏感资源情况。", "instruction": "h_poc数据，编写查询语句实现如下分析场景", "output": "appname:h_2 tag:h_2 \n| stats count() as cnt by h_1.uri,h_1.database_user,h_1.database_name,h_1.table_name\n|rename h_1.uri as url \n| join url[[\n\tappname:apache tag:access\n\t| rename middleware.referer as url \n\t|stats count() as cnt1 by url,middleware.clientip ]] \n| rename url as uri \n|lookup desc,u_ip h_url.csv on uri=url\n| fields url,h_1.database_user,middleware.clientip,desc,u_ip,h_1.database_name,h_1.table_name,cnt\n| rename h_1.database_user as \"用户\",middleware.clientip as \"源地址\",desc as \"系统名称\",u_ip as \"系统IP\",h_1.database_name as \"数据库名\",h_1.table_name as \"敏感表表名\""}
{"input": "功能请成功处理比例。", "instruction": "通达信数据，编写查询语句实现如下分析场景", "output": "(appname:tdx  NOT 连接信息) \"功能请求\" | stats count() as total | eval t=\"A\" | join  type=left t [[(appname:tdx  NOT 连接信息) \"成功处理\" | stats count() as succ | eval t=\"A\"]] | eval per=succ/total"}
{"input": "平均耗时。", "instruction": "zsns 应用的tomcat业务数据，编写查询语句实现如下分析场景", "output": "appname:zsns tomcat.event_type:*请求报文\ntomcat.event_type:*${type}*\n| stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp\n|rename timestamp as t1\n|join tomcat.service.head.origCstSeqNo [[\n\tappname:zsns tomcat.event_type:*响应报文\n\t| stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp\n\t|rename timestamp as t2\n]]\n| eval cost= tolong(t2)-tolong(t1)|stats avg(cost) as avg_cost"}
{"input": "最大耗时。", "instruction": "zsns 应用的tomcat业务数据，编写查询语句实现如下分析场景", "output": "appname:zsns tomcat.event_type:*请求报文\ntomcat.event_type:*${type}*\n| stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp\n|rename timestamp as t1\n|join tomcat.service.head.origCstSeqNo [[\n\tappname:zsns tomcat.event_type:*响应报文\n\t| stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp\n\t|rename timestamp as t2\n]]\n| eval cost= tolong(t2)-tolong(t1)|stats max(cost) as max_cost"}
{"input": "具体方案如下：1. 首先使用 AND 连接两个搜索条件,筛选出appname为vpn并且tag为sangfor vpn的日志。\n2. 然后再次使用 AND 连接搜索条件,进一步筛选出access类型的日志。\n3. 接着使用 NOT 连接一个搜索条件,过滤掉省份为private的日志。\n4. 使用 stats count() by 分组统计登录用户,并使用 fields 选择需要的字段。\n5. 使用 eval time = formatdate(timestamp) 转换时间字段值的格式。\n6. 使用 table 格式化显示字段,选择时间、登录用户、源IP、目的IP、目的端口和协议字段。\n7. 使用 join type = inner 连接之前的统计结果,增加省份和城市字段。\n8. 使用 rename 重命名部分字段。\n9. 最后使用 limit 限制显示5条结果。。", "instruction": "非内网ip访问资源情况，从深信服 VPN 日志中查最近 5 条", "output": "(* AND appname:vpn) AND 'tag':sangfor vpn.actype:access\\ resource [[ (* AND appname:vpn) AND 'tag':sangfor vpn.actype:login NOT vpn.src.geo.province:private  |stats count() by vpn.login_user  |fields vpn.login_user]]  |eval time = formatdate(timestamp) |table time,vpn.login_user,vpn.src.geo.ip,vpn.dst_ip,vpn.dst_port,vpn.proto |join type = inner vpn.login_user[[ (* AND appname:vpn) AND 'tag':sangfor vpn.actype:login NOT vpn.src.geo.province:private  |stats count() by vpn.login_user,vpn.src.geo.ip,vpn.src.geo.province,vpn.src.geo.city |rename vpn.src.geo.ip as ip |fields ip,vpn.login_user,vpn.src.geo.province,vpn.src.geo.city]] |rename time as \"时间\",vpn.login_user as \"用户\",vpn.src.geo.ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.proto as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\" |limit 5"}
{"input": "直播业务节点状态与直播次数及占比情况。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 ) | stats count() as _count_1 by appname,cdn.http_status | join type = left appname [[ appname:cdn tag:aofei | stats count() as _count_2 by appname ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename appname as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"直播次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "直播业务各节点状态与点播次数及占比情况。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 ) | stats count() as _count_1 by tag,cdn.http_status | join type = left tag [[ appname:huawei    |  stats count() as _count_2 by tag   ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"直播次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "直播业务各节点3 秒超时情况。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.finished_body_response:>3 |  stats count() as _count_1 by tag | join type =left tag [[ appname:huawei   AND  (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) |  stats count() as _count_2 by tag ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"命中次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "非内网ip访问资源情况，展示 50 条。", "instruction": "深信服VPN日志数据，编写查询语句实现如下分析场景", "output": "(* AND appname:vpn) AND 'tag':sangfor vpn.actype:access\\ resource [[\n\t(* AND appname:vpn) AND 'tag':sangfor vpn.actype:login NOT vpn.src.geo.province:private \n\t|stats count() by vpn.login_user \n\t|fields vpn.login_user]] \n|eval time = formatdate(timestamp)\n|table time,vpn.login_user,vpn.src.geo.ip,vpn.dst_ip,vpn.dst_port,vpn.proto\n|join type = inner vpn.login_user[[\n\t\t(* AND appname:vpn) AND 'tag':sangfor vpn.actype:login NOT vpn.src.geo.province:private \n\t|stats count() by vpn.login_user,vpn.src.geo.ip,vpn.src.geo.province,vpn.src.geo.city\n\t|rename vpn.src.geo.ip as ip\n\t|fields ip,vpn.login_user,vpn.src.geo.province,vpn.src.geo.city]]\n|rename time as \"时间\",vpn.login_user as \"用户\",vpn.src.geo.ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.proto as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\"\n|limit 50"}
{"input": " 关联中间件访问来源 IP 和 DLP 来源 IP，统计各敏感文件被访问情况，列出最多的 10 条。索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "中间件和 DLP数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access | stats count() as cnt by middleware.clientip | rename middleware.clientip as src_ip |join src_ip[[appname:dlp tag:websense|rename dlp.src_ip as src_ip | stats count() as cnt by src_ip,dlp.file_name]] | limit 10"}
{"input": "非内网ip访问资源情况，展示前 50 条。需要利用登录用户名来分别关联vpn.actype为access resource的网络五元组信息和vpn.actype为login的地理信息。", "instruction": "Cisco_VPN日志数据，编写查询语句实现如下分析场景", "output": "(* AND appname:vpn) AND 'tag':cisco vpn.actype:access\\ resource [[\n\t(* AND appname:vpn) AND 'tag':cisco vpn.actype:login NOT vpn.src.geo.province:private \n\t|stats count() by vpn.login_user \n\t|fields vpn.login_user]] \n|eval time = formatdate(timestamp)\n|table time,vpn.login_user,vpn.src.geo.ip,vpn.dst_ip,vpn.dst_port,vpn.proto\n|join type = inner vpn.login_user[[\n\t\t(* AND appname:vpn) AND 'tag':cisco vpn.actype:login NOT vpn.src.geo.province:private \n\t|stats count() by vpn.login_user,vpn.src.geo.ip,vpn.src.geo.province,vpn.src.geo.city\n\t|rename vpn.src.geo.ip as ip\n\t|fields ip,vpn.login_user,vpn.src.geo.province,vpn.src.geo.city]]\n|rename time as \"时间\",vpn.login_user as \"用户\",vpn.src.geo.ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.proto as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\"\n|limit 50"}
{"input": "aofei点播业务各节点状态与点播次数及占比情况。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 )  AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  |  stats count() as _count_1 by appname,cdn.http_status | join type=left appname [[ appname:cdn tag:aofei    |  stats count() as _count_2 by appname   ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename appname as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"命中次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "CDN各节点状态与命中率。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 )   |  stats count() as _count_1 by tag,cdn.http_status | join type = left tag [[ appname:cdn tag:huawei    |  stats count() as _count_2 by tag   ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"命中次数\", _count_2 as \"访问次数\", percent as \"命中率\""}
{"input": "点播业务各节点状态与点播次数及占比情况。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 )  AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  |  stats count() as _count_1 by tag,cdn.http_status | join type =  left tag [[ appname:huawei    |  stats count() as _count_2 by tag   ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"命中次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "点播业务各节点超时情况。点播域名包括：vod1.video.com,vod2.video.com,vod3.video.com,vod4.video.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei AND cdn.finished_body_response:>3 AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) |  stats count() as _count_1 by tag | join type =left tag [[ appname:cdn tag:huawei   AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) |  stats count() as _count_2 by tag ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"命中次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "今天和本小时的接收过滤模式，按security_gateway.message关联。索引可用字段有：security_gateway.Meaning, security_gateway.event_name, security_gateway.message, security_gateway.service, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "梭子鱼邮件网关日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" endtime=\"now\"\nappname:security_gateway tag:barracuda security_gateway.event_name:RECV| stats count() as count_1 by  security_gateway.message\n|join type=left security_gateway.message\n[[\nstarttime=\"now-1h\" endtime=\"now\" \nappname:security_gateway tag:barracuda security_gateway.service:RECV| stats count() as count_2 by  security_gateway.message\n]]\n|rename  security_gateway.message as \"过滤模式\"\n|rename count_1 as \"今天\"\n|rename count_2 as \"本小时\""}
{"input": "今天和本小时的发送过滤模式，按security_gateway.message关联。索引可用字段有：security_gateway.Meaning, security_gateway.event_name, security_gateway.message, security_gateway.service, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "梭子鱼邮件网关日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"now/d\" endtime=\"now\"\nappname:security_gateway tag:barracuda security_gateway.event_name:SEND| stats count() as count_1 by  security_gateway.message\n|join type=left security_gateway.message\n[[\nstarttime=\"now-1h\" endtime=\"now\" \nappname:security_gateway  tag:barracuda security_gateway.service:SEND| stats count() as count_2 by  security_gateway.message\n]]\n|rename  security_gateway.message as \"过滤模式\"\n|rename count_1 as \"今天\"\n|rename count_2 as \"本小时\""}
{"input": "分支机构连接成功率。", "instruction": "lingcloud流量数据，编写查询语句实现如下分析场景", "output": "appname:lingcloud AND tag:kpi_permin_site utc |stats count() by lingcloud.siteid|join type=left lingcloud.siteid [[appname:lingcloud AND tag:kpi_permin_site utc|stats sum(lingcloud.data.successfulTcpConnNum) as cnt_succ by lingcloud.siteid]]|join type=left lingcloud.siteid [[appname:lingcloud AND tag:kpi_permin_site utc |stats sum(lingcloud.data.failedTcpConnNum) as cnt_fail by lingcloud.siteid]]|lookup sitename dclingcloud_site.csv on lingcloud.siteid=siteid|where !empty(sitename)|eval succ=if(empty(cnt_succ),0,cnt_succ)|eval failed=if(empty(cnt_fail),0,cnt_fail)|eval rate=succ*100/(succ+failed)"}
{"input": "订单成功率。", "instruction": "pf_gateway数据，编写查询语句实现如下分析场景", "output": "appname:pf_gateway  |stats count() as cnt by appname| join type=left appname  [[appname:pf_gateway gateway.result:result=true|stats count() as cnt1 by appname]]|eval pe=format(\"%.2f\",cnt1/cnt*100)"}
{"input": "近60分钟内与java、httpd、php-fpm、tomcat等父进程相关的ps、gcc、whoami等可疑命令,统计其执行情况,并连接近 2 天内父进程的详细信息。索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "linux日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"-60m/m\" endtime=\"now\"((appname:linux tag:audit) OR (appname:linux linux.log_type:audit)) AND(\"bin/*\") AND(linux.event_detail.comm:\"ps\" OR linux.event_detail.comm:\"gcc\" OR linux.event_detail.comm:\"whoami\" OR linux.event_detail.comm:\"who\" OR linux.event_detail.comm:\"w\" OR linux.event_detail.comm:\"id\" OR linux.event_detail.comm:\"uname\" OR linux.event_detail.comm:\"nc\" OR linux.event_detail.comm:\"socat\" OR linux.event_detail.comm:\"wget\" OR linux.event_detail.comm:\"useradd\" OR linux.event_detail.comm:\"userdel\" OR linux.event_detail.comm:\"curl\" OR linux.event_detail.comm:\"mkfifo\" OR linux.event_detail.comm:\"adduser\" OR linux.event_detail.comm:\"ifconfig\") \n|eval time=formatdate(timestamp,\"MMM dd HH:mm\")\n| stats count() as cnt by time,linux.event_id,linux.event_detail.ppid,linux.event_detail.pid,linux.event_detail.comm\n| fields time,linux.event_id,linux.event_detail.ppid,linux.event_detail.pid,linux.event_detail.comm\n| rename linux.event_detail.ppid as ppid,linux.event_detail.pid as pid,linux.event_id as \"事件ID\",linux.event_detail.comm as \"操作指令\" \n| join type=inner max=100 ppid[[\n\tstarttime=\"-2d/d\" endtime=\"now\" ((appname:linux tag:audit) OR (appname:linux linux.log_type:audit)) AND (\"java\" OR \"httpd\" OR \"php-fpm\" OR \"tomcat\")\n\t| stats count() as cnt1 by linux.event_detail.pid,linux.event_id,linux.event_detail.exe,linux.event_detail.comm \n\t| fields linux.event_detail.pid,linux.event_id,linux.event_detail.exe,linux.event_detail.comm\n\t| rename linux.event_detail.pid as ppid,linux.event_id as \"父进程eventID\" ,linux.event_detail.exe as \"父进程工作路径\",linux.event_detail.comm as \"父进程操作指令\"]]"}
{"input": "h_减少的登录账户。", "instruction": "企业bg数据，编写查询语句实现如下分析场景", "output": "starttime=2020-03-26:15:00:00 endtime=2020-03-26:16:00:00 appname:h_1  | stats count() as cnt_left by h_1.user_name\t|join type=left h_1.user_name[[starttime=2020-03-26:21:00:00 endtime=2020-03-26:22:00:00 appname:h_1  | stats count() as cnt_right by h_1.user_name]]|where empty(cnt_right)|rename h_1.user_name as \"账号\"|rename cnt_left as \"1小时前次数\"|rename cnt_right as \"1小时后次数\""}
{"input": "", "instruction": "linux_与一天前相比新增的进程", "output": "starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1h by cmdline  |join type=left cmdline [[ starttime=\"-1h-1d\" endtime=\"-1h\" appname:top_info_proc_stats  |stats count() as cnt_1d by cmdline]]  |where empty(cnt_1d) |fields cmdline  |rename cmdline as \"新增进程名\""}
{"input": "CDN命中率最高节点top10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei    | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100) "}
{"input": "aofei_cdn命中率最高资源TOP10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by appname, cdn.prefix_url | join type = left appname [[ \nappname:cdn tag:aofei   | stats count()  as count_2 by appname, cdn.prefix_url ]] | eval per = count_1 / count_2 | limit 10  | eval percent = format(\"%.2f%%\", per * 100) "}
{"input": "直播业务命中率最高节点TOP10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:live.hcs.yottabyte.cn OR cdn.domain:livelimit.lovev.com OR cdn.domain:hlssplive.rizhiyi.com OR  cdn.domain:hlszblive.rizhiyi.com OR cdn.domain:sp.live.rizhiyi.com  OR cdn.domain:yy.live.rizhiyi.com OR cdn.domain:zb.live.rizhiyi.com) | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei   | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100) "}
{"input": "1. 从mfe日志标记为tranlog类型的日志里按 msgid 过滤。取msgNa字段,如果为空则取msgtype字段的值,存储在msgNa字段；2. 格式化sender字段,拼接银行名称sendBankNa,存储在sender字段；3. 统计每个交易请求的次数cnt,以及交易时间timestamp、发起方sender、发起方名称sendName、交易编码msgNa、交易IDmsgid和接收方名称recverName；4. 重命名timestamp为reqTime,表示交易请求时间；5. 左连接同一交易ID的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间；6. 计算交易响应时间与请求时间的差cost,表示交易耗时；7. 格式化交易描述desc,包含发起方名称、发起方和耗时；8. 重命名相关字段。。", "instruction": "在支付清算系统日志里关联借记来账的请求和响应两条日志,计算交易耗时,实现监控系统交易执行情况的场景,最终输出每个交易的请求时间、响应时间、交易编码、发起方、接收方和交易描述。请按下述步骤编写 SPL 语句", "output": "appname:mfe tag:tranlog msgid:${msgid}| eval msgNa=if(empty(msgNa),msgtype,msgNa)| eval sender=format(\"%s_%s\",sender,sendBankNa)| stats count() as cnt by timestamp,sender,sendName,msgNa,msgid,recverName| rename timestamp as reqTime| join type=left msgid [[ appname:mfe tag:tranlog origmsgid:${msgid} | stats count() as cnt by timestamp,origmsgid | rename origmsgid as msgid,timestamp as respTime]]| eval cost=respTime-reqTime| eval desc=format(\"%s::sender:%s_%sms\",sendName,sender,cost)| rename msgNa as tranCode,sendName as send,recverName as recver| fields reqTime,respTime,tranCode,send,recver,desc"}
{"input": "1. 从mps日志中提取指定 msgid 值的日志,取msgNa字段,如果为空则取msgtype字段的值,存储在msgNa字段；2. 取chnlNa字段,如果为空则取chnlcode字段的值,存储在chnlNa字段；3. 取sendBankNa字段,如果为空则取origsender字段的值,存储在sendBankNa字段；4. 统计每个交易请求的次数cnt,以及交易时间timestamp、交易编码msgNa、渠道编码chnlNa、发起方银行sendBankNa、交易IDmsgid和接收系统sysid；5. 重命名timestamp为reqTime,表示交易请求时间；6. 左连接同一交易ID的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间,以及付款方账号payeraccno和响应状态respstatus和响应编码respNa；7. 计算交易响应时间与请求时间的差cost,表示交易耗时；8. 格式化交易描述desc,包含渠道编码、付款方账号、响应状态、响应编码和耗时；9. 重命名相关字段,提取最终结果。", "instruction": "在 mps 日志里关联计算指定 msgid 的交易耗时。请按下列步骤编写语句", "output": "appname:mps msgid:${msgid} | eval msgNa=if(empty(msgNa),msgtype,msgNa) | eval chnlNa=if(empty(chnlNa),chnlcode,chnlNa) | eval sendBankNa=if(empty(sendBankNa),origsender,sendBankNa) | stats count() as cnt by timestamp,msgNa,chnlNa,sendBankNa,msgid,sysid | rename timestamp as reqTime | join type=left msgid [[  appname:mps origmsgid:${msgid}  | stats count() as cnt by timestamp,origmsgid,payeraccno,respstatus,respNa  | rename timestamp as respTime,origmsgid as msgid ]] | eval cost=respTime-reqTime | eval desc=format(\"%s::payeraccno:%s:respstatus:%s_%s_%sms\",chnlNa,payeraccno,respstatus,respNa,cost) | rename msgNa as tranCode,sendBankNa as send,sysid as recver | fields reqTime,respTime,tranCode,send,recver,desc"}
{"input": "1. 从mps日志中提取交易请求日志,交易编码TC为100503s,取otpserialno字段,以及交易时间timestamp、otpserialno、otpdate、付款方账户PmtSdAcctNm、接收系统sysid、流水号workseqid、交易编码TxCd和交易流水seqNo；2. 重命名timestamp为reqTime,表示交易请求时间 ；3. 左连接同一交易流水seqNo的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间,以及响应码rtncode和响应信息rtnmsg；4. 计算交易响应时间与请求时间的差cost,表示交易耗时 ；5. 赋值接收方recver为“渠道”；6. 格式化交易描述desc,包含otpserialno、otpdate、workseqid、parername、rtncode、rtnmsg和耗时。。", "instruction": "在 mps 日志里计算渠道交易的请求和响应耗时。请按如下步骤编写 SPL", "output": "appname:mps seqNo:${seqNo} TC:100503s otpserialno:* | stats count() as cnt by timestamp,otpserialno,otpdate,PmtSdAcctNm,sysid,workseqid,TxCd,seqNo | rename timestamp as reqTime | join type=left seqNo [[  appname:mps seqNo:${seqNo} TC:100503s rtncode:*  | stats count() as cnt by timestamp,seqNo,rtncode,rtnmsg  | rename timestamp as respTime ]] | eval cost=respTime-reqTime | eval recver=\"渠道\" | eval desc=format(\"otpserialno:%s:otpdate:%s:workseqid:%s:parername:%s::rtncode:%s_%s_%sms\",otpserialno,otpdate,workseqid,PmtSdAcctNm,rtncode,rtnmsg,cost) | rename TxCd as tranCode,sysid as send | fields reqTime,respTime,tranCode,send,recver,desc"}
{"input": "1. 从mps日志中提取交易请求日志,交易编码TC为PYS040,取otpserialno、TC、工作序列号workseqid、接收系统sysid和序列号seqNo；2. 重命名timestamp为reqTime,表示交易请求时间；3. 左连接同一序列号seqNo的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间,以及原交易序列号orgserialno、控制日期ctldate、响应码rtncode、响应信息rtnmsg和错误信息errNa；4. 计算交易响应时间与请求时间的差cost,表示交易耗时 ；5. 格式化交易描述desc,包含相关交易信息和响应信息；6. 重命名相关字段。", "instruction": "根据如下要求编写 SPL 语句分析 mps 日志", "output": "appname:mps seqNo:${seqNo} TC:PYS040 otpserialno:* | stats count() as cnt by timestamp,otpserialno,TC,workseqid,sysid,seqNo | rename timestamp as reqTime | join type=left seqNo [[  appname:mps seqNo:${seqNo} TC:PYS040 rtncode:* | eval ctldate=if(empty(ctldate),NULL,ctldate)  | stats count() as cnt by timestamp,ctldate,orgserialno,rtncode,rtnmsg,errNa,TC,seqNo  | rename timestamp as respTime ]] | eval cost=respTime-reqTime | eval recver=\"核心\" | eval desc=format(\"otpserialno:%s:orgserialno:%s:ctldate:%s,workseqid:%s::rtncode:%s_%s_%s_%sms\",otpserialno,orgserialno,ctldate,workseqid,rtncode,rtnmsg,errNa,cost) | rename TC as tranCode,sysid as send | fields reqTime,respTime,tranCode,send,recver,desc"}
{"input": "1. 从esb日志中提取发送方为MPS、服务编码为PYS040的请求日志,取交易时间timestamp、消息编码msgCd、接收方rcvAppCd、发送方sndAppCd和序列号seqNb；2. 重命名timestamp为reqTime,表示交易请求时间；3. 左连接同一序列号seqNb的响应日志,统计响应时间timestamp并重命名为respTime,表示交易响应时间,以及响应码retCd和响应信息retMsg ；4. 计算交易响应时间与请求时间的差cost,表示交易耗时 ；5. 赋值接收方recver为ESB ；6. 格式化交易描述desc,包含序列号和响应信息；7. 重命名相关字段,提取最终结果；8. 使用formatdate函数格式化reqTime和respTime为更详细时间格式。", "instruction": "根据如下要求编写 SPL 语句分析 mps 日志", "output": "appname:esb 'tag':cbs seqNb:${seqNb} SvcCd:PYS040 sndAppCd:MPS | stats count() as cnt by timestamp,msgCd,rcvAppCd,sndAppCd,seqNb | rename timestamp as reqTime | join type=left seqNb [[  appname:esb 'tag':cbs refSeqNb:${seqNb}  | stats count() as cnt by timestamp,refSeqNb,retCd,retMsg  | rename timestamp as respTime,refSeqNb as seqNb ]] | eval cost=respTime-reqTime | eval recver=\"ESB\" | eval desc=format(\"seqNb:%s::retCd:%s_%s_%sms\",seqNb,retCd,retMsg,cost) | rename msgCd as tranCode,sndAppCd as send | fields reqTime,respTime,tranCode,send,recver,desc| eval reqTime=formatdate(reqTime,\"yy-MM-dd HH:mm:ss.SSS\")| eval respTime=formatdate(respTime,\"yy-MM-dd HH:mm:ss.SSS\")"}
{"input": "1. 从esb日志中提取发送方为MPS、服务编码为PYS040的请求日志,取交易时间timestamp、消息编码msgCd、接收方rcvAppCd、发送方sndAppCd和序列号seqNb ；2. 重命名timestamp为reqTime,表示交易请求时间 ；3. 左连接同一序列号seqNb的响应日志,统计响应时间timestamp并重命名为rspTime,表示交易响应时间,以及响应码retCd和响应信息retMsg ；4. 计算交易响应时间与请求时间的差cost,表示交易耗时；5. 赋值接收方recver为ESB；6. 格式化交易描述desc,包含序列号和响应信息；7. 重命名相关字段。", "instruction": "根据如下要求编写 SPL 语句分析 mps 日志", "output": "appname:esb 'tag':cbs seqNb:${seqNb} SvcCd:PYS040 sndAppCd:MPS | stats count() as cnt by timestamp,msgCd,rcvAppCd,sndAppCd,seqNb | rename timestamp as reqTime | join type=left seqNb [[  appname:esb 'tag':cbs refSeqNb:${seqNb}  | stats count() as cnt by timestamp,refSeqNb,retCd,retMsg  | rename timestamp as rspTime,refSeqNb as seqNb ]] | eval cost=rspTime-reqTime | eval recver=\"ESB\" | eval desc=format(\"seqNb:%s::retCd:%s_%s_%sms\",seqNb,retCd,retMsg,cost) | rename reqTime as time,msgCd as tranCode,sndAppCd as send | fields time,tranCode,send,recver,desc"}
{"input": "点播业务命中率最低节点TOP10。点播域名包括：vod.hcs.yottabyte.cn, hlsspvod.rizhiyi.com, sp.vod.rizhiyi.com, hlszbvod.rizhiyi.com。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:vod.hcs.yottabyte.cn OR cdn.domain:hlsspvod.rizhiyi.com OR  cdn.domain:sp.vod.rizhiyi.com OR cdn.domain:hlszbvod.rizhiyi.com)  | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei    | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2 | sort by +per| limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "图片业务命中率最低节点TOP10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:wapx.yottabyte.cn OR cdn.domain:img.yottabyte.cn OR  cdn.domain:yy0.tv.yottabyte.cn OR cdn.domain:yy1.tv.yottabyte.cn OR cdn.domain:yy2.tv.yottabyte.cn)  | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei   | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2|sort  by per | limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "先搜索 Accepted password for 日志，按ip,hostname,audit.msg.user,audit.msg.src_ip,audit.msg.src_port,audit.msg.pid,timestamp分组统计。然后搜索 sessin closed for 日志，按 ip,hostname,audit.msg.pid,audit.msg.user,timestamp统计结果，用ip,audit.msg.user,audit.msg.pid字段做关联两个查询的结果。将 closed 日志的时间命名为 logout_time，accepted 日志的时间命名为 login_time，二者相减，得到在线时间。最后将在线时间从毫秒转为分钟，登录时间和登出时间转为人类可读格式。索引可用字段有：audit.MACHINE, audit.OSUSER, audit.PROGRAM, audit.SQL_ID, audit.SQL_TEXT, audit.USERNAME, audit.command, audit.msg.cmd, audit.msg.command, audit.msg.exec_time, audit.msg.info, audit.msg.path, audit.msg.pid, audit.msg.pwd, audit.msg.rhost, audit.msg.ruser, audit.msg.ser, audit.msg.src_ip, audit.msg.src_port, audit.msg.user, audit.up_time, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "linux_当天ssh登录成功详情", "output": "starttime=\"now/d\" appname:audit  AND audit.msg.ser:sshd AND \"Accepted password for\" | stats count() as login by ip,hostname,audit.msg.user,audit.msg.src_ip,audit.msg.src_port,audit.msg.pid,timestamp  | rename timestamp as login_time  | sort by login_time | join type=left ip,audit.msg.user,audit.msg.pid  [[  appname:audit AND audit.msg.ser:sshd AND (\"session closed for\") | stats count() as logout by ip,hostname,audit.msg.pid,audit.msg.user,timestamp  | rename timestamp as logout_time  | sort by logout_time ]]  | eval dura=format(\"%.2f分钟\",(logout_time-login_time)/60000)  | eval login_time=formatdate(login_time)  | eval logout_time=formatdate(logout_time) "}
{"input": "索引可用字段有：audit.MACHINE, audit.OSUSER, audit.PROGRAM, audit.SQL_ID, audit.SQL_TEXT, audit.USERNAME, audit.command, audit.msg.cmd, audit.msg.command, audit.msg.exec_time, audit.msg.info, audit.msg.path, audit.msg.pid, audit.msg.pwd, audit.msg.rhost, audit.msg.ruser, audit.msg.ser, audit.msg.src_ip, audit.msg.src_port, audit.msg.user, audit.up_time, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "ssh登录详情", "output": "appname:audit  AND audit.msg.ser:sshd AND \"Accepted password for\" | stats count() as login by ip,hostname,audit.msg.user,audit.msg.src_ip,audit.msg.src_port,audit.msg.pid,timestamp | rename timestamp as login_time | join type=left audit.msg.user,audit.msg.pid [[ appname:audit AND audit.msg.ser:sshd AND (\"session closed for\") | stats count() as logout by ip,hostname,audit.msg.pid,audit.msg.user,timestamp | rename timestamp as logout_time ]] | sort by login_time | eval dura=format(\"%.2f分钟\",(logout_time-login_time)/60000) | eval login_time=formatdate(login_time) | eval logout_time=formatdate(logout_time) "}
{"input": "ssh登录详情。索引可用字段有：audit.MACHINE, audit.OSUSER, audit.PROGRAM, audit.SQL_ID, audit.SQL_TEXT, audit.USERNAME, audit.command, audit.msg.cmd, audit.msg.command, audit.msg.exec_time, audit.msg.info, audit.msg.path, audit.msg.pid, audit.msg.pwd, audit.msg.rhost, audit.msg.ruser, audit.msg.ser, audit.msg.src_ip, audit.msg.src_port, audit.msg.user, audit.up_time, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "linux审计数据，编写查询语句实现如下分析场景", "output": "appname:audit  AND audit.msg.ser:sshd AND \"Accepted password for\" | stats count() as login by ip,hostname,audit.msg.user,audit.msg.src_ip,audit.msg.src_port,audit.msg.pid,timestamp | rename timestamp as login_time | join type=left audit.msg.user,audit.msg.pid [[ appname:audit AND audit.msg.ser:sshd AND (\"session closed for\") | stats count() as logout by ip,hostname,audit.msg.pid,audit.msg.user,timestamp | rename timestamp as logout_time ]] | sort by login_time | eval dura=format(\"%.2f分钟\",(logout_time-login_time)/60000) | eval login_time=formatdate(login_time) | eval logout_time=formatdate(logout_time) "}
{"input": "最近5分钟网络设备端口MTU。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "starttime=\"now-5m\" endtime=\"now\" appname:switchperf AND switchperf.type:ifMtu | eval MTU=tolong(switchperf.value)  | stats avg(MTU) as MTU by switchperf.devip,switchperf.ifindex\n| join type=left switchperf.ifindex [[starttime=\"now-5m\" endtime=\"now\" appname:switchperf AND switchperf.type:ifDescr | stats count() by switchperf.ifindex,switchperf.value]] \n| rename switchperf.value as ifdescr | sort by MTU,+switchperf.ifindex"}
{"input": "请求失败日志中，按 30 分钟趋势统计访问量前 5 名应用的平均请求时长。索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": " (appname:apache tag:access middleware.status:>399)  |bucket timestamp span=30m as ts |stats avg(middleware.req_time) as avg_ by appname, ts |join type=inner appname [[ (appname:apache tag:access middleware.status:>399)  |stats count() as count_ by appname |sort by count_ |limit 5 ]]"}
{"input": "请求状态码异常次数最大的前 5 个 appname，按 30 分钟统计请求量和平均请求时长。索引可用字段有：waf.action, waf.attack_name, waf.attack_type, waf.bytes_in, waf.cost, waf.cve_id, waf.dst_city, waf.dst_domain, waf.dst_ip, waf.dst_latitude, waf.dst_longitude, waf.dst_port, waf.error_msg, waf.event_level, waf.event_log_level, waf.event_name, waf.event_type, waf.http_method, waf.http_refer, waf.is_truncated, waf.kv.Evt_level, waf.kv.Evt_type, waf.kv.event_name, waf.kv.http_method, waf.kv.http_refer, waf.kv.http_url, waf.kv.msg, waf.kv.owasp_top, waf.kv.pri, waf.kv.severity_level, waf.kv.status, waf.kv.type, waf.level, waf.log_category, waf.message, waf.message.action, waf.message.event, waf.message.method, waf.message.policy, waf.message.src_ip.geo.ip, waf.message.src_ip.geo.province, waf.message.src_port, waf.message.status, waf.message.threaten, waf.method, waf.module, waf.msg.act, waf.msg.cs, waf.msg.policy_id, waf.msg.src.geo.country, waf.policy_name, waf.proto, waf.referer, waf.risk_level, waf.severity, waf.src.geo.city, waf.src.geo.country, waf.src.geo.ip, waf.src.geo.isp, waf.src.geo.latitude, waf.src.geo.longitude, waf.src.geo.province, waf.src_ip, waf.src_port, waf.status, waf.status_code, waf.threat_level, waf.time, waf.ua_browser, waf.ua_device, waf.ua_os, waf.uri, waf.url, waf.user_agent.browser, waf.user_agent.os, waf.website_name, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": " (appname:waf tag:river waf.status_code:>399)  |bucket timestamp span=30m as ts |stats avg(waf.cost) as avg_ by appname, ts |join type=inner appname [[ (appname:waf tag:river waf.status_code:>399)  |stats count() as count_ by appname |sort by count_ |limit 5 ]]"}
{"input": "分应用名统计请求数和字节数流量，按 20 秒趋势统计。", "instruction": "nginx数据，编写查询语句实现如下分析场景", "output": "(appname:nginx)  |bucket timestamp span=20s as ts |stats sum(middleware.bytes) as ct by appname, ts |join type=inner appname [[ (appname:nginx)  |stats count() as count_ by appname |sort by count_ |limit 5 ]]"}
{"input": "dell防火墙msg占比前 10 名。索引可用字段有：mongodb.action, mongodb.component, mongodb.cost, mongodb.desc, mongodb.msg, mongodb.namespace, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "dell防火墙日志数据，编写查询语句实现如下分析场景", "output": "tag:dell|stats count() as count_2 by firewall.msg,appname\n|join type=left appname\n[[\ntag:dell| stats count() as count_1 by appname\n]]\n|sort by count_2\n|limit 10\n|eval percent1=(count_2/count_1)*100\n|eval percent=format(\"%.2f%%\",percent1)\n|eval bbb=firewall.msg+\"_\"+count_2+\"条_\"+percent"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux操作系统审计_ssh登录详情", "output": "appname:linux tag:secure AND type:sshd AND \"Accepted password for\"  |stats count() as login by ip,hostname,user,src_ip,src_port,pid,timestamp  |rename timestamp as login_time  |join type=left user,pid [[  appname:linux tag:secure AND type:sshd AND \"session closed for\"  |stats count() as logout by ip,hostname,pid,user,timestamp  |rename timestamp as logout_time ]]  |sort by login_time  |eval dura=format(\"%.2f分钟\",(logout_time-login_time)/60000)  |eval login_time=formatdate(login_time)  |eval logout_time=formatdate(logout_time) "}
{"input": "索引可用字段有：aix.class_dec, aix.dst_host, aix.facility, aix.login_time, aix.login_way, aix.net, aix.resource_name, aix.severity, aix.span_h, aix.span_m, aix.src_ip, aix.src_port, aix.type, aix.type_dec, aix.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "aix登录异常用户_30天没有登录但今天突然登录", "output": "appname:aix tag:last| stats count(hostname) as count_1 by hostname,aix.user,aix.type,aix.span_h,aix.span_m,aix.src_ip,timestamp|eval ts=formatdate(timestamp) |join type=left aix.user [[starttime = \"now/d-31d\" endtime = \"now/d-1d\" appname:aix tag:last| stats count(hostname) as count_2 by hostname,aix.user ]] |eval aaa=if(empty(count_2),0,1) |where aaa<1  |eval span_h=(todouble(aix.span_h))*3600 |eval span_m=(todouble(aix.span_m))*60 |eval login_cost=span_h+span_m  |sort by login_cost"}
{"input": "登录异常用户_30天没有登录但今天突然登录。索引可用字段有：aix.class_dec, aix.dst_host, aix.facility, aix.login_time, aix.login_way, aix.net, aix.resource_name, aix.severity, aix.span_h, aix.span_m, aix.src_ip, aix.src_port, aix.type, aix.type_dec, aix.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "aix日志数据，编写查询语句实现如下分析场景", "output": "appname:aix tag:last| stats count(hostname) as count_1 by hostname,aix.user,aix.type,aix.span_h,aix.span_m,aix.src_ip,timestamp|eval ts=formatdate(timestamp)\n|join type=left aix.user\n[[starttime = \"now/d-31d\" endtime = \"now/d-1d\" appname:aix tag:last| stats count(hostname) as count_2 by hostname,aix.user ]]\n|eval aaa=if(empty(count_2),0,1)\n|where aaa<1\n\n|eval span_h=(todouble(aix.span_h))*3600\n|eval span_m=(todouble(aix.span_m))*60\n|eval login_cost=span_h+span_m\n\n|sort by login_cost\n"}
{"input": "CDN命中率最低节点top10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei   | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100) | sort by +per "}
{"input": "aofei_cdn命中率最低资源TOP10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "奥飞CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by appname, cdn.prefix_url | join type = left appname [[ \nappname:cdn tag:aofei   | stats count()  as count_2 by appname, cdn.prefix_url ]] | eval per = count_1 / count_2 | limit 10  | eval percent = format(\"%.2f%%\", per * 100) | sort by +per "}
{"input": "直播业务命中率最低节点TOP10。索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "华为CDN数据，编写查询语句实现如下分析场景", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:live.hcs.yottabyte.cn OR cdn.domain:livelimit.lovev.com OR cdn.domain:hlssplive.rizhiyi.com OR  cdn.domain:hlszblive.rizhiyi.com OR cdn.domain:sp.live.rizhiyi.com  OR cdn.domain:yy.live.rizhiyi.com OR cdn.domain:zb.live.rizhiyi.com) | stats count()  as count_1 by tag | join type = left tag [[ \nappname:cdn tag:huawei    | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2 | sort by +per| limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，在公司里使用过哪些WIFI? 并且这些WIFI的名称、信号强度、时间等信息都能告诉我。", "output": "appname:ac tag:h3c ac.status:online | table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid|rename ac.* as *|rename timestamp as time1,time as online_time|sort by cnt|join type=inner client,ap_name[[ appname:ac tag:h3c ac.status:offline  | table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid |rename ac.* as * |rename timestamp as time2,time as offline_time |sort by cnt]]|eval time3=time2-time1|where time3>=0|stats count(client) as cnt,dc(ap_name) as apcnt,dc(ssid) as sscnt by client|sort by cnt|limit 10|rename client as \"客户端\",cnt as \"频繁连接掉线次数\",apcnt as \"连接AP数量\",sscnt as \"连接ssid数量\""}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，过去一天中有多少次访问了使用华为CDN的网站或者图片资源吗？请帮忙把这些数据统计出来并按比例展示在界面上。", "output": "appname:cdn tag:huawei   AND cdn.cdn_status:*HIT  AND (cdn.domain:wapx.yottabyte.cn OR cdn.domain:img.yottabyte.cn OR  cdn.domain:yy0.tv.yottabyte.cn OR cdn.domain:yy1.tv.yottabyte.cn OR cdn.domain:yy2.tv.yottabyte.cn)  | stats count()  as count_1 by tag | join type = left tag [[ appname:cdn tag:huawei  | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，有没有人从公司的服务器上登录过cron服务呢？如果有的话，他们使用哪些命令呢？", "output": "appname:linux tag:crond event_name:定时任务事件 |stats count() as ct by ip,user,command |eval total=ip+\"_\"+user+\"_\"+command |eval total_md5=md5(total) |rename ip as today_ip,user as today_user,command as today_command | join type=left total_md5 [[ |inputlookup cron_list.csv | eval total_md5=md5(total) ]] |fields total_md5,today_ip,today_user,today_command,command,ct |eval command=if(empty(command),\"该条记录不在定时任务列表中\",command)"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想询问关于aofei CDN供应商的访问量和错误率的信息，具体来说，需要了解以下几个方面：1. 在最近一段时间内（例如过去7天）对的网站进行了多少次访问；2. 在这些访问中，有多少次导致了错误或失败（HTTP状态码不为200），以及这类错误发生的比例是多于其他状态吗？", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT  | stats count()  as _count_1 by appname | join type = left appname [[ appname:cdn tag:aofei   | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在某一天的视频播放量中，哪个CDN节点的带宽占比较高。请告诉我这些信息。", "output": "appname:cdn tag:aofei(cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:aofei  (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在某一天中，同样的视频域名有几个被访问到了。请告诉我这些域名的数量占比如何。", "output": "appname:cdn tag:aofei(cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:aofei  (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在某一天中，使用华为CDN的网站有多少个。", "output": "appname:cdn tag:huawei (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:huawei    (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在某一天的使用华为CDN服务的网站有哪些？请告诉我这些网站的数量和访问量分别是多少。", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:huawei   (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)| stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在某一天的访问量中，有多少来自于华为的网站。你能帮我把这个问题翻译成日志易查询吗？", "output": "appname:cdn tag:huawei (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn)AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:huawei    (cdn.domain:wapx.example.cn OR cdn.domain:img.example.cn OR  cdn.domain:tv.example.cn) | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "", "instruction": "我想问的是，有几位同学使用了 Sangfor VPN 服务登录到学校的网络系统呢？你能不能告诉我这些同学在哪些地区和城市进行了登录吗？", "output": "(* AND appname:vpn) AND 'tag':sangfor vpn.actype:access\\ resource [[ (* AND appname:vpn) AND 'tag':sangfor vpn.actype:login NOT vpn.src.geo.province:private  |stats count() by vpn.login_user  |fields vpn.login_user]]  |eval time = formatdate(timestamp) |table time,vpn.login_user,vpn.src.geo.ip,vpn.dst_ip,vpn.dst_port,vpn.proto |join type = inner vpn.login_user[[ (* AND appname:vpn) AND 'tag':sangfor vpn.actype:login NOT vpn.src.geo.province:private  |stats count() by vpn.login_user,vpn.src.geo.ip,vpn.src.geo.province,vpn.src.geo.city |rename vpn.src.geo.ip as ip |fields ip,vpn.login_user,vpn.src.geo.province,vpn.src.geo.city]] |rename time as \"时间\",vpn.login_user as \"用户\",vpn.src.geo.ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.proto as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\" |limit 5"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，CDN服务商为华为云的网站提供的HTTP状态码分别是多少？", "output": "appname:cdn tag:huawei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 ) | stats count() as _count_1 by tag,cdn.http_status | join type = left tag [[ appname:huawei    |  stats count() as _count_2 by tag   ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"直播次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，访问量最高的那个网站有哪些文件被盗走了吗？请帮我把这些文件的名字列出来。", "output": "appname:apache tag:access | stats count() as cnt by middleware.clientip | rename middleware.clientip as src_ip |join src_ip[[appname:dlp tag:websense|rename dlp.src_ip as src_ip | stats count() as cnt by src_ip,dlp.file_name]] | limit 10"}
{"input": "", "instruction": "我想问的是：公司的VPN登录人数有变化吗？具体哪些地区的人数变多或少？这些IP地址和他们所在的位置有关系么？", "output": "(* AND appname:vpn) AND 'tag':cisco vpn.actype:access\\ resource [[ (* AND appname:vpn) AND 'tag':cisco vpn.actype:login NOT vpn.src.geo.province:private  |stats count() by vpn.login_user  |fields vpn.login_user]] |eval time = formatdate(timestamp)|table time,vpn.login_user,vpn.src.geo.ip,vpn.dst_ip,vpn.dst_port,vpn.proto|join type = inner vpn.login_user[[  (* AND appname:vpn) AND 'tag':cisco vpn.actype:login NOT vpn.src.geo.province:private  |stats count() by vpn.login_user,vpn.src.geo.ip,vpn.src.geo.province,vpn.src.geo.city |rename vpn.src.geo.ip as ip |fields ip,vpn.login_user,vpn.src.geo.province,vpn.src.geo.city]]|rename time as \"时间\",vpn.login_user as \"用户\",vpn.src.geo.ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.proto as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\"|limit 50"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，CDN服务出现问题的概率有多大？你能不能把这个时间段内所有HTTP错误码都列举出来吗？", "output": "appname:cdn tag:huawei AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 )  AND (cdn.domain:vod1.video.com OR cdn.domain:vod2.video.com OR  cdn.domain:vod3.video.com OR cdn.domain:vod4.video.com)  |  stats count() as _count_1 by tag,cdn.http_status | join type =  left tag [[ appname:huawei    |  stats count() as _count_2 by tag   ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100) | rename tag as \"节点名称\", cdn.http_status as \"状态码\", _count_1 as \"命中次数\", _count_2 as \"访问次数\", percent as \"百分比\""}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，访问量中，有多少是和华为相关的？并且这些访问占比是上一天的几倍吗？", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:wapx.yottabyte.cn OR cdn.domain:img.yottabyte.cn OR  cdn.domain:yy0.tv.yottabyte.cn OR cdn.domain:yy1.tv.yottabyte.cn OR cdn.domain:yy2.tv.yottabyte.cn)  | stats count()  as count_1 by tag | join type = left tag [[ appname:cdn tag:huawei   | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2|sort  by per | limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，有多少用户访问了使用华为CDN的网站，并且能够命中缓存。", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by tag | join type = left tag [[ appname:cdn tag:huawei   | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100) | sort by +per "}
{"input": "", "instruction": "我想问的是，在 npm 和 apm 中分别有哪些用户访问过我的网站？请列出所有 IP 地址和他们的访问时间。", "output": "*  appname:npm grg.src_ip:*|eval time=formatdate(timestamp,\"HH:mm\")| table time,grg.src_ip,grg.dst_ip,grg.message.total_bytes|rename grg.dst_ip as host|join type=inner host[[ *   appname:apm  |eval time1=formatdate(timestamp,\"HH:mm\") | table time1,grg.src_ip,grg.host.hostname,grg.process.title,grg.process.pid |rename grg.src_ip as host]]|rename grg.src_ip as \"源地址\",host as \"目的地址\",time as \"流量监测时间\",time1 as \"apm监测时间\",grg.host.hostname as  \"主机名\",grg.process.title as \"程序名\",grg.process.pid as \"程序PID\""}
{"input": "索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，某台设备的丢包率和总发送量之比是多少？你能帮我把这个问题转化为日志易查询吗？", "output": "appname:switchperf AND (switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts OR switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.type,switchperf.ifindex | eval totalpkts=_max-_min | stats sum(totalpkts) as _total| eval data=\"discards_ratio\"| join data  [[appname:switchperf AND (switchperf.type:ifInDiscards OR switchperf.type:ifOutDiscards) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.type,switchperf.ifindex | eval totaldiscards=_max-_min | stats sum(totaldiscards) as _discards| eval data=\"discards_ratio\"]] | eval discards_ratio=_discards/_total"}
{"input": "索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "错误包占比多少？", "output": "appname:switchperf AND (switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts OR switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.devip,switchperf.type,switchperf.ifindex | eval totalpkts=_max-_min | stats sum(totalpkts) as _total| eval  data=\"errors_ratio\"| join data  [[appname:switchperf AND (switchperf.type:ifInErrors OR switchperf.type:ifOutErrors) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.devip,switchperf.type,switchperf.ifindex | eval totalerrors=_max-_min | stats sum(totalerrors) as _errors| eval data=\"errors_ratio\"]] | eval errors_ratio=_errors/_total"}
{"input": "索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "丢包率是多少？请再把结果打印出来。我想看一下具体的数据。这个结果有点长，可以考虑换行显示或者截断展示中间部分。", "output": "appname:switchperf AND (switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts OR switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.type,switchperf.ifindex | eval totalpkts=_max-_min | stats sum(totalpkts) as _total| eval data=\"discards_ratio\"| join data  [[appname:switchperf AND (switchperf.type:ifInDiscards OR switchperf.type:ifOutDiscards) | stats max(switchperf.value) as _max,min(switchperf.value) as _min by switchperf.type,switchperf.ifindex | eval totaldiscards=_max-_min | stats sum(totaldiscards) as _discards| eval data=\"discards_ratio\"]] | eval discards_ratio=_discards/_total"}
{"input": "索引可用字段有：kafka.count_partition, kafka.count_topic, kafka.event_name, kafka.event_type, kafka.lag, kafka.partition, kafka.reson, kafka.topic, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道 Kafka 应用的性能问题所在。我认为它可能与滞后时间有关，因此我想要查看每个主题的滞后时间总和以及它们所属分区的数量。", "output": "appname:kafka tag:performance| stats sum(kafka.lag) as lag by kafka.topic|join type=left kafka.topic [[appname:kafka tag:cnt_topic kafka.count_partition:*|table kafka.topic,kafka.count_partition]]"}
{"input": "索引可用字段有：windows.EventData.Data, windows.IpAddress, windows.System.EventID.text, windows.System.Level, windows.System.Provider.Name, windows.event_type, windows.level, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，我的电脑上有哪些正在与外网通信的进程？可以给出最新的二十条记录吗？这些进程中，除了自己的程序之外，还有谁在使用网络呢？", "output": "appname:windows tag:process process.local_addr:* process.proto:TCP process.state:ESTABLISHED |limit 20 | table process.foreign_addr,process.foreign_port,process.local_addr,process.local_port,process.pid|rename process.pid as pid |join type = left pid [[tag:tasklist |table tasklist.pid,tasklist.taskname|rename tasklist.pid as pid]] |rename process.foreign_addr as foreign_addr,process.foreign_port as foreign_port,process.local_addr as local_addr,process.local_port as local_port,tasklist.taskname as taskname"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，在 Linux 系统中，有哪些安全相关的事件会涉及到用户管理呢？比如用户创建、修改或删除等操作。你能否列举一些例子吗？", "output": "appname:linux tag:secure event_name:创建用户事件 |table timestamp,ip,user |rename timestamp as ctime  |join type=left ip,user [[ appname:linux tag:secure event_name:删除用户事件 |table timestamp,ip,user |rename timestamp as dtime ]] |eval cost=(dtime-ctime)/1000 |eval createtime=formatdate(ctime,\"HH:mm:ss\") |eval deletetime=formatdate(dtime,\"HH:mm:ss\") |fields ip,user,createtime,deletetime,cost |rename ip as \"主机IP\",user as \"用户\",createtime as \"用户创建时间\",deletetime as \"用户删除时间\",cost as \"用户存在时长(秒)\""}
{"input": "索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道在新华三的 AC 中，有多少人在同一时间段内都处于联网状态和离线状态。请告诉我这个统计的时间段是多久？", "output": "appname:ac tag:h3c ac.status:onlineac.client:${client} | table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid|rename ac.* as *|rename timestamp as time1,time as online_time|sort by cnt|join type=inner client,ap_name[[ appname:ac tag:h3c ac.status:offline  | table ac.time,timestamp,ac.client,ac.ap_name,ac.ssid |rename ac.* as * |rename timestamp as time2,time as offline_time |sort by cnt]]|eval time3=(time2-time1)/1000|where time3>=0|fields online_time,offline_time,client,appname,ssid,time3|rename online_time as \"上线时间\",offline_time as \"下线时间\",client as \"客户端\",time3 as \"登录时长/s\""}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，在过去一小时内，有多少次请求中包含了“huawei”这个标签和“cdn”这个应用名，同时又满足以下条件：访问的域名为 vod.hcs.yottabyte.cn、hlsspvod.rizhiyi.com、sp.vod.rizhiyi.com 和 hlszbvod.rizhiyi.com 中的任意一个。", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  AND (cdn.domain:vod.hcs.yottabyte.cn OR cdn.domain:hlsspvod.rizhiyi.com OR  cdn.domain:sp.vod.rizhiyi.com OR cdn.domain:hlszbvod.rizhiyi.com)  | stats count()  as count_1 by tag | join type = left tag [[ appname:cdn tag:huawei    | stats count()  as count_2 by tag ]]| eval per = count_1 / count_2| limit 10  | eval percent = format(\"%.2f%%\", per * 100)  "}
{"input": "索引可用字段有：vpn.action, vpn.actor.displayName, vpn.actype, vpn.app.upstream.host, vpn.app.upstream.port, vpn.app.web.request.url, vpn.auth_dst, vpn.dst.geo.city, vpn.dst.geo.country, vpn.dst.geo.ip, vpn.dst.geo.isp, vpn.dst.geo.latitude, vpn.dst.geo.longitude, vpn.dst.geo.province, vpn.dst_ip, vpn.dst_nt_host, vpn.dst_port, vpn.event_level, vpn.event_name, vpn.kv.dst.geo.country, vpn.kv.dst.geo.latitude, vpn.kv.dst.geo.longitude, vpn.kv.msg, vpn.kv.proto, vpn.kv.src.geo.city, vpn.kv.src.geo.country, vpn.kv.src.geo.latitude, vpn.kv.src.geo.longitude, vpn.kv.user, vpn.login_user, vpn.msg, vpn.msg.virtual_ip, vpn.proto, vpn.reason, vpn.resource_name, vpn.result, vpn.seconds, vpn.src._ip, vpn.src.geo.city, vpn.src.geo.country, vpn.src.geo.ip, vpn.src.geo.isp, vpn.src.geo.latitude, vpn.src.geo.longitude, vpn.src.geo.province, vpn.src_ip, vpn.src_ip.geo.city, vpn.src_ip.geo.country, vpn.src_port, vpn.state, vpn.target.displayName, vpn.time, vpn.transport, vpn.user, vpn.user_name, vpn.vpn.login_user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是 VPN 用户在使用过程中是否进行认证，并且过滤掉私有网络的访问记录。", "output": "appname:vpn tag:cisco (NOT \"authentication\") AND (NOT vpn.src.geo.province:private ) AND vpn.user:*|eval time = formatdate(timestamp)|table time,vpn.user,vpn.src._ip,vpn.dst_ip,vpn.dst_port,vpn.transport|join type = inner vpn.user[[ appname:vpn tag:cisco (\"authentication\") AND (NOT vpn.src.geo.province:private )  |stats count() by vpn.user,vpn.src_ip,vpn.src.geo.province,vpn.src.geo.city |fields vpn.src_ip,vpn.user,vpn.src.geo.province,vpn.src.geo.city]]|rename time as \"时间\",vpn.user as \"用户\",vpn.src_ip as \"源地址\",vpn.dst_ip as \"目的地址\",vpn.dst_port as \"目的端口\",vpn.transport as \"协议\",vpn.src.geo.province as \"省份\",vpn.src.geo.city as \"城市\"|limit 50"}
{"input": "索引可用字段有：switch.IP, switch.action, switch.auth_method, switch.bandwidth, switch.brief, switch.cmd, switch.count, switch.desc, switch.desc.cmd, switch.desc.user, switch.describe, switch.ethernet, switch.event_type, switch.facility, switch.host, switch.host_ip, switch.interface_name, switch.ip, switch.kv.COMMAND, switch.kv.TTY, switch.kv.USER, switch.kvmsg.IpAddress, switch.kvmsg.UserName, switch.level, switch.log_message, switch.log_type, switch.login_method, switch.mode, switch.module, switch.port, switch.port_channel, switch.reason, switch.result, switch.severity, switch.speed, switch.src_ip, switch.src_mac, switch.state, switch.terminal, switch.time, switch.user, switch.vlan, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道在 Huawei 这个应用中，有多少个严重等级为 3 以上的问题。", "output": "appname:switch tag:huawei | stats count() as count_ by switch.severity | eval tmp=switch.severity*count_|join type=left switch.severity [[ appname:switch tag:huawei switch.severity:>3 | stats count() as count1 by switch.severity  | eval tmp=switch.severity*count1]]|stats sum(count_) as sum_,sum(count1) as sum1|eval health=(sum1)/sum_"}
{"input": "索引可用字段有：exchange.client_hostname, exchange.clientip.geo.ip, exchange.dst.geo.city, exchange.dst.geo.country, exchange.dst_ip, exchange.event_id, exchange.message_subject, exchange.recipient_address, exchange.recipient_count, exchange.recipient_status, exchange.sender_address, exchange.server_hostname, exchange.source, exchange.src_ip, exchange.status, exchange.total_bytes, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "应用在“前台”标签下的总访问量以及在该标签下返回状态码为“200”的访问量的信息。", "output": "appname:exchange tag:front  |stats count()  as count_all | eval a=1 | join type=left a  [[ appname:exchange tag:front  AND exchange.status:200 | stats count() as count_200 | eval a=1 ]] | eval cnt_all = tolong(count_all) | eval cnt_200=tolong(count_200) | eval rate=if(empty(cnt_200),0,cnt_200/cnt_all) |eval rate=format(\"%.4f\",rate) |fields rate"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道当你在做什么的时候，你会出现在哪些系统的安全审计报告中呢？你可以把你的操作记录留下来吗？", "output": "appname:linux tag:secure event_name:创建用户事件 |table timestamp,ip,user |join type=left ip,user [[ appname:linux tag:secure event_name:删除用户事件 |table timestamp,ip,user ]] |stats count() as cnt  "}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问关于CDN服务的访问量和错误率的信息。我的推理结果为：寻找与您的应用名称为“cdn”且标记包含“aofei”的记录，并希望了解它们之间的关联性。此外，您还要求了解这些记录的状态是否为成功（*HIT）。在执行这项搜索时，我使用了stats命令将所有相关字段聚合到一行中，以便于进一步分析。接下来，我使用join命令将原始数据与该应用的所有其他记录进行匹配，但是只保留具有相同应用名称的那些记录。通过对比两个计数器的值，可以计算出每个应用的成功率。最后，我使用eval命令将两个计数器值相除，从而得到每种应用的平均成功率。", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT  | stats count()  as _count_1 by appname | join type = left appname [[ appname:cdn tag:aofei | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是：有哪些域名的视频流量使用了您的服务？请列出所有带有“aofei”标签且访问了您提供的CDN服务的网站和应用名称。", "output": "appname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:aofei     (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在某些视频直播平台上，有哪些使用了您的服务的网站。您能帮我列出它们吗？", "output": "appname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:aofei (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问有关 CDN 和华为产品的访问量和流量比例", "output": "appname:cdn tag:huawei  AND cdn.cdn_status:*HIT  | stats count() as _count_1 by appname | join type = left appname [[ appname:cdn tag:huawei    | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，你在做什么呢？你的界面上显示的东西让人很困惑。你可以把它清除一番吗？", "output": "appname:cdn tag:huawei  (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com) AND cdn.cdn_status:*HIT | stats count()  as _count_1 by appname| join type = left appname [[ appname:cdn tag:huawei    (cdn.domain:live1.video.cn OR cdn:domain:live2.video.com OR live3.video.com)  | stats count()  as _count_2 by appname ]]| eval per = _count_1 / _count_2"}
{"input": "", "instruction": "我想问的是：在有多少人访问了哪些网站，以及他们的登录帐号、来自哪里的 IP 地址和访问的目标页面（比如数据库名+表名）等信息。", "output": "appname:h_2 tag:h_2 | stats count() as cnt by h_1.uri,h_1.database_user,h_1.database_name,h_1.table_name|rename h_1.uri as url | join url[[ appname:apache tag:access | rename middleware.referer as url  |stats count() as cnt1 by url,middleware.clientip ]] | rename url as uri |lookup desc,u_ip h_url.csv on uri=url| fields url,h_1.database_user,middleware.clientip,desc,u_ip,h_1.database_name,h_1.table_name,cnt| rename h_1.database_user as \"用户\",middleware.clientip as \"源地址\",desc as \"系统名称\",u_ip as \"系统IP\",h_1.database_name as \"数据库名\",h_1.table_name as \"敏感表表名\""}
{"input": "", "instruction": "我想知道网站 zsns 下有哪些 Tomcat 服务的请求和相应时间间隔最长的一条记录。请帮忙把这些信息打印出来。", "output": "appname:zsns tomcat.event_type:*请求报文tomcat.event_type:*${type}*| stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp|rename timestamp as t1|join tomcat.service.head.origCstSeqNo [[ appname:zsns tomcat.event_type:*响应报文 | stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp |rename timestamp as t2]]| eval cost= tolong(t2)-tolong(t1)|stats max(cost) as max_cost"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "直播业务在全部 CDN 业务里的占比", "output": "appname:cdn AND (cdn.http_status:404 OR cdn.http_status:5?? OR cdn.http_status:403 OR cdn.http_status:200 OR cdn.http_status:206 )  AND (cdn.domain:live1.video.com OR cdn.domain:live2.video.com OR cdn.domain:live3.video.com) |  stats count() as _count_1 by hostname,cdn.http_status  | join type = left hostname [[ appname:cdn | stats count() as _count_2 by hostname ]] | eval percent = format(\"%.2f%%\", _count_1 / _count_2 * 100)"}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问关于某CDN服务的访问量和错误率的信息，具体来说，您需要了解以下几个方面：1. 某CDN服务在某个时间段内的总请求数量、成功请求数量、失败请求数量等统计信息；2. 某CDN服务在某个时间段内的各个URL的响应速度分布情况（即RTT）；3. 在某CDN服务中不同应用或业务类型的错误率分布状况。", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by appname, cdn.prefix_url | join type = left appname [[ appname:cdn tag:aofei   | stats count()  as count_2 by appname, cdn.prefix_url ]] | eval per = count_1 / count_2 | limit 10  | eval percent = format(\"%.2f%%\", per * 100) "}
{"input": "索引可用字段有：mongodb.action, mongodb.component, mongodb.cost, mongodb.desc, mongodb.msg, mongodb.namespace, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问有关Dell设备的访问记录和应用数量的信息，并且希望从中找出最常用的十个应用。", "output": "tag:dell|stats count() as count_2 by firewall.msg,appname|join type=left appname[[tag:dell| stats count() as count_1 by appname]]|sort by count_2|limit 10|eval percent1=(count_2/count_1)*100|eval percent=format(\"%.2f%%\",percent1)|eval bbb=firewall.msg+\"_\"+count_2+\"条_\"+percent"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问有关某台 Linux 服务器上所有与安全相关的 SSHD 登录和注销事件的时间、地点等信息，并计算出每个用户的登陆时间和在线时长。", "output": "appname:linux tag:secure AND type:sshd AND \"Accepted password for\"  |stats count() as login by ip,hostname,user,src_ip,src_port,pid,timestamp  |rename timestamp as login_time  |join type=left user,pid [[  appname:linux tag:secure AND type:sshd AND \"session closed for\"  |stats count() as logout by ip,hostname,pid,user,timestamp  |rename timestamp as logout_time ]]  |sort by login_time  |eval dura=format(\"%.2f分钟\",(logout_time-login_time)/60000)  |eval login_time=formatdate(login_time)  |eval logout_time=formatdate(logout_time) "}
{"input": "索引可用字段有：cdn.cdn_status, cdn.clientip.geo.city, cdn.clientip.geo.isp, cdn.domain, cdn.event_name, cdn.finished_body_response, cdn.geo.city, cdn.geo.country, cdn.geo.province, cdn.http_status, cdn.prefix_url, cdn.proto, cdn.remote_addr, cdn.request_domain, cdn.request_url, cdn.src_outside_ip, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "CDN服务商的访问量和请求数量，以及这些数据与该公司其他业务相比的变化趋势。", "output": "appname:cdn tag:aofei  AND cdn.cdn_status:*HIT   | stats count()  as count_1 by appname, cdn.prefix_url | join type = left appname [[ appname:cdn tag:aofei   | stats count()  as count_2 by appname, cdn.prefix_url ]] | eval per = count_1 / count_2 | limit 10  | eval percent = format(\"%.2f%%\", per * 100) | sort by +per "}
{"input": "索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，最近十分钟内，交换机上有哪些接口的入口流量比较高呢？", "output": "starttime=\"now-10m\" endtime=\"now\" appname:switchperf AND (switchperf.type:ifInOctets OR switchperf.type:ifOutOctets) | table timestamp,switchperf.devip,switchperf.ifindex,switchperf.type,switchperf.value |  sort by switchperf.ifindex,switchperf.type,+timestamp| autoregress switchperf.value as lastvalue p=1 | autoregress switchperf.type as lasttype p=1 | autoregress switchperf.ifindex as lastifindex p=1 | where switchperf.ifindex==lastifindex | where switchperf.type==lasttype | eval bps=case(switchperf.value-lastvalue<0,(switchperf.value-lastvalue+4294967296)/300,default,(switchperf.value-lastvalue)/300) |where bps>0| eval bps=tolong(bps) | fields timestamp,switchperf.devip,switchperf.ifindex,switchperf.type,bps| join type=inner switchperf.ifindex [[starttime=\"now-10m\" endtime=\"now\" appname:switchperf switchperf.type:ifDescr NOT vlan NOT NULL0 | table switchperf.ifindex,switchperf.value | rename switchperf.value as ifdescr]]"}
{"input": "索引可用字段有：kafka.count_partition, kafka.count_topic, kafka.event_name, kafka.event_type, kafka.lag, kafka.partition, kafka.reson, kafka.topic, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是 Kafka 服务在过去一天内发生的错误事件，并列出最近七天内发生的所有相同类型的错误事件以及它们的原因。", "output": "starttime=\"now/d\" endtime=\"now\" (appname:kafka kafka.event_type:ERROR)|eval time=formatdate(timestamp,\"MM/dd HH:mm\")|table time,kafka.event_name,kafka.reson|rename kafka.reson as newErrorReson|join type=left kafka.reson[[ starttime=\"-7d/d\" endtime=\"-1d/d\" (appname:kafka kafka.event_type:ERROR)|eval time=formatdate(timestamp,\"MM/dd HH:mm\")|table time,kafka.event_name,kafka.reson]]|fields time,kafka.event_name,newErrorReson"}
{"input": "", "instruction": "我想问以下信息：> 查询最近一周内，CPU 使用率低于 80% 的主机的信息，并将该数据与上周同期的数据进行对比", "output": "starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats AND tag:top_info |eval per=(100-cpu.idle_percent) |stats avg(per) as avg_ by ip,hostname |join type=left hostname [[ starttime=\"-7d/d\" endtime=\"now/d\" appname:top_info_system_stats AND tag:top_info | eval per=(100-cpu.idle_percent) |stats max(per) as max_ by ip,hostname]] |eval avg_=format(\"%.2f%%\",avg_) |eval max_=format(\"%.2f%%\",max_) "}
{"input": "索引可用字段有：firewall.action, firewall.alarm_ip, firewall.app, firewall.app_name, firewall.app_type, firewall.appcat, firewall.application_type, firewall.apprisk, firewall.attack, firewall.attack_message, firewall.attack_name, firewall.brief, firewall.dip, firewall.dst.geo.city, firewall.dst.geo.country, firewall.dst.geo.ip, firewall.dst.geo.province, firewall.dst.geo.latitude, firewall.dst.geo.longitude, firewall.dst_ip, firewall.dst_port, firewall.dst_zone, firewall.dup_add, firewall.event_level, firewall.event_name, firewall.event_type, firewall.facility, firewall.flow.application, firewall.flow.dst_ip.geo.city, firewall.flow.policy, firewall.flow.proto, firewall.fw_ip, firewall.grade, firewall.host, firewall.ingress_if, firewall.interface, firewall.kv.proto, firewall.kv.rule, firewall.level, firewall.locip, firewall.log_level, firewall.message, firewall.mod, firewall.module, firewall.msg, firewall.msg.CloseReason, firewall.msg.PolicyName, firewall.msg.RcvBytes, firewall.msg.SendBytes, firewall.msg.action, firewall.msg.command, firewall.msg.description, firewall.msg.dst_addr.geo.city, firewall.msg.dst_addr.geo.latitude, firewall.msg.dst_addr.geo.longitude, firewall.msg.dst_port, firewall.msg.fw, firewall.msg.method, firewall.msg.msg, firewall.msg.op, firewall.msg.pri, firewall.msg.proto, firewall.msg.reason, firewall.msg.result, firewall.msg.rule, firewall.msg.src_addr.geo.city, firewall.msg.src_addr.geo.country, firewall.msg.src_addr.geo.latitude, firewall.msg.src_addr.geo.longitude, firewall.msg.user, firewall.op, firewall.policy, firewall.policy_id, firewall.pri, firewall.pri_cn, firewall.proto, firewall.rcvd_pkt, firewall.reason, firewall.receive_byte, firewall.recorder, firewall.rem_ip.geo.city, firewall.rem_ip.geo.country, firewall.rem_ip.geo.province, firewall.remip, firewall.result, firewall.rule, firewall.rule_name, firewall.send_byte, firewall.sent, firewall.service, firewall.session_type, firewall.severity, firewall.severity_level, firewall.sip, firewall.source, firewall.src.geo.city, firewall.src.geo.country, firewall.src.geo.ip, firewall.src.geo.province, firewall.src.geo.latitude, firewall.src.geo.longitude, firewall.src_ip, firewall.src_port, firewall.src_zone, firewall.status, firewall.subtype, firewall.sys_info_id, firewall.sys_notify_traffic, firewall.threat_name, firewall.threat_subtype, firewall.threat_type, firewall.time, firewall.transport, firewall.type, firewall.url, firewall.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道今天有多少条记录的应用名称为“防火墙”且消息动作为接受的日志。", "output": "starttime=\"now/d\" endtime=\"now\" appname:firewall  firewall.msg.action:accept |stats count() as count_accept  by appname |join type=left  appname [[starttime=\"now/d\" endtime=\"now\" appname:firewall    |stats count() as  count_all by appname ]] |eval precent= count_accept/count_all"}
{"input": "索引可用字段有：firewall.action, firewall.alarm_ip, firewall.app, firewall.app_name, firewall.app_type, firewall.appcat, firewall.application_type, firewall.apprisk, firewall.attack, firewall.attack_message, firewall.attack_name, firewall.brief, firewall.dip, firewall.dst.geo.city, firewall.dst.geo.country, firewall.dst.geo.ip, firewall.dst.geo.province, firewall.dst.geo.latitude, firewall.dst.geo.longitude, firewall.dst_ip, firewall.dst_port, firewall.dst_zone, firewall.dup_add, firewall.event_level, firewall.event_name, firewall.event_type, firewall.facility, firewall.flow.application, firewall.flow.dst_ip.geo.city, firewall.flow.policy, firewall.flow.proto, firewall.fw_ip, firewall.grade, firewall.host, firewall.ingress_if, firewall.interface, firewall.kv.proto, firewall.kv.rule, firewall.level, firewall.locip, firewall.log_level, firewall.message, firewall.mod, firewall.module, firewall.msg, firewall.msg.CloseReason, firewall.msg.PolicyName, firewall.msg.RcvBytes, firewall.msg.SendBytes, firewall.msg.action, firewall.msg.command, firewall.msg.description, firewall.msg.dst_addr.geo.city, firewall.msg.dst_addr.geo.latitude, firewall.msg.dst_addr.geo.longitude, firewall.msg.dst_port, firewall.msg.fw, firewall.msg.method, firewall.msg.msg, firewall.msg.op, firewall.msg.pri, firewall.msg.proto, firewall.msg.reason, firewall.msg.result, firewall.msg.rule, firewall.msg.src_addr.geo.city, firewall.msg.src_addr.geo.country, firewall.msg.src_addr.geo.latitude, firewall.msg.src_addr.geo.longitude, firewall.msg.user, firewall.op, firewall.policy, firewall.policy_id, firewall.pri, firewall.pri_cn, firewall.proto, firewall.rcvd_pkt, firewall.reason, firewall.receive_byte, firewall.recorder, firewall.rem_ip.geo.city, firewall.rem_ip.geo.country, firewall.rem_ip.geo.province, firewall.remip, firewall.result, firewall.rule, firewall.rule_name, firewall.send_byte, firewall.sent, firewall.service, firewall.session_type, firewall.severity, firewall.severity_level, firewall.sip, firewall.source, firewall.src.geo.city, firewall.src.geo.country, firewall.src.geo.ip, firewall.src.geo.province, firewall.src.geo.latitude, firewall.src.geo.longitude, firewall.src_ip, firewall.src_port, firewall.src_zone, firewall.status, firewall.subtype, firewall.sys_info_id, firewall.sys_notify_traffic, firewall.threat_name, firewall.threat_subtype, firewall.threat_type, firewall.time, firewall.transport, firewall.type, firewall.url, firewall.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道最近十分钟内，访问了哪些应用的流量中有多少比例被防火墙接受了。", "output": "starttime=\"now-10m/m\" endtime=\"now\" appname:firewall  firewall.msg.action:accept |stats count() as count_accept  by appname |join type=left  appname [[starttime=\"now-10m/m\" endtime=\"now\" appname:firewall   |stats count() as  count_all by appname ]] |eval precent= count_accept/count_all"}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道今天和七天前的同期访问量分别有多少，以及其中哪个页面访问量多零点五倍。", "output": "starttime=\"now/d\" appname:apache  | stats count() as cnt1 by apache.request_path | join type=left apache.request_path [[ starttime=\"now-7d/d\" endtime=\"now-7d\" appname:apache | stats count() as cnt2 by apache.request_path ]] | where cnt1 > cnt2 * 1.5"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是今天有没有人在使用 Linux 系统的服务器上运行了名叫 `crond` 的计划任务。这个计划任务每天都会执行一次，每次执行的时间间隔是固定的，而且总共只要花费几秒钟就能完成。除了这些基本的信息外，你还可以根据不同的维度（比如 IP、用户等）对结果进行统计和分析。", "output": "starttime=\"now/d\" appname:linux tag:crond event_name:定时任务列表 duration:* |stats count() as ct by ip,user,duration,command |eval total=ip+\"_\"+user+\"_\"+command |eval total_md5=md5(total) |rename ip as today_ip,user as today_user,command as today_command | join type=left total_md5 [[ |inputlookup cron_list.csv | eval total_md5=md5(total) ]] |eval status=if(empty(command),\"该条记录为新增记录\",command) |stats count() as ct"}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，今天有哪些用户在使用 Linux 系统的 crontab 命令进行了定时任务？请列出 IP、用户名、执行时间和具体命令，并将它们总体上分成三类：一类是没有重复的命令，另一类是重复出现过的命令，第三类是已经被删除的命令。", "output": "starttime=\"now/d\" appname:linux tag:crond event_name:定时任务列表 duration:* |stats count() as ct by ip,user,duration,command |eval total=ip+\"_\"+user+\"_\"+command |eval total_md5=md5(total) |rename ip as today_ip,user as today_user,command as today_command | join type=left total_md5 [[ |inputlookup cron_list.csv | eval total_md5=md5(total) ]] |eval status=if(empty(command),\"该条记录为新增记录\",command) |fields today_ip,today_user,duration,today_command,status"}
{"input": "", "instruction": "我想问如何编写日志易查询语句，以获取过去一小时和过去一天内没有在运行的新进程的信息。", "output": "starttime=\"-1h\" endtime=\"now\" appname:top_info_proc_stats |stats count() as cnt_1h by cmdline  |join type=left cmdline [[ starttime=\"-1h-1d\" endtime=\"-1h\" appname:top_info_proc_stats  |stats count() as cnt_1d by cmdline]]  |where empty(cnt_1d) |fields cmdline  |rename cmdline as \"新增进程名\""}
{"input": "索引可用字段有：audit.MACHINE, audit.OSUSER, audit.PROGRAM, audit.SQL_ID, audit.SQL_TEXT, audit.USERNAME, audit.command, audit.msg.cmd, audit.msg.command, audit.msg.exec_time, audit.msg.info, audit.msg.path, audit.msg.pid, audit.msg.pwd, audit.msg.rhost, audit.msg.ruser, audit.msg.ser, audit.msg.src_ip, audit.msg.src_port, audit.msg.user, audit.up_time, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想询问今天有多少次SSH登录成功的用户数量、他们分别使用哪些主机登录、使用的IP地址、端口号、进程ID以及登录时间等信息，并计算出每个用户的登录时长和总共登录时长，最后将结果以易于阅读的方式展示给用户。", "output": "starttime=\"now/d\" appname:audit  AND audit.msg.ser:sshd AND \"Accepted password for\" | stats count() as login by ip,hostname,audit.msg.user,audit.msg.src_ip,audit.msg.src_port,audit.msg.pid,timestamp  | rename timestamp as login_time  | sort by login_time | join type=left ip,audit.msg.user,audit.msg.pid  [[  appname:audit AND audit.msg.ser:sshd AND (\"session closed for\") | stats count() as logout by ip,hostname,audit.msg.pid,audit.msg.user,timestamp  | rename timestamp as logout_time  | sort by logout_time ]]  | eval dura=format(\"%.2f分钟\",(logout_time-login_time)/60000)  | eval login_time=formatdate(login_time)  | eval logout_time=formatdate(logout_time) "}
{"input": "索引可用字段有：aix.class_dec, aix.dst_host, aix.facility, aix.login_time, aix.login_way, aix.net, aix.resource_name, aix.severity, aix.span_h, aix.span_m, aix.src_ip, aix.src_port, aix.type, aix.type_dec, aix.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想知道在过去三十一天里，有多少人使用AIX应用登录系统，并且没有在第二天再次登录。", "output": "appname:aix tag:last| stats count(hostname) as count_1 by hostname,aix.user,aix.type,aix.span_h,aix.span_m,aix.src_ip,timestamp|eval ts=formatdate(timestamp) |join type=left aix.user [[starttime = \"now/d-31d\" endtime = \"now/d-1d\" appname:aix tag:last| stats count(hostname) as count_2 by hostname,aix.user ]] |eval aaa=if(empty(count_2),0,1) |where aaa<1  |eval span_h=(todouble(aix.span_h))*3600 |eval span_m=(todouble(aix.span_m))*60 |eval login_cost=span_h+span_m  |sort by login_cost"}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问如何使用日志易查询 Apache 访问日志中每个 IP 地址的请求数量和总体请求量之间的比例。", "output": "appname:apache | bucket timestamp span=1h as ts |stats count() as ip_count by apache.clientip,ts | join type=left ts [[appname:apache | bucket timestamp span=1h as ts |stats count() as aip_count by ts ]]|eval prent_ = format(\"%.2f%%\",ip_count / aip_count *100)"}
{"input": "", "instruction": "我想知道有多少个请求失败了，并且按小时给出平均耗时。", "output": "appname:zsns tomcat.event_type:*请求报文 | stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp|rename  timestamp as t1|join tomcat.service.head.origCstSeqNo [[ appname:zsns tomcat.event_type:*响应报文 | stats count() as cnt by tomcat.service.head.origCstSeqNo,timestamp |eval t2=timestamp]]| eval cost= tolong(t2)-tolong(t1)|bucket timestamp span=1h as ts|stats avg(cost) as avg_cost by ts"}
{"input": "", "instruction": "我想把 nginx 服务的下载流量和访问量趋势图画在一起", "output": "(appname:nginx)  |bucket timestamp span=20s as ts |stats sum(middleware.bytes) as ct by appname, ts |join type=inner appname [[ (appname:nginx)  |stats count() as count_ by appname |sort by count_ |limit 5 ]]"}
{"input": "索引可用字段有：waf.action, waf.attack_name, waf.attack_type, waf.bytes_in, waf.cost, waf.cve_id, waf.dst_city, waf.dst_domain, waf.dst_ip, waf.dst_latitude, waf.dst_longitude, waf.dst_port, waf.error_msg, waf.event_level, waf.event_log_level, waf.event_name, waf.event_type, waf.http_method, waf.http_refer, waf.is_truncated, waf.kv.Evt_level, waf.kv.Evt_type, waf.kv.event_name, waf.kv.http_method, waf.kv.http_refer, waf.kv.http_url, waf.kv.msg, waf.kv.owasp_top, waf.kv.pri, waf.kv.severity_level, waf.kv.status, waf.kv.type, waf.level, waf.log_category, waf.message, waf.message.action, waf.message.event, waf.message.method, waf.message.policy, waf.message.src_ip.geo.ip, waf.message.src_ip.geo.province, waf.message.src_port, waf.message.status, waf.message.threaten, waf.method, waf.module, waf.msg.act, waf.msg.cs, waf.msg.policy_id, waf.msg.src.geo.country, waf.policy_name, waf.proto, waf.referer, waf.risk_level, waf.severity, waf.src.geo.city, waf.src.geo.country, waf.src.geo.ip, waf.src.geo.isp, waf.src.geo.latitude, waf.src.geo.longitude, waf.src.geo.province, waf.src_ip, waf.src_port, waf.status, waf.status_code, waf.threat_level, waf.time, waf.ua_browser, waf.ua_device, waf.ua_os, waf.uri, waf.url, waf.user_agent.browser, waf.user_agent.os, waf.website_name, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，在每三十分钟内，有多少次访问了 Imperva WAF 服务的 IP 地址？并且显示前三个最常见的 IP 地址和访问次数。", "output": "appname:waf  tag:imperva |bucket timestamp span=30m as ts |stats count() as ct  by ts,waf.dst_ip | join type=left waf.dst_ip  [[appname:waf  tag:imperva |top 3 waf.dst_ip]] |where count>0"}
{"input": "", "instruction": "我想询问关于某公司的网站访问日志中，HTTP响应状态码为200（成功）和非200（失败）之间的比例有多高的信息。", "output": "appname:thinkive_works_web_log AND middleware.action: \"Response\" |bucket timestamp span=30m as ts | stats count() as total by ts, middleware.func_no | join type=left ts, middleware.func_no [[appname:thinkive_works_web_log AND middleware.action: \"Response\" AND NOT middleware.response:0 |bucket timestamp span=30m as ts | stats count() as failed_ by ts, middleware.func_no]] |table ts, middleware.func_no,total,failed_|eval failed=if(empty(failed_),0,failed_)|eval failed_pct=failed/total |table ts, middleware.func_no, failed_pct|rename middleware.func_no as '接口', failed_pct as '失败率'"}
{"input": "索引可用字段有：ac.ac_ip, ac.action, ac.ap_ip, ac.ap_name, ac.app, ac.app_name, ac.band, ac.client, ac.command, ac.dst_ip, ac.dst_port, ac.event_id, ac.event_name, ac.event_type, ac.kv.app_cat_name, ac.kv.log_level, ac.kv.receive_addr, ac.kv.send_addr, ac.kv.subject, ac.kv.term_device, ac.log_type, ac.mac_addr, ac.mnemonic, ac.msg.app, ac.msg.serv, ac.msg.tm_type, ac.msg.user, ac.operation, ac.policy, ac.request_url, ac.resource, ac.resource_type, ac.result, ac.src_ip, ac.src_mac, ac.ssid, ac.status, ac.time, ac.user, ac.user_agent, ac.user_name, ac.web_app, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是最近一周有没有访问过“招聘”或者“求职”的网站，而且访问次数在几次以内、几到二十次之间、二十到五十次之间或大于五十次。", "output": "appname:ac tag:qianxin ac.log_type:* ac.web_app:*招聘* OR ac.web_app:*求职*|stats count() as times,dc(ac.request_url) as type by ac.src_ip|eval timeslevel=tolong(case(times<=5,\"1\",times>5&&times<=20,\"2\",times>20&&times<=50,\"3\",times>50,\"4\"))| eval typelevel=tolong(case(type<8,\"1\",type>7&&type<=10,\"2\",type>10&&type<=20,\"3\",type>20,\"4\"))| join ac.src_ip[[ appname:ac tag:qianxin ac.log_type:web ac.web_app:*招聘* OR ac.web_app:*求职* |bucket timestamp span=1d as ts |stats dc(ts) as days by ac.client,ac.src_ip |eval dayslevel=tolong(case(days==1,\"1\",days>1&&days<=3,\"2\",days==4,\"3\",days>4,\"4\"))]]|eval score=timeslevel*0.3+typelevel*0.2+dayslevel*0.5"}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问有关 Apache 服务器的访问日志中，返回平均响应时间最长的前五个应用的信息。", "output": " (appname:apache tag:access middleware.status:>399)  |bucket timestamp span=30m as ts |stats avg(middleware.req_time) as avg_ by appname, ts |join type=inner appname [[ (appname:apache tag:access middleware.status:>399)  |stats count() as count_ by appname |sort by count_ |limit 5 ]]"}
