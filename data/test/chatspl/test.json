{"input": "凌晨0点到晚上8点的Linux主机日志", "output": "starttime=\"now/d\" endtime=\"now/d+20h\" appname:linux", "category": "query", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "查询晚上23点到次日8点的所有日志", "output": "starttime=\"now/d+23h\" endtime=\"now/d+1d+8h\" *", "category": "query", "level": 1, "now": 1701765481000,"start_ts":"-1000d", "fields": ""}
{"input": "查询前两天到当前时间数据", "output": "starttime=\"now-2d\" endtime=\"now\" *", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查询用户liwei最近10天登录防火墙设备的记录", "output": "starttime=\"-10d\" appname:firewall firewall.login_user:liwei", "category": "query", "level": 1, "now": 1677227381000,"start_ts":"-1000d", "fields": "firewall日志:appname:firewall 用户:firewall.login_user"}
{"input": "查询请求时间在昨天的10:00至今天的10:00之间，且响应时间大于1秒且小于5秒，且包含“timeout”或“error”，且状态码为404或500，且IP地址为“192.168.1.1”或“192.168.1.2”，且用户代理为“Chrome”或“Firefox”，且请求路径为“/login”或“/logout”的所有apache请求日志。", "output": "starttime=\"-1d/d+10h\" endtime=\"now/d+10h\" appname:apache AND (apache.req_time:>1 AND apache.req_time:<5) AND (apache.status:404 OR apache.status:500) AND (apache.ua.browser:Chrome OR apache.ua.browser:Firefox) AND (apache.request_path:\"/login\" OR apache.request_path:\"/logout\") AND (ip:192.168.1.1 OR ip:192.168.1.2)", "category": "query", "level": 2, "now": 1701902611000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 响应时间:apache.req_time 状态码:apache.status 用户代理:apache.ua.browser 请求路径:apache.request_path"}
{"input": "前天", "output": "starttime=\"now-2d/d\" endtime=\"now-1d/d\" *", "category": "query", "level": 1, "now": 1701941392000,"start_ts":"-1000d", "fields": ""}
{"input": "查询上周一的日志", "output": "starttime=\"now-1w/w\" endtime=\"now-1w/w+1d\" *", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": ""}
{"input": "查询上个月最后一天的数据", "output": "starttime=\"now/M-1d\" endtime=\"now/M\" *", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": ""}
{"input": "今天上午六点到下午八点之间的所有日志", "output": "starttime=\"now/d+6h\" endtime=\"now/d+20h\" *", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": ""}
{"input": "查询周一的日志", "output": "starttime=\"now/w\" endtime=\"now/w+1d\" *", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": ""}
{"input": "查询三天前的日志", "output": "starttime=\"now-3d\" endtime=\"now-2d\" *", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": ""}
{"input": "查询请求时间大于1秒且小于5秒，且包含“timeout”或“error”，且状态码为404或500的所有apache请求日志。", "output": "appname:apache (apache.req_time:>1 AND apache.req_time:<5) AND (timeout OR error) AND (apache.status:\"404\" OR apache.status:\"500\")", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-10d", "fields": "apache日志:appname:apache 响应时间:apache.req_time 状态码:apache.status"}
{"input": "应用apache，最近1天，apache.upstream_resp_time大于0.5的事件趋势", "output": "starttime=\"-1d\" appname:apache apache.upstream_resp_time:>0.5", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "搜索schedule索引，昨天一整天的数据，schedule name为hour logsize", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" _index:schedule schedule_name:\"hour logsize\"", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "apache日志中，查询最近一天到现在，apache状态码大于200的日志", "output": "starttime=\"-1d\" endtime=\"now\" appname:apache apache.status:>200", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "查询rizhiyi日志，并判断字段 return_code 不为空并且不等于000000", "output": "appname:rizhiyi AND return_code:* AND NOT return_code:000000", "category": "query", "level": 1, "now": 1701821450000,"start_ts":"-1d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "查找今天error或failed关键字的日志，但是不要ip为192.168.40.102上的日志", "output": "starttime=\"now/d\" (error OR failed) NOT ip:192.168.40.102", "category": "query", "level": 1, "now": 1701920613000,"start_ts":"-1d", "fields": ""}
{"input": "查找今天error或failed关键字的日志，但是不要包含warn关键字的日志", "output": "starttime=\"now/d\" (error OR failed) NOT warn", "category": "query", "level": 1, "now": 1701963811000,"start_ts":"-1d", "fields": ""}
{"input": "查看nginx.user不含m的数据", "output": "nginx.user:* NOT nginx.user:\"*m*\"", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用全文检索功能，查询展现查询错误码不为300的原始日志 所属应用是[apache] 标签是[access] 所属索引是[yotta] 主机名称是[VM_16_9_centos]", "output": "appname:apache tag:access _index:yotta hostname:VM_16_9_centos NOT apache.status:300", "category": "query", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "使用全文检索功能，查询展现查询错误码不为300的原始日志，错误码字段为status当前数据中，错误码的分布 所属应用是[apache] 标签是[access] 所属索引是[yotta] 主机名称是[VM_16_9_centos]", "output": "appname:apache tag:access _index:yotta hostname:VM_16_9_centos NOT apache.status:300 | stats count() by apache.status", "category": "stats", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "看错误日志已知的业务系统信息如下 所属应用是[test123] 错误关键字是[中断or停止or 注销or超时]", "output": "appname:test123 (中断 OR 停止 OR 注销 OR 超时)", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计catrgary字段不等于50，且hitcount大于10的日志", "output": "(NOT category:50) AND hitcount:>10", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "从a.csv中读取事件信息", "output": "| inputlookup a.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "读取外部字典siem_resource.csv", "output": "| inputlookup siem_resource.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用inputlookup读取siem_resource.csv", "output": "| inputlookup siem_resource.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "输出fh_name.csv字典内容", "output": "| inputlookup fh_name.csv ", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "请帮我查询字典表为test.csv的内容", "output": "| inputlookup test.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查看字典abc.csv的数据，给出spl", "output": "| inputlookup abc.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "读取lookup文件a.csv中的事件信息", "output": "| inputlookup a.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查看ccd.csv字典", "output": "| inputlookup ccd.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用inputlookup命令读取system.csv字典内容", "output": "| inputlookup system.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用inputlookup输出fh.csv字典中的内容", "output": "| inputlookup fh.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用inputlookup 获取字典a.csv的数据，展示字段a", "output": "| inputlookup a.csv | table a", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用inputlookup打印classname.csv字典的内容", "output": "| inputlookup classname.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用inputlookup读取bankCode.csv", "output": "| inputlookup bankCode.csv", "category": "inputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用stats 统计appname、hostname、ip 并使用mvcombine把ip列做合并", "output": "* | stats count() by appname,hostname,ip | mvcombine ip", "category": "multivalue", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "分析邮件安全网关syslog日志appname:email_gateway，检测收件人mailTo超过10个的群发邮件事件", "output": "appname:email_gateway | where mvcount(mailTo)>10 ", "category": "multivalue", "level": 2, "now": 1699459200000,"start_ts":"-1d", "fields": "email_gateway日志:appname:email_gateway"}
{"input": "mvcombine使用###进行分割，连接linux数据中的ip字段", "output": "appname:linux | mvcombine sep=\"###\" ip", "category": "multivalue", "level": 1, "now": 1701860622530,"start_ts":"-300d", "fields": "linux日志:appname:linux"}
{"input": "统计下windows系统今日的登录成功率", "output": "starttime=\"now/d\" endtime=\"now\" appname:windows json.event_id:4624 | stats count() as succ_cnt | appendcols [[ starttime=\"now/d\" endtime=\"now\" appname:windows (json.event_id:4624 OR json.event_id:4625) | stats count() as total_cnt ]] | eval login_succ_pct = succ_cnt/total_cnt", "category": "appendcols", "level": 1, "now": 1695883628000,"start_ts":"-1000d", "fields": "windows日志:appname:windows 登录成功:json.event_id:4624 登录失败:json.event_id:4625"}
{"input": "access日志分别统计PV，并且追加一列UV信息", "output": "appname:apache tag:access | stats count() as PV | appendcols [[ appname:apache tag:access | stats dc(apache.clientip) as UV ]]", "category": "appendcols", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 用户地址:apache.clientip"}
{"input": "统计各机器不同磁盘的最大Inode使用率", "output": "appname:top_info_disk_stats | stats max(json.disk.inodes_used_percent) by ip,json.disk.path", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "top_info_disk_stats日志:appname:top_info_disk_stats inode使用率:json.disk.inodes_used_percent 磁盘:json.disk.path"}
{"input": "统计每台机器的网络端口出入总流量", "output": "appname:top_info_system_stats | stats sum(json.net.bytes_sent), sum(json.net.bytes_recv) by ip", "category": "stats", "level": 1, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats 网络出口流量:json.net.byte_sent 网络入口流量:json.net.bytes_recv"}
{"input": "vpn日志解析中有vpn.src_ip字段，vpn_user.csv字典有id、src_ip、user字段，请用lookup关联vpn_user.csv的src_ip字段，匹配出user字段", "output": "appname:vpn | lookup user vpn_user.csv on vpn.src_ip=src_ip", "category": "lookup", "level": 1, "now": 1656577396000,"start_ts":"-1000d", "fields": "vpn日志:appname:vpn"}
{"input": "vpn日志中有vpn.src_ip字段，vpn_user.csv字典有id、src_ip、user字段，请关联vpn_user.csv的src_ip字段，匹配出user字段", "output": "appname:vpn | lookup user vpn_user.csv on vpn.src_ip=src_ip", "category": "lookup", "level": 1, "now": 1656577396000,"start_ts":"-1000d", "fields": "vpn日志:appname:vpn"}
{"input": "筛选出appname为dmz和skyeye并status为失陷的数据，统计sip、dip、deamon字段并通过sip值去关联fh_name.csv的sip展示name的值", "output": "(appname:dmz OR appname:skyeye) AND status:\"失陷\" | stats count() by sip,dip,daemon | lookup name fh_name.csv on sip=sip", "category": "lookup", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "dmz日志:appname:dmz"}
{"input": "对 apache 访问日志中的主机字段，关联cmdb.csv的host 列，展示对应的 owner, email和phone", "output": "appname:apache | lookup owner,email,phone cmdb.csv on hostname=host", "category": "lookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "用主机名关联cmdb.csv的host，获取的owner和phone，统计 apache 日志里 5xx 报错最多的 owner 是谁", "output": "appname:apache apache.status:>499 | lookup owner,phone cmdb.csv on hostname=host | top 1 owner", "category": "lookup", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "在搜索结果里通过一个子查询将字段cluster中数值占比最小的值找出来后，再查询apache日志中apache.cluster符合这个值的日志", "output": "appname:apache [[ appname:apache | stats count() as cnt by apache.cluster | sort by +cnt | limit 1 | fields apache.cluster ]]", "category": "subquery", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "在搜索结果里通过一个子查询将字段cluster中数值占比最小的值找出来后，再查询apache日志中apache.cluster符合这个值的日志，并统计其中的 clientip 前十名", "output": "appname:apache [[ appname:apache | stats count() as cnt by apache.cluster | sort by +cnt | limit 1 | fields apache.cluster ]] | top 10 apache.clientip", "category": "subquery", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "查询baoleiji日志里username字段存在的值不存在于ticket日志的username字段里", "output": "appname:baoleiji | stats count() as baoleiji by username | join type=left username [[ appname:ticket | stats count() as ticket by username ]] | where empty(ticket)", "category": "join", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "baoleiji日志:appname:baoleiji"}
{"input": "统计日志中 ip 地址和主机名，然后用outlookup函数输出aa.csv文件，只需要保留IP、host", "output": "* | stats count() by hostname,ip | fields hostname,ip | outputlookup aa.csv", "category": "outputlookup", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "分析DNS域名解析日志,每分钟总量超过过去1小时内平均每分钟样本量的10倍触发告警", "output": "starttime=\"-1h\" appname:dns | bucket timestamp span=1m as ts|stats count() as cnt by ts | eventstats avg(cnt) as avg_ | eval is_outlier=if(cnt > 10 * avg_, 1, 0)", "category": "eventstats", "level": 2, "now": 1671528764296,"start_ts":"-1d", "fields": "dns日志:appname:dns"}
{"input": "查找1小时内单个IP的访问次数占这1小时内总IP数的百分比，appname:*", "output": "starttime=\"-1h\" appname:* | stats count() as cnt by ip | eventstats sum(cnt) as total | eval ip_pct = cnt / total", "category": "eventstats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "日志:appname:"}
{"input": "同时搜索yotta索引里appname是apache的日志，和metric索引里appname是json的日志，并提取出来同名的clientip字段", "output": "_index:yotta appname:apache | stats count() as apache_cnt by apache.clientip | rename apache.clientip as clientip | join clientip [[ _index:metric appname:json | stats count() as metric_cnt by json.clientip | rename json.clientip as clientip ]]", "category": "join", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "日志中包含\"error-123-test\"，用parse提取第二个”-“后面的值，并把字段名取为moudle", "output": "* | parse \"error-\\d+-(?<module>\\w+)\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "日志中包含\"error-123-test\"，用parse提取第一个”-“后面的值，并把字段名取为 code，然后转换为数值类型并过滤大于 100 的数据", "output": "* | parse \"error-(?<code>\\d+)-\\w+\" | eval code=tolong(code) | where code>100", "category": "parse", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "日志中包含样例\"error-123-test\"，用parse提取第一段字符串", "output": "* | parse \"(?<level>\\w+)-\\d+-\\w+\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用parse提取nginx访问日志中状态码字段status", "output": "appname:nginx tag:access | parse \"\\s(?<status>\\d{3})\\s\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx"}
{"input": "使用parse命令解析提取“2023-11-07 21:08:14,178 INFO gro”中INFO内容，字段名level", "output": "* | parse \"\\d+-\\d+-\\d+ \\d\\d:\\d\\d:\\d\\d,\\d{3} (?<level>[A-Z]+) \\S+\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "给定日志样例：2023-11-16 18:56:57,462 DEBUG kafka-source-0 internals.ConsumerCoordinator: [Consumer clientId=consumer-logriver-3, groupId=logriver] Received successful Heartbeat response，请使用parse命令提取DEBUG内容", "output": "* | parse \"\\d+-\\d+-\\d+ \\d\\d:\\d\\d:\\d\\d,\\d{3} (?<level>[A-Z]+) .*\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "请提供IP地址的正则表达式", "output": "* | parse \"(?<ip>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计appname为apache，url长度进行分段，统计每一段长度的数量", "output": "appname:apache | bucket apache.resp_len ranges=((0,1000),(1000,1000000),(1000000,MAX)) as rs | stats count() by rs", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache url长度:apache.resp_len"}
{"input": "请帮我按天统计各linux主机上每个磁盘最大使用率的时间趋势图", "output": "appname:top_info_disk_stats | bucket timestamp span=1d as ts | stats max(json.disk.used_percent) by ts, hostname, json.disk.path", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "top_info_disk_stats日志:appname:top_info_disk_stats 磁盘:json.disk.path 使用率:json.disk.used_percent"}
{"input": "用bucket命令统计今天全天的linux日志时间趋势图", "output": "starttime=\"now/d\" endtime=\"now+1d/d\" appname:linux | bucket timestamp span=1h as ts | stats count() by ts", "category": "bucket", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "请用bucket统计各linux主机今天下午到晚八点的日志时间趋势图", "output": "starttime=\"now/d+12h\" endtime=\"now/d+20h\" appname:linux | bucket timestamp span=1h as ts | stats count() by ts,hostname", "category": "bucket", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "根据时间维度分析windows的账号修改密码事件的事件趋势", "output": "appname:windows (json.event_id:4724 OR json.event_id:4723) | timechart count()", "category": "timechart", "level": 1, "now": 1695883628000,"start_ts":"-1000d", "fields": "windows日志:appname:windows 更改密码:json.event_id:4723 重置密码:json.event_id:4724"}
{"input": "linux日志里面error关键字的时间趋势分析", "output": "appname:linux error | timechart count()", "category": "timechart", "level": 1, "now": 1701860622530,"start_ts":"-100d", "fields": "linux日志:appname:linux"}
{"input": "appanme为linux，对error事件分析事件的趋势", "output": "appname:linux error | timechart count()", "category": "timechart", "level": 1, "now": 1701860622530,"start_ts":"-100d", "fields": "linux日志:appname:linux"}
{"input": "请帮我统计appname为rizhiyi日志的时间趋势图", "output": "appname:rizhiyi | timechart count()", "category": "timechart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "请帮我统计今天appname为rizhiyi日志的时间趋势图", "output": "starttime=\"now/d\" appname:rizhiyi | timechart count()", "category": "timechart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "请帮我统计今天全天的linux日志时间趋势图", "output": "starttime=\"now/d\" endtime=\"now+1d/d\" appname:linux | timechart count()", "category": "timechart", "level": 1, "now": 1701860622530,"start_ts":"-100d", "fields": "linux日志:appname:linux"}
{"input": "请帮我统计各linux主机今天日志时间趋势图", "output": "starttime=\"now/d\" endtime=\"now\" appname:linux | timechart count() by hostname", "category": "timechart", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "今天各个source的日志量趋势", "output": "starttime=\"now/d\" endtime=\"now\" * | timechart count() by source", "category": "timechart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "请帮我统计linux七天前到昨天前的日志时间趋势图", "output": "starttime=\"now-7d/d\" endtime=\"now-1d/d\" appname:linux | timechart count()", "category": "timechart", "level": 1, "now": 1702033422000,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "请给我最近十分钟appname为linux的日志量同比趋势", "output": "starttime=\"-10m\" appname:linux | timechart span=1m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"今天\" | join _time [[ starttime=\"now-10m-1d\" endtime=\"now-1d\" appname:linux | timechart span=1m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"昨天\" ]]", "category": "join", "level": 2, "now": 1701860622530,"start_ts":"-1d", "fields": "linux日志:appname:linux"}
{"input": "请给我最近10m内appname为linux的今天、昨天和前天日志量同比趋势", "output": "starttime=\"-10m\" appname:linux | timechart span=1m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"今天\" | join _time [[ starttime=\"now-10m-1d\" endtime=\"now-1d\" appname:linux | timechart span=1m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"昨天\" ]] | join _time [[ starttime=\"now-10m-2d\" endtime=\"now-2d\" appname:linux | timechart span=1m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"前天\" ]]", "category": "join", "level": 3, "now": 1701860622530,"start_ts":"-1d", "fields": "linux日志:appname:linux"}
{"input": "请帮我统计appname为rizhiyi今天昨天七天前日志时间趋势图,10分钟一个点", "output": "starttime=\"now/d\" endtime=\"now\" appname:rizhiyi | timechart span=10m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"今天\" | join _time [[ starttime=\"now/d-1d\" endtime=\"now-1d\" appname:rizhiyi | timechart span=10m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"昨天\" ]] | join _time [[ starttime=\"now/d-7d\" endtime=\"now-7d\" appname:rizhiyi | timechart span=10m count() | eval _time=formatdate(_time, \"HH:mm\"), line=\"七天前\" ]]", "category": "join", "level": 3, "now": 1701855000000,"start_ts":"-1000d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "请给我appname为linux的今天、昨天和前天数据量的环比趋势", "output": "starttime=\"now-2d/d\" endtime=\"now+1d/d\" appname:linux | timechart span=1h count() | timewrap 1d", "category": "timewrap", "level": 2, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "按小时统计事件数，并计算出当前小时和上个小时的事件数变化比率", "output": "starttime=\"now-1h/h\" endtime=\"now+1h/h\" * | timechart span=1h count() as cnt | timewrap 1h | eval rates = cnt_0hours_before / cnt_1hours_before", "category": "timewrap", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "绘制当期日志量趋势和近60日的移动平均线趋势", "output": "starttime=\"-60d\" * | timechart span=1d count() as cnt | movingavg cnt,5", "category": "movingavg", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "绘制最近60天的日志量趋势和5日移动平均线趋势,使用函数movingavg", "output": "starttime=\"-60d\" * | timechart span=1d count() as cnt | movingavg cnt,5", "category": "movingavg", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "找出昨天有数据,前天没有数据的appname", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" * | stats count() as cnt_1days_before by appname | join type=left appname [[ starttime=\"now-2d/d\" endtime=\"now-1d/d\" * | stats count() as cnt_2days_before by appname ]] | where empty(cnt_2days_before)", "category": "join", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "请帮我八今天和昨天的时间趋势图join联系在一起", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" *|bucket timestamp span=1h as ts | stats count() by ts | eval ts=formatdate(ts, \"HH\"),line=\"昨天\" | join type=left ts [[ starttime=\"now/d\" endtime=\"now\" * | bucket timestamp span=1h as ts | stats count() by ts | eval ts=formatdate(ts, \"HH\"), line=\"今天\" ]]", "category": "join", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查找某攻击地址同时在防火墙和waf上都有攻击事件", "output": "appname:firewall | stats count() by src_ip | join type=inner src_ip [[ appname:waf | stats count() by src_ip ]]", "category": "join", "level": 1, "now": 1677227381000,"start_ts":"-1000d", "fields": "防火墙日志:appname:firewall waf日志:appname:waf 攻击地址:src_ip"}
{"input": "统计apache每小时事件数，以时间为join字段，统计midware每小时事件数", "output": "appname:apache | timechart span=1h count() as apache | eval _time=formatdate(_time, \"HH\") | join _time [[ appname:middleware | timechart span=1h count() as middleware | eval _time=formatdate(_time, \"HH\") ]]", "category": "join", "level": 1, "now": 1701855000000,"start_ts":"-10d", "fields": "apache日志:appname:apache middleware日志:appname:middleware"}
{"input": "对apache日志分别搜索两个结果，一个是统计apache.request_path的访问数量，一个是统计apache.status是200的日志中apache.request_path的访问数量，然后用join按apache.request_path为主键将两个结果合并", "output": "appname:apache | stats count() as total_cnt by apache.request_path | join type=left apache.request_path [[ appname:apache AND apache.status:200 | stats count() as succ_cnt by apache.request_path ]]", "category": "join", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "以主机ip的纬度统计appname:esb交易量，并通过ip关联join操作系统日志中error报错数量", "output": "appname:esb | stats count() as esb_cnt by ip | join ip [[ appname:linux error | stats count() as os_err by ip ]]", "category": "join", "level": 1, "now": 1701963811000,"start_ts":"-1000d", "fields": "esb日志:appname:esb"}
{"input": "使用join分别统计nginx和tomcat相同来源ip的日志量", "output": "appname:nginx | stats count() by nginx.clientip | rename nginx.clientip as clientip | join clientip [[ appname:tomcat | stats count() by tomcat.remote_addr | rename tomcat.remote_addr as clientip ]]", "category": "join", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 来源IP:nginx.clientip tomcat日志:appname:tomcat 来源IP:tomcat.remote_addr"}
{"input": "请帮我使用table语法列出ips防火墙日志中SSH登录事件的五元组，并对其进行去重", "output": "appname:ips SSH | stats count() by src_ip, src_port, dst_ip, dst_port, proto | table src_ip, src_port, dst_ip, dst_port, proto", "category": "table", "level": 1, "now": 1697193755000,"start_ts":"-10d", "fields": "ips日志:appname:ips 来源地址:src_ip 来源端口:src_port 目的地址:dst_ip 目的端口:dst_port 协议:proto"}
{"input": "统计过去一天每小时每个ip的事件数，并取出每一行结果中时间的小时值", "output": "starttime=\"now-1d\" endtime=\"now\" * | timechart span=1h count() by ip | eval hour=formatdate(_time, \"HH\") | table hour", "category": "table", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计apache状态码分布，并去除状态码字段", "output": "appname:apache | stats count() by apache.status | fields -apache.status", "category": "fields", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "筛选CPU使用率大于70的服务器，并列出Ip", "output": "appname:top_info_system_stats json.cpu.user_percent:>70 | stats count() by ip | table ip", "category": "table", "level": 1, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats CPU使用率:json.cpu.user_percent"}
{"input": "将原始日志中仅保留appname和hostname这两个字段的结果下载为a.json文件输出", "output": "* | fields appname,hostname | download filename=\"a\" fileformat=\"json\"", "category": "download", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用fields把查询结果中保留ip和source字段", "output": "* | fields ip, source", "category": "fields", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "appname为firewall，table出所有解析之后的字段", "output": "appname:firewall | table firewall.*", "category": "table", "level": 1, "now": 1677227381000,"start_ts":"-1000d", "fields": "firewall日志:appname:firewall"}
{"input": "列出appname为linux的日志的所有字段", "output": "appname:linux | table *", "category": "table", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "使用table展示ip、hostname、状态码", "output": "status:* | table ip,hostname,status", "category": "table", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "状态码:status"}
{"input": "table字段a，b，c，并把字段a重命名为test", "output": "* | table a, b, c | rename a as test", "category": "table", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "将appname:abc的查询中的结果用表格展示并且只显示以json.i开始字段", "output": "appname:abc | table json.i*", "category": "table", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "abc日志:appname:abc"}
{"input": "将查询中的结果用表格展示并且只显示apache.status和apache.method 字段", "output": "appname:apache | table apache.status, apache.method", "category": "table", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "判断交换机的端口状态，状态为down时输出ip和端口信息", "output": "appname:switch down | table ip, switch.ethernet", "category": "table", "level": 1, "now": 1701273290000,"start_ts":"-1000d", "fields": "switch日志:appname:switch 端口:switch.ethernet"}
{"input": "统计B系统今天用户登录情况，展示登录状态login_status，用户名login_user，登录时间login_time", "output": "starttime=\"now/d\" appname:b | table login_status,login_user,login_time", "category": "table", "level": 1, "now": 1701963212000,"start_ts":"-1d", "fields": "b日志:appname:b"}
{"input": "查询最近一天DNS请求日志中访问最多的域名，并按照访问次数排序，且展示源IP与目的IP和访问的最晚时间", "output": "starttime=\"-1d\" appname:dns | stats count(), latest(dns.src_ip), latest(ip), last(timestamp) by dns.domain", "category": "stats", "level": 2, "now": 1671528764300,"start_ts":"-1000d", "fields": "dns日志:appname:dns 来源IP:dns.src_ip 目的IP:ip 域名:dns.domain"}
{"input": "用where过滤 a或b 字段是字符串类型的数据", "output": "* | where typeof(a)==\"string\" || typeof(b)==\"string\"", "category": "where", "level": 1, "now": 1701373411000,"start_ts":"-10d", "fields": ""}
{"input": "在where中过滤 ip 地址且属于 192.168.1.0/24 内网地址段的主机", "output": "* | where is_valid_ip(ip) && cidrmatch(\"192.168.1.0/24\", ip)", "category": "where", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "在所有日志中，生成一个where a==1并且b==2的语句", "output": "* | where a==1 && b==2", "category": "where", "level": 1, "now": 1701373411000,"start_ts":"-10d", "fields": ""}
{"input": "帮我统计主机VM_16_9_centos今天cpu使用率差值超过2%的时间点;", "output": "starttime=\"now/d\" endtime=\"now\" hostname:VM_16_9_centos appname:top_info_system_stats | autoregress json.cpu.user_percent as last_perc p=1 | eval cpu_usage_diff=abs(json.cpu.user_percent-last_perc) | where cpu_usage_diff > 2 | table timestamp", "category": "autoregress", "level": 2, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats CPU使用率:json.cpu.user_percent"}
{"input": "查询rizhiyi日志，使用where判断字段 return_code 不为空且不等于000000", "output": "appname:rizhiyi return_code:* | where !empty(return_code) && return_code != \"000000\"", "category": "where", "level": 1, "now": 1701821450000,"start_ts":"-1d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "统计nginx访问日志状态码，过滤出大于400的结果", "output": "appname:nginx | stats count() by nginx.status | eval nginx.status=tolong(nginx.status) | where nginx.status > 400", "category": "where", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 状态码:nginx.status"}
{"input": "统计今天appname数据量，并使用where命令保留appname:xx和appname:yy的内容", "output": "starttime=\"now/d\" appname:* | stats count() by appname | where appname==\"xx\" || appname==\"yy\"", "category": "stats", "level": 1, "now": 1701398612000,"start_ts":"-1d", "fields": "xx日志:appname:xx"}
{"input": "以appname:dmz为条件统计zh.sip和zh.dip的字段并筛选出结果大于10的数据", "output": "appname:dmz (zh.sip:* AND zh.dip:*) | stats count() as cnt by zh.sip,zh.dip | where cnt > 10", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "dmz日志:appname:dmz"}
{"input": "接受日志时间减去发送日志时间看有没有大于5s的", "output": "_index:yotta | eval duration = collector_recv_timestamp - agent_send_timestamp | where duration > 5", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "接收日志时间:collector_recv_timestamp 发送日志时间:agent_send_timestamp"}
{"input": "EIP账号在四小时内使用两个及以上IP登录", "output": "starttime=\"-4h\" appname:eip | stats count() as cnt by src_ip | where cnt>=2", "category": "stats", "level": 1, "now": 1701657812000 ,"start_ts":"-1d", "fields": "EIP日志:appname:eip 来源IP:src_ip"}
{"input": "分析昨天的IAM日志appname:iam在10分钟内，来源src_ip上超过2个账号account锁定的情况", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" appname:iam (src_ip:* AND account:*) | bucket timestamp span=10m as ts | stats count() as cnt by src_ip,account,ts | where cnt >= 2", "category": "bucket", "level": 1, "now": 1701902611000,"start_ts":"-1d", "fields": "IAM日志:appname:iam"}
{"input": "分析2分钟内，防火墙日志appname:firewall来源src_ip访问不同目标主机dst_ip（端口port为3389/445/139）>= 5个主机的行为", "output": "starttime=\"-2m\" appname:firewall firewall.src_ip:* AND (firewall.dst_port:3389 OR firewall.dst_port:445 OR firewall.dst_port:139) | stats dc(firewall.dst_ip) as cnt by firewall.src_ip | where cnt >= 5", "category": "stats", "level": 1, "now": 1677203416000,"start_ts":"-1000d", "fields": "firewall日志:appname:firewall"}
{"input": "Cisco 交换机日志源地址排名TOP100", "output": "appname:switch tag:cisco | top 100 switch.src_ip", "category": "top", "level": 1, "now": 1701273290000,"start_ts":"-1000d", "fields": " Cisco交换机日志:appname:switch tag:cisco 来源地址:switch.src_ip"}
{"input": "日志量排名前十的系统", "output": " * | top 10 appname", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "列出appname数量前10", "output": "appname:* | top 10 appname", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "日志:appname:"}
{"input": "请帮我统计所有的logtype  top100的数量", "output": "logtype:* | top 100 logtype", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查找logtype:apache 访问日志中访问次数最多的IP地址", "output": "logtype:apache | top 1 ip", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "帮我找到tdx系统里耗时time字段小于10的数据", "output": "appname:tdx tdx.time:<10", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "tdx日志:appname:tdx 耗时:tdx.time"}
{"input": "过滤登录用户不为admin且其余vpn用户登录次数TOP10", "output": "appname:vpn NOT vpn.login_user:admin | top 10 vpn.login_user", "category": "top", "level": 1, "now": 1656577396000,"start_ts":"-1000d", "fields": "vpn日志:appname:vpn 登录用户:vpn.login_user"}
{"input": "统计apache日志前10的状态码", "output": "apache.status:* | top 10 apache.status", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "展示apache日志前20的clientip", "output": "appname:apache | top 20 apache.clientip", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 来源地址:apache.clientip"}
{"input": "统计windows事件里面登陆失败事件，id为4625，并统计字段src_ip的top10", "output": "appname:windows json.event_name:登录失败事件 json.event_id:4625 | top 10 json.src_ip", "category": "top", "level": 1, "now": 1695883628000,"start_ts":"-1000d", "fields": "windows日志:appname:windows 事件ID:json.event_id"}
{"input": "我想找到最近一周产生日志最多的业务appname", "output": "starttime=\"-7d\" endtime=\"now\" * | top 1 appname", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "主管道统计大前天nginx访问日志平均耗时，append子管道统计昨天的nginx访问日志平均耗时", "output": "starttime=\"-3d/d\" endtime=\"-2d/d\" appname:nginx | stats avg(nginx.req_time) | eval line=\"大前天\" | append [[ starttime=\"-1d/d\" endtime=\"now/d\" appname:nginx | stats avg(nginx.req_time) | eval line=\"昨天\" ]]", "category": "append", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 耗时:nginx.req_time"}
{"input": "按照1分钟分桶统计当天日志条数，同时按照1分钟分桶统计当天错误日志条数，绘制两条趋势图", "output": "starttime=\"now/d\" endtime=\"now\" * | bucket timestamp span=1m as ts | stats count() by ts | eval time=formatdate(ts,\"HH:mm\") | eval line=\"总数\" | join type=left time [[ starttime=\"now/d\" endtime=\"now\" error | bucket timestamp span=1m as ts | stats count() by ts | eval time=formatdate(ts,\"HH:mm\") | eval line=\"错误数\"]]", "category": "join", "level": 2, "now": 1701963811000,"start_ts":"-1d", "fields": ""}
{"input": "把appname为test2的事件追加到appname为test1后面", "output": "appname:test1 | append [[ appname:test2 ]]", "category": "append", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "test日志:appname:test"}
{"input": "统计最近十分钟内waf中的相应码为399以上和399以下的百分比，和昨天同比", "output": "starttime=\"-10m\" appname:waf | stats count() as total, count(eval(waf.status>399)) as error | eval error_perc = error / total | eval line=\"当前\" | append [[ starttime=\"now-10m-1d\" endtime=\"now-1d\" appname:waf | stats count() as total, count(eval(waf.status>399)) as error| eval error_perc = error / total | eval line=\"同比昨天\" ]]", "category": "append", "level": 2, "now": 1666049645000,"start_ts":"-1000d", "fields": "waf日志:appname:waf 响应码:waf.status"}
{"input": "查询appname:nginx 2019-12-04日至2019-12-06日的结果并且将该时间范围统计出来的count数追加到每一行结果中", "output": "starttime=2019-12-04:00:00:00 endtime=2019-12-06:00:00:00 appname:nginx | eventstats count()", "category": "eventstats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx"}
{"input": "搜索所有数据并且按照数据logtype计算count值并且根据logtype给每行添加上count0字段", "output": "* | stats count() by logtype | eventstats count() as count0 by logtype", "category": "eventstats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计nginx状态码前十，并使用eventstats给每行添加上count值", "output": "appname:nginx | top 10 nginx.status | eventstats count()", "category": "eventstats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 状态码:nginx.status"}
{"input": "对logtype:apache数据，按照timestamp升序进行排序", "output": "logtype:apache | sort by +timestamp", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计今天appname数据量，按数据量从小到大排序", "output": "starttime=\"now/d\" * | stats count() as cnt by appname | sort by +cnt", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "今天每30分钟的字节数，并根据字节数大小升序", "output": "starttime=\"now/d\" endtime=\"now\" * | timechart span=30m sum(bytes) as total | sort by +total", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "昨天每30分钟的字节数，并根据字节数大小降序", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" * | timechart span=30m sum(bytes) as total |sort by total", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "获取上周中数据量最多的那一天", "output": "starttime=\"now-1w/w\" endtime=\"now/w\" * | timechart span=1d count() as cnt | sort by cnt | head 1 | eval day=formatdate(_time, \"yyyy-MM-dd\")", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计所有apache的状态码，对结果进行正序排序，并返回前10个结果", "output": "appname:apache|stats count() as cnt by apache.status |sort by +cnt | limit 10", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "统计所有apache的状态码，对结果进行按倒序排序，并返回前10个结果", "output": "appname:apache | stats count() as cnt by apache.status | sort by -cnt | head 10", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "查询apache日志，统计url出现次数最少的值的集合", "output": "appname:apache | stats count() as cnt by apache.request_path | sort by +cnt | limit 1", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache url:apache.request_path"}
{"input": "统计不同appname下，每个ip的数量，并按照ip的数量降序排序", "output": "* | stats count() as cnt by appname,ip |sort by -cnt", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查看linux一天cpu使用率最高时间点", "output": "starttime=\"now/d\" endtime=\"now\" appname:top_info_system_stats | sort by -json.cpu.user_percent | limit 1", "category": "sort", "level": 1, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats CPU使用率:json.cpu.user_percent"}
{"input": "统计nginx最大请求时间，取出前十", "output": "appname:nginx | sort by -nginx.req_time | limit 10", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 请求时间:nginx.req_time"}
{"input": "统计最近10分钟src_ip字段按照时间增序排序后的第一个值", "output": "starttime=\"-10m\" * | fields src_ip, timestamp | sort by +timestamp | limit 1", "category": "sort", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计最近10分钟src_ip字段按照时间增序排序后的最后一个值", "output": "starttime=\"-10m\" * | fields src_ip, timestamp | sort by -timestamp | limit 1", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计所有的appname和tag请根据下面的内容生成spl查询语句：请输出对应用的错误数统计并按5分钟一个点聚合 所属索引是[yotta] 错误关键字是[错误|失败|MAC校验错,fail|异常,NOT FOUND|bad request,中断|停止|注销|超时]", "output": "_index:yotta (错误 OR 失败 OR MAC校验错 OR fail OR 异常 OR \"NOT FOUND\" OR \"bad request\" OR 中断 OR 停止 OR 注销 OR 超时) | bucket timestamp span=5m as ts | stats count() as cnt by appname,tag,ts", "category": "bucket", "level": 1, "now": 1628133435000,"start_ts":"-10d", "fields": ""}
{"input": "统计最近一天每小时跨度内日志数量", "output": "starttime=\"-1d\" endtime=\"now\" * | bucket timestamp span=1h as ts | stats count() by ts", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计最近一天每小时跨度内各个主机的日志数量", "output": "starttime=\"now-1d\" endtime=\"now\" * | bucket timestamp span=1h as ts | stats count() by hostname, ts", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计最近一天每小时跨度内各个应用的日志数量", "output": "starttime=\"now-1d\" endtime=\"now\" * | bucket timestamp span=1h as ts | stats count() by appname,ts", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计今日linux事件每小时趋势", "output": "starttime=\"now/d\" endtime=\"now\" appname:linux | bucket timestamp span=1h as ts | stats count() by ts", "category": "bucket", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "以5分钟一个时间分桶，统计每个分桶内每个appname的日志条数", "output": "* |bucket timestamp span=5m as ts |stats count() by ts,appname", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-10d", "fields": ""}
{"input": "以5分钟一个时间分桶，以appname和tag为分组，统计每个分桶内每个appname和tag分组内的日志条数", "output": "* |bucket timestamp span=5m as ts|stats count() by ts,appname,tag", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-10d", "fields": ""}
{"input": "统计nginx访问状态码每进100的分段内，有多少次请求", "output": "appname:nginx | bucket nginx.status ranges=((0,100),(100,200),(200,399),(399,)) as rs | stats count() by rs", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 状态码:nginx.status"}
{"input": "统计tomcat系统的耗时区间，分为100-20、200-300、300-400、400-500", "output": "appname:tomcat | bucket tomcat.req_time ranges=((100,200),(200,300),(300,400),(400,500)) as rs | stats count() by rs", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "tomcat日志:appname:tomcat 耗时:tomcat.req_time"}
{"input": "统计日志条数count，按照1分钟分桶，110%做为upper，90%做为lower，列出ts，upper，lower，count", "output": "* | bucket timestamp span=1m as ts | stats count() as cnt by ts | eval upper=cnt*1.1 | eval lower=cnt*0.9 | table ts, upper, lower, cnt", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1d", "fields": ""}
{"input": "按照1分钟分桶统计日志条数cnt，upper=1.1cnt，lower=0.9cnt，列出ts，upper，lower，cnt", "output": "* | bucket timestamp span=1m as ts | stats count() as cnt by ts | eval upper=cnt*1.1 | eval lower=cnt*0.9 | table ts, upper, lower, cnt", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1d", "fields": ""}
{"input": "统计apache的状态码分布，并将状态码重命名为中文状态码", "output": "appname:apache | stats count() by apache.status | rename apache.status as \"状态码\"", "category": "rename", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "统计apache状态码并重命名为rizhiyi", "output": "appname:apache | stats count() by apache.status | rename apache.status as rizhiyi", "category": "rename", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "从日志中提取出满足正则表达式“[0-9]{12}\"的数据，并将数据的字段名称设置为test", "output": "* | parse \"(?<test>[0-9]{12})\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "本周产生事件的ip命名为事件ip", "output": "starttime=\"now/w\" * | rename ip as \"事件ip\"", "category": "rename", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计本周产生事件的ip重命名为事件ip", "output": "starttime=\"now/w\" * | stats count() by ip | rename ip as \"事件ip\"", "category": "rename", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "将appname:web的username字段重命名为“用户名”", "output": "appname:web | rename username as \"用户名\"", "category": "rename", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "web日志:appname:web"}
{"input": "统计appname为rizhiyi的ip，hostname，logtype字段只展示hostname，并改名为hn", "output": "appname:rizhiyi | stats count() by ip, hostname, logtype | table hostname | rename hostname as hn", "category": "rename", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "appname为test；分组统计hostname、appname两个字段的日志条数，将日志数量重命名为cnt1", "output": "appname:test | stats count() as cnt1 by hostname,appname", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "test日志:appname:test"}
{"input": "appnam为apache，耗时字段是cost_ms，单位是毫秒，统计平均耗时，统计完增加一个字段cost_s，等于平均耗时除以1000", "output": "appname:apache | stats avg(cost_ms) as avg_cost_ms | eval cost_s=avg_cost_ms/1000", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "应用apache，最近1天，将所有字段名的前缀去掉", "output": "starttime=\"-1d\" appname:apache | rename apache.* as *", "category": "rename", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "统计当前所有的appname和tag的日志条数，以appname和tag字段分组统计，将appname重命名为app，行列转换", "output": "appname:* tag:* | stats count() as cnt by appname,tag | rename appname as app | transpose row=app column=tag valuefield=cnt", "category": "transpose", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "日志:appname:"}
{"input": "按ip统计核心系统日志量ct将ip重名为主机，ct重命名为日志量条数", "output": "appname:core | stats count() as ct by ip | rename ct as \"日志量条数\", ip as \"主机\"", "category": "rename", "level": 1, "now": 1701941012000 ,"start_ts":"-1d", "fields": "核心系统日志:appname:core"}
{"input": "返回前三条数据", "output": "* | limit 3", "category": "limit", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计过去一周内，每个国家的访问量，取前3名。", "output": "starttime=\"-1w\" appname:apache | stats count() by apache.geo.country | limit 3", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "访问日志:appname:apache 国家:apache.geo.country"}
{"input": "列出最近一天数量最多的appname", "output": "starttime=\"now-1d\" * | stats count() by appname | limit 1", "category": "limit", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计防火墙攻击ip前十", "output": "appname:firewall | stats count() by firewall.src_ip | limit 10", "category": "limit", "level": 1, "now": 1677227381000,"start_ts":"-1000d", "fields": "防火墙日志:appname:firewall 攻击地址:firewall.src_ip"}
{"input": "请帮我统计所有的logtype前100的数量", "output": "* | stats count() by logtype | limit 100", "category": "limit", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "请帮我统计所有的logtype  top100的数量", "output": "* | top 100 logtype", "category": "top", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "绿盟IPS攻击源头top 20  统计", "output": "appname:ips tag:nsfocus | top 20 ips.src_ip", "category": "top", "level": 1, "now": 1697193754000,"start_ts":"-1000d", "fields": "绿盟IPS日志:appname:ips tag:nsfocus 来源地址:ips.src_ip"}
{"input": "appname:firewall 中统计firewall.dst.geo.ip字段TOP10", "output": "appname:firewall | top 10 firewall.dst.geo.ip", "category": "top", "level": 1, "now": 1677227381000,"start_ts":"-1000d", "fields": "firewall日志:appname:firewall"}
{"input": "appname:atrust，统计访问量排名前10的国家", "output": "appname:atrust | stats count() by atrust.geo.country | limit 10", "category": "limit", "level": 1, "now": 1688113396000,"start_ts":"-1000d", "fields": "atrust日志:appname:atrust 国家:atrust.geo.country"}
{"input": "以ip为分组统计日志数量，取前10", "output": "* | stats count() by ip | limit 10", "category": "limit", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "帮我统计apppname为1的日志中，最近一天value最大的值", "output": "appname:1 | stats max(value)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "日志:appname:"}
{"input": "统计waf拦截事件级别top10", "output": "appname:waf waf.action:block | top 10 waf.event_level", "category": "top", "level": 1, "now": 1666049645000,"start_ts":"-1000d", "fields": "waf日志:appname:waf 事件级别:waf.event_level 拦截操作:waf.action:block"}
{"input": "将json.time时间字段转换成Unix格式", "output": "* | eval json.time=parsedate(json.time, \"yyyy-MM-dd HH:mm:ss.SSSZ\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "将2023-11-15转换成时间戳", "output": "* | eval date=parsedate(\"2023-11-15\", \"yyyy-MM-dd\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "用parse从2023-11-16 09:29:39,057 INFO http-nio-8080-exec-1 这段日志中提取出日期时间，然后转换为时间戳，传给 bucket 命令统计时间趋势", "output": "* | parse \"(?<datetime>\\d{4}-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d,\\d{3}) \\w+ .*\" | eval datetime=parsedate(datetime, \"yyyy-MM-dd HH:mm:ss,SSS\") | bucket datetime span=1m as ts | stats count() by ts", "category": "parse", "level": 2, "now": 1701855000000,"start_ts":"-10d", "fields": ""}
{"input": "统计apache每小时事件数，以小时字段为join字段，关联统计midware每小时事件数", "output": "appname:apache | timechart span=1d count() | eval hour=formatdate(_time,\"HH\"), line=\"apache\" | join hour [[ appname:middleware | timechart span=1d count() | eval hour=formatdate(_time, \"HH\"), line=\"middleware\" ]]", "category": "join", "level": 2, "now": 1701855000000,"start_ts":"-10d", "fields": "apache日志:appname:apache middleware日志:appname:middleware"}
{"input": "请对appname为rizhiyi的raw_message字段做正则解析，如在“INFO [zookeeper connection] [BEAVER] Get urls from url pool”文本中获取到BEAVER的值赋给module字段", "output": "appname:rizhiyi | parse field=raw_message \"\\w+ \\[.*?\\] \\[(?<module>\\w+)\\] .*\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "rizhiyi日志:appname:rizhiyi"}
{"input": "查询2天前到1天前的apache日志", "output": "starttime=\"-2d\" endtime=\"-1d\" appname:apache ", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "计算当前时间的小时值", "output": "| makeresults | eval hour=formatdate(timestamp, \"HH\")", "category": "makeresults", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "计算今天是周几", "output": "| makeresults | eval today=formatdate(timestamp, \"e\")", "category": "makeresults", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计今天的siem_watchlist原始日志有多少Mb", "output": "starttime=\"now/d\" endtime=\"now\" appname:siem_watchlist |stats sum(raw_message_length) as size | eval size=format(\"%.2f MB\",size/1024/1024)", "category": "stats", "level": 1, "now": 1701956011000,"start_ts":"-1000d", "fields": "siem_watchlist日志:appname:siem_watchlist 原始日志长度:raw_message_length"}
{"input": "tomcat 错误码数量同环比上周同期", "output": "starttime=\"-10m\" appname:tomcat tomcat.status:>399 | stats count() | eval line=\"当前\" | append [[ starttime=\"now-10m-1w\" endtime=\"now-1w\" appname:tomcat tomcat.status:>399 | stats count() | eval line=\"上周同期\" ]]", "category": "append", "level": 2, "now": 1701847165000,"start_ts":"-1000d", "fields": "tomcat日志:appname:tomcat 状态码:tomcat.status"}
{"input": "统计青藤云登录失败日志中某个源IP最近5分钟对同一台主机登录多个账号失败，青藤云主机登录失败日志为：appname:qingteng logType:ssh result:failed，源IP字段为：src_ip，账号字段为：user", "output": "starttime=\"-5m\" appname:qingteng logType:ssh result:failed | stats dc(user) as user_dc by src_ip,ip | where user_dc>1", "category": "where", "level": 1, "now": 1701920615000,"start_ts":"-1d", "fields": ""}
{"input": "比较用户在周末和工作日的交易耗时", "output": "appname:trade | eval weekday=if(tolong(formatdate(timestamp, \"e\"))<5, \"work\", \"weekend\") | stats avg(trade.duration) by weekday", "category": "eval", "level": 1, "now": 1628133434431,"start_ts":"-1000d", "fields": "交易日志:appname:trade 耗时:trade.duration"}
{"input": "统计每天18点到19点的数据", "output": "* | eval hour=formatdate(timestamp, \"HH\"), day=formatdate(timestamp, \"dd\"), needed=if(hour==\"18\", 1, 0) | stats sum(needed) as needed_count by day", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计今天appname:waf的日志数，分桶为一小时，并且与昨天appname:waf的日志数，分桶为一小时做同环比", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" appname:waf |bucket timestamp span=1h as ts |stats count() by ts |eval hour=formatdate(ts,\"HH\") | eval line=\"昨天\" | join hour [[ starttime=\"now/d\" endtime=\"now\" appname:waf |bucket timestamp span=1h as ts |stats count() by ts |eval hour=formatdate(ts,\"HH\") | eval line=\"今天\" ]]", "category": "join", "level": 2, "now": 1666222445000,"start_ts":"-1000d", "fields": "waf日志:appname:waf"}
{"input": "统计过去一天每小时每个ip的事件数，并取出时间的小时值", "output": "starttime=\"now-1d\" endtime=\"now\" * | timechart span=1h count() by ip | eval hour=formatdate(_time,\"HH\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "把agent_send_timestamp字段格式化为yyyy-MM-dd HH:mm:ss的时间格式", "output": "* | eval time=formatdate(agent_send_timestamp, \"yyyy-MM-dd HH:mm:ss\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "把agent_send_timestamp字段格式化为年月日时分秒的时间格式", "output": "* | eval timestamp=formatdate(agent_send_timestamp, \"yyyy-MM-dd HH:mm:ss\")| fields timestamp", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "把collector_recv_timestamp字段格式化为可读的时间格式", "output": "* | eval timestamp=formatdate(collector_recv_timestamp, \"yyyy-MM-dd HH:mm:ss,SSS\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "计算apache日志时间的小时值", "output": "appname:apache | eval hour = formatdate(timestamp, \"HH\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "计算apache日志时间的小时", "output": "appname:apache | eval hour = formatdate(timestamp, \"HH\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "计算apache日志时间的小时分钟", "output": "appname:apache | eval hour=formatdate(timestamp, \"HH:mm\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "atrust日志中字段atrust.time原本是字符型的值，字符的格式是“MMM dd HH:mm:ss”，请转换成时间戳格式", "output": "appname:atrust atrust.time:* |eval atrust.time=parsedate(atrust.time,\"MMM dd HH:mm:ss\")", "category": "eval", "level": 1, "now": 1688113396000,"start_ts":"-10d", "fields": "atrust日志:appname:atrust"}
{"input": "atrust日志中以 atrust.traceId 为唯一 id进行事务串联，过滤事务耗时大于 0 秒的事务", "output": "appname:atrust atrust.traceId:* | transaction atrust.traceId | where _duration > 0", "category": "transaction", "level": 2, "now": 1688113396000,"start_ts":"-10d", "fields": "atrust日志:appname:atrust"}
{"input": "查询出apache日志的状态码大于200并且请求方式是GET，然后计算总的apache请求长度的50%分位值", "output": "apache.status:>200 AND apache.method:GET AND apache.resp_len:>0 | stats pct(apache.resp_len, 50)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status 请求方式:apache.method 请求长度:apache.resp_len"}
{"input": "查询出apache日志的状态码大于200并且请求方式是GET，然后对apache请求长度进行排序并返回apache请求长度在75%分位的值", "output": "appname:apache (apache.status:>200 AND apache.method:GET) | stats pct(apache.resp_len, 75)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache状态码:apache.status 请求方式:apache.method 请求长度:apache.resp_len"}
{"input": "统计后端响应时间的最大值", "output": "appname:nginx | stats max(nginx.upstream_resp_time)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "反向代理日志:appname:nginx 后端响应时间:nginx.upstream_resp_time"}
{"input": "统计后端响应时间的方差", "output": "appname:nginx | stats var(nginx.upstream_resp_time)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "反向代理日志:appname:nginx 后端响应时间:nginx.upstream_resp_time"}
{"input": "统计后端响应时间的第 95 百分位数", "output": "appname:nginx | stats pct(nginx.upstream_resp_time, 95)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "反向代理日志:appname:nginx 后端响应时间:nginx.upstream_resp_time"}
{"input": "统计后端响应时间的第 99 百分位数", "output": "appname:nginx | stats pct(nginx.upstream_resp_time, 99)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "反向代理日志:appname:nginx 后端响应时间:nginx.upstream_resp_time"}
{"input": "统计后端响应时间的第 99.9 百分位数", "output": "appname:nginx | stats pct(nginx.upstream_resp_time, 99.9)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "反向代理日志:appname:nginx 后端响应时间:nginx.upstream_resp_time"}
{"input": "写一个spl，统计今天mbank系统最大tps", "output": "starttime=\"now/d\" endtime=\"now\" appname:mbank | timechart span=1s count() as tps | stats max(tps)", "category": "stats", "level": 1, "now": 1701920614000,"start_ts":"-1000d", "fields": "mbank日志:appname:mbank"}
{"input": "写一个spl，统计今天mbank系统最大tps对应的时间点是几时几分几秒", "output": "starttime=\"now/d\" endtime=\"now\" appname:mbank | timechart span=1s count() as tps | sort by tps | eval time=formatdate(_time, \"HH:mm:ss\") | limit 1", "category": "sort", "level": 2, "now": 1701920614000,"start_ts":"-1000d", "fields": "mbank日志:appname:mbank"}
{"input": "统计过去30天内，每小时的请求响应时间的平均值和最大值。按平均值倒序，耗时保留小数点后 2 位，时间戳展示天和小时", "output": "starttime=\"-30d\" endtime=\"now\" appname:apache | bucket timestamp span=1h as ts | stats avg(apache.req_time) as avg_, max(apache.req_time) as max_ by ts | sort by avg_ | eval avg_=format(\"%.2f\", avg_), max_=format(\"%.2f\", max_), ts=formatdate(ts, \"dd/HH\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache"}
{"input": "在tdx日志中，将相同id下的action是结束的日志时间减去action是开始的日志时间，得出resp_time字段", "output": "appname:tdx tdx.action:开始 | stats first(timestamp) as begin by tdx.id | join type=left tdx.id [[ appname:tdx tdx.action:结束 | stats last(timestamp) as end by tdx.id ]] | eval resp_time=tolong(end) - tolong(begin)", "category": "join", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "tdx日志:appname:tdx ID:tdx.id action:tdx.action"}
{"input": "对比昨天和前天的error日志数量，并计算两天的百分比和差值", "output": "starttime=\"now-2d/d\" endtime=\"now-1d/d\" error | stats count() as '前天' | appendcols [[ starttime=\"now-1d/d\" endtime=\"now/d\" error | stats count() as '昨天' ]] | eval diff='昨天'-'前天', perc=format(\"%.2f%%\", 100*'昨天'/'前天')", "category": "appendcols", "level": 2, "now": 1701963811000,"start_ts":"-1000d", "fields": ""}
{"input": "统计esb系统今天和昨天每小时交易量对比spl语句", "output": "starttime=\"now-1d/d\" endtime=\"now/d\" appname:esb | timechart span=1h count() | eval hour=formatdate(_time, \"HH\") | eval line=\"昨天\" | join hour [[ starttime=\"now/d\" endtime=\"now\" appname:esb | timechart span=1h count() | eval hour=formatdate(_time, \"HH\") | eval line=\"今天\" ]]", "category": "join", "level": 2, "now": 1701963811000,"start_ts":"-10d", "fields": "esb日志:appname:esb"}
{"input": "寻找今天所有包含“error”的日志，并计算出它们的总数以及相比昨天的变化情况。", "output": "starttime=\"now/d\" error | stats count() as today | appendcols [[ starttime=\"now-1d/d\" endtime=\"now-1d\" error | stats count() as yestoday ]] | eval change=today/yestoday", "category": "stats", "level": 1, "now": 1701963811000,"start_ts":"-1000d", "fields": ""}
{"input": "搜索出appache日志中城市为苏州的日志，并按照访问路径request_path分组，对每个组求出访问的不同client个数，并限制数量在10到100范围", "output": "appname:apache tag:access apache.geo.city:苏州市 | stats dc(apache.clientip) as _dc by apache.request_path | where _dc>10 && _dc<100", "category": "where", "level": 1, "now": 1701847165000,"start_ts":"-100d", "fields": "apache日志:appname:apache 城市:apache.geo.city 访问路径:apache.request_path 访问来源:apache.clientip"}
{"input": "查询日志量大小按天分桶单位是GB", "output": "* | timechart span=1d sum(raw_message_length) as total | eval GB=format(\"%.2f GB\",total/1024/1024/1024)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-300d", "fields": "原始日志长度:raw_message_length"}
{"input": "统计平台里面，有多少个IP，每个IP有多少条日志，每个IP有多少G数据量", "output": "* | stats count() as cnt, sum(raw_message_length) as total by ip | eval total=format(\"%.2f GB\",total/1024/1024/1024) | eventstats count() as ip_cnt", "category": "eventstats", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "对已经接收到的日志数据，按appname分类统计，各个appname产生了多少日志量，日志量换算成GB单位", "output": "* | stats sum(raw_message_length) as total by appname | eval GB=format(\"%.2f GB\",total/1024/1024/1024)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "对已经接收到的日志数据，按IP统计，各IP产生了多少G日志数量", "output": "* | stats sum(raw_message_length) as total by ip | eval GB=format(\"%.2f GB\",total/1024/1024/1024)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查询waf日志中，统计今日高危事件数与昨日高危事件数同比增长率", "output": "starttime=\"now/d\" endtime=\"now\" appname:waf waf.event_level:high | stats count() as today | appendcols [[ starttime=\"now-1d/d\" endtime=\"now-1d\" appname:waf waf.event_level:high | stats count() as yestoday ]] | eval perc=format(\"%.2f%%\", 100*(today-yestoday)/yestoday)", "category": "appendcols", "level": 2, "now": 1666049646000,"start_ts":"-1000d", "fields": "waf日志:appname:waf 事件级别:waf.event_level"}
{"input": "查询waf日志中，统计最近5分钟高危事件数与5分钟到10分钟前高危事件数环比增长率", "output": "starttime=\"-5m\" endtime=\"now\" appname:waf waf.event_level:high | stats count() as new_cnt | appendcols [[starttime=\"-10m\" endtime=\"-5m\" appname:waf waf.event_level:high | stats count() as cnt ]] | eval rate=format(\"%.2f%%\",(new_cnt-cnt)/cnt*100)", "category": "appendcols", "level": 2, "now": 1666049645000,"start_ts":"-1000d", "fields": "waf日志:appname:waf 事件级别:waf.event_level"}
{"input": "统计过去一天每个小时每个ip事件数占当前这个小时总数的百分比", "output": "starttime=\"-1d\" endtime=\"now\" * | bucket timestamp span=1h as ts | stats count() as ip_cnt by ts,ip | eventstats sum(ip_cnt) as hour_cnt by ts | eval per=format(\"%.2f%%\",ip_cnt/hour_cnt*100)", "category": "eventstats", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计主机磁盘繁忙率(百分比)", "output": "appname:top_info_disk_stats | stats max(json.disk.used_percent) as perc by hostname | eval perc=format(\"%.2f%%\", perc)", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "top_info_disk_stats日志:appname:top_info_disk_stats 磁盘使用率:json.disk.used_percent"}
{"input": "查询微服务网关nginx的按耗时平均分成10分后按耗时值进行分组统计各耗时段内的请求次数？", "output": "appname:nginx | chart count() by nginx.req_time bins=10", "category": "chart", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 耗时:nginx.req_time"}
{"input": "将 username 和 action 字段作为 X 和 Y 轴，绘制热力图", "output": "* | chart rendertype=\"heatmap\" count(action) by username", "category": "chart", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查询今日nginx每分钟访问失败数量，并绘画曲线图", "output": "starttime=\"now/d\" endtime=\"now\" appname:nginx nginx.status:>399 | timechart rendertype=\"line\" span=1m count()", "category": "timechart", "level": 2, "now": 1701855000000,"start_ts":"-1d", "fields": "nginx日志:appname:nginx 状态码:nginx.status"}
{"input": "创建柱状图显示不同事件类型的数量", "output": "* | chart rendertype=\"bar\" count() by event_type", "category": "chart", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "事件类型:event_type"}
{"input": "分析防火墙源地址和目的地址的桑基图", "output": "appname:firewall | chart rendertype=\"sankey\" count() over firewall.src_ip by firewall.dst_ip", "category": "chart", "level": 2, "now": 1677227381000,"start_ts":"-1000d", "fields": "防火墙日志:appname:firewall 来源地址:firewall.src_ip 目的地址:firewall.dst_ip"}
{"input": "统计访问量最高的前五个网站，并将结果以柱状图的形式展示出来。", "output": "appname:apache | chart rendertype=\"bar\" limit=5 count() by apache.domain", "category": "chart", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 网站域名:apache.domain"}
{"input": "通过对用户的来源ip等数据进行分析，可以生成饼图或直方图", "output": "* | chart rendertype=\"pie\" count() by src_ip", "category": "chart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "来源IP:src_ip"}
{"input": "统计今天的siem_watchlist原始日志有多少M", "output": "starttime=\"now/d\" endtime=\"now\" appname:siem_watchlist | stats sum(raw_message_length) as total | eval total=format(\"%.2f MB\", total/1024/1024)", "category": "eval", "level": 1, "now": 1701956011000,"start_ts":"-1000d", "fields": "siem_watchlist日志:appname:siem_watchlist 原始日志长度:raw_message_length"}
{"input": "统计访问日志中响应码在200到300范围内的日志", "output": "appname:apache apache.status:[200 TO 300]", "category": "query", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 状态码:apache.status"}
{"input": "提取source字段的一级目录生成新字段test", "output": "source:* | parse field=source \"^/(?<test>[^/]*?)/\"", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "从日志原文中抽取ip地址，得到新字段ip_addr，并按照ip_addr分组计算appname的个数", "output": "appname:* | parse \"(?<ip_addr>(?:\\d{1,3}\\.){3}\\d{1,3})\" | stats dc(appname) by ip_addr", "category": "parse", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "日志:appname:"}
{"input": "统计appname:esb事件数除以appname:esb 和appname:ITM事件数总和", "output": "appname:esb | stats count() as esb_cnt | appendcols [[ appname:ITM | stats count() as itm_cnt ]] | eval ret = esb_cnt / (esb_cnt + itm_cnt)", "category": "appendcols", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "nginx.status为200则成功，否则为失败", "output": "nginx.status:* | eval status = if(nginx.status == 200, \"成功\", \"失败\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "查询nginx.status，如果为200标注成功，否则标注失败", "output": "nginx.status:* | eval status = if(nginx.status == 200, \"成功\", \"失败\")", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "结合eval命令，如何判断dst_ip是否在192.168.1.1/24网段中", "output": "* | eval ret=cidrmatch(\"192.168.1.1/24\", dst_ip)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "计算今天ip为192.168.40.102和ip为192.168.40.106日志条数的差值", "output": "starttime=\"now/d\" endtime=\"now\" ip:\"192.168.40.102\" | stats count() as cnt1 | appendcols [[ starttime=\"now/d\" endtime=\"now\" ip:\"192.168.40.106\" | stats count() as cnt2 ]] | eval diff=cnt1-cnt2", "category": "appendcols", "level": 2, "now": 1701920613000,"start_ts":"-1000d", "fields": ""}
{"input": "用autoregress计算今天ip为192.168.40.102和ip为192.168.40.106日志条数的差值", "output": "starttime=\"now/d\" endtime=\"now\" (ip:\"192.168.40.102\" OR ip:\"192.168.40.106\" ) | stats count() as cnt by ip | autoregress cnt as cnt1 p=1 | eval diff=cnt1-cnt", "category": "autoregress", "level": 2, "now": 1701920613000,"start_ts":"-1000d", "fields": ""}
{"input": "帮我判断appname为test日志中value值的是否为空，如果为空赋值100，不为空就展示原本值", "output": "appname:test value:* |eval value=if(empty(value),100,value)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "test日志:appname:test"}
{"input": "使用spl的case函数判断status状态，如果状态为on赋值为1 如果状态为off赋值为2 如果状态为其他赋值为3", "output": "status:* | eval status=case(status==\"on\", 1, status==\"off\", 2, default, 3)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "使用case函数，判断request.status等于200返回OK，等于404返回NO，等于301返回YES，等于其他的返回NULL", "output": "request.status:* | eval request.status=case(request.status ==200, \"OK\", request.status==404, \"NO\", request.status==301, \"YES\", default, NULL)", "category": "eval", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "返回出现次数最少的 srcip，并且在五次以下，并输出 srcip_cnt 字段作为 count 值，并按照 srcip_cnt 排序", "output": "* | stats count() as srcip_cnt by srcip | where srcip_cnt<5 | sort by +srcip_cnt", "category": "where", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "返回出现次数最少的 srcip，并且在五次以下，并输出 srcip_cnt 字段作为 count 值，并按照 srcip_cnt 排序，并计算出现次数占总次数的百分比", "output": "* | stats count() as srcip_cnt by srcip | sort by +srcip_cnt | eventstats sum(srcip_cnt) as total | eval perc=format(\"%.2f%%\", srcip_cnt/total*100) | where srcip_cnt<5", "category": "eventstats", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "返回出现次数最少的 srcip，并且在五次以下，并输出 srcip_cnt 字段作为 count 值，并按照 srcip_cnt 排序，并计算出现次数占总次数的百分比，并限制结果数量为 10，并显示每个 srcip 的详细信息", "output": "* | stats count() as srcip_cnt by srcip | sort by +srcip_cnt | eventstats sum(srcip_cnt) as total | eval perc=format(\"%.2f%%\", srcip_cnt/total*100) | where srcip_cnt<5 | limit 10", "category": "eventstats", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "我想统计过去一周的事件数量，按每天计算。", "output": "starttime=\"now-1w\" * | timechart span=1d count()", "category": "timechart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "我需要过去24小时内，每小时的页面浏览次数。", "output": "starttime=\"now-24h\" appname:apache apache.request_path:*.html | timechart span=1h count()", "category": "timechart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "访问日志:appname:apache 请求路径:apache.request_path"}
{"input": "我想知道过去一年每个月的独立访客数。", "output": "starttime=\"now-1y\" appname:apache | timechart span=30d dc(apache.clientip)", "category": "timechart", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 访问来源:apache.clientip"}
{"input": "用bucket分析从6月3号到6月7号的每日数据量", "output": "* | bucket timestamp timeranges=((2023-06-03, 2023-06-04), (2023-06-04, 2023-06-05), (2023-06-06, 2023-06-07)) as tr |stats count() by tr", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "我想了解6 月 8 号和 10 号两天的上午 9 点半到下午 3 点半的网站访问量。", "output": "appname:apache |bucket timestamp timeranges=((2023-06-08:09:30:00, 2023-06-08:15:30:00), (2023-06-10:09:30:00, 2023-06-10:15:30:00)) as tr |stats count() by tr", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "访问日志:appname:apache"}
{"input": "请将orderAmount订单金额，分为不同的价格区间并统计每个区间的订单数。区间为0-50, 50-100, 100-150。", "output": "* |bucket orderAmount ranges=((0, 50), (50, 100), (100, 150)) as rs |stats count() by rs", "category": "bucket", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "请生成每分钟的交易量直方图，覆盖今天全天。", "output": "starttime=\"now-1d/d\" endtime=\"now+1d/d\" appname:trade | timechart rendertype=\"column\" span=1m count()", "category": "timechart", "level": 2, "now": 1628133434431,"start_ts":"-1d", "fields": "trade日志:appname:trade"}
{"input": "我想看看内存使用量的分布，每256MB作为一个区间。", "output": "appname:top_info_system_stats | eval mem_used_mb = tolong(json.Mem.used/1024/1024) | bucket mem_used_mb span=256 as vs |stats count() by vs", "category": "bucket", "level": 2, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats 内存使用量:json.Mem.used"}
{"input": "请展示过去一天内，每100MB的网络出口流量分布情况。", "output": "appname:top_info_system_stats | eval net_out_mb = tolong(json.net.bytes_sent/1024/1024) | bucket net_out_mb span=100 as vs |stats count() as ct by vs", "category": "bucket", "level": 2, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats 网络出口流量:json.net.bytes_sent"}
{"input": "我想要在过去一周内，按天统计每个服务器的平均CPU使用率，只显示前5个服务器。", "output": "starttime=\"now-1w\" appname:top_info_system_stats | timechart limit=5 span=1d avg(json.cpu.user_percent) by ip", "category": "timechart", "level": 2, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats CPU使用率:json.cpu.user_percent"}
{"input": "请展示过去24小时，每小时网络流量的最大值，仅针对主要的3台主机。", "output": "starttime=\"-24h\" appname:top_info_system_stats | eval net_bytes=json.net.bytes_sent+json.net.bytes_recv | timechart limit=3 span=1h max(net_bytes) by hostname", "category": "timechart", "level": 2, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats 网络出口流量:json.net.bytes_sent 网络入口流量:json.net.bytes_recv"}
{"input": "我想要看到服务器CPU使用率的累积百分比分布条形图，坐标轴分别在50%, 75%, 90%的百分比点。", "output": "appname:top_info_system_stats | stats pct(json.cpu.user_percent, 50, 75, 90) as p | unpivot | chart rendertype=\"bar\" first('row 1') as value by column", "category": "unpivot", "level": 3, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats CPU使用率:json.cpu.user_percent"}
{"input": "展示不同主机磁盘I/O操作的累积百分比，关注的百分比点为20%, 40%, 60%, 80%。", "output": "appname:top_info_disk_io_stats | eval diskio=json.io_stat.w_s+json.io_stat.r_s | stats pct(diskio, 20, 40, 60, 80) by hostname | unpivot header_field=hostname", "category": "unpivot", "level": 3, "now": 1701855000000,"start_ts":"-1000d", "fields": "top_info_disk_io_stats日志:appname:top_info_disk_io_stats 磁盘读操作数:json.io_stat.r_s 磁盘写操作数:json.io_stat.w_s"}
{"input": "我想看看我们的用户在不同国家、省份和城市的分布情况。", "output": "appname:apache | stats count() by apache.geo.country, apache.geo.province, apache.geo.city", "category": "stats", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache 国家:apache.geo.country 省份:apache.geo.province 城市:apache.geo.city"}
{"input": "统计网络攻击的来源地，需要按照国家、省份和城市来划分。", "output": "tag:attack | stats count() by src.geo.country, src.geo.province, src.geo.city", "categorystats": "", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": "统计日志:tag:attack 国家:geo.country 省份:geo.province 城市:geo.city"}
{"input": "我需要了解apache访问日志中不同ISP请求的地理分布，按经纬度出图。", "output": "appname:apache | geostats latfield=apache.geo.latitude longfield=apache.geo.longitude count() by apache.geo.isp", "category": "geostats", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": "apache日志:appname:apache ISP:apache.geo.isp 经度:apache.geo.longitude 纬度:apache.geo.latitude"}
{"input": "我想知道服务器CPU使用率的90%百分位是多少。", "output": "appname:top_info_system_stats | stats pct_ranks(json.cpu.user_percent, 90)", "category": "stats", "level": 1, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats CPU使用率:json.cpu.user_percent"}
{"input": "我需要了解内存使用量达到顶部5%的阈值是多少。", "output": "appname:top_info_system_stats | stats pct_ranks(json.Mem.used, 95)", "category": "stats", "level": 1, "now": 1701791782000,"start_ts":"-1000d", "fields": "top_info_system_stats日志:appname:top_info_system_stats 内存使用量:json.Mem.used"}
{"input": "使用dedup函数，对linux.src_ip进行去重并返回前三个linux.src_ip", "output": "appname:linux | dedup 1 linux.src_ip |limit 3", "category": "dedup", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux"}
{"input": "数据库连接名称为mysqltest，sql语句select count(*) from Account", "output": "| dbxquery connection=\"mysqltest\" query=\"select count(*) from Account\"", "category": "dbx", "level": 1, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "已知道VPN查询语句为：appname:vpn、源IP字段为vpn.src_ip，防火墙查询语句为：appname:firewall、源IP字段为firewall.src_ip，帮忙用join命令统计下VPN是否与防火墙有相同源IP", "output":"appname:vpn | stats count() by vpn.src_ip | rename vpn.src_ip as src_ip | join type=inner src_ip [[ appname:firewall | stats count() by firewall.src_ip | rename firewall.src_ip as src_ip ]]", "category": "join", "level": 1, "now": 1677227381000,"start_ts":"-1000d", "fields": "vpn日志:appname:vpn"}
{"input": "请帮我统计linux日志中前十的登录用户", "output": "appname:linux | stats count() by linux.user | limit 10", "category": "limit", "level": 1, "now": 1701860622530,"start_ts":"-1000d", "fields": "linux日志:appname:linux 登录用户:linux.user"}
{"input": "查询VPN用户登录日志中，10分钟内连续登录次数大于等于3次的用户信息", "output": "starttime=\"-10m\" appname:vpn | stats count() as cnt by vpn.login_user | where cnt > 3", "category": "where", "level": 1, "now": 1656577396000,"start_ts":"-1000d", "fields": "vpn日志:appname:vpn 登录用户:vpn.login_user"}
{"input": "让ips.level显示低中高，用spl语句怎么写", "output": "ips.level:* | eval ips.level = case(ips.level==\"低风险\", \"低\", ips.level==\"中风险\", \"中\", ips.level==\"高风险\", \"高\")", "category": "eval", "level": 2, "now": 1701855000000,"start_ts":"-1000d", "fields": ""}
{"input": "统计今天appname数据量，只保留appname:xx和appname:yy的内容", "output": "starttime=\"now/d\" (appname:xx OR appname:yy) | stats count() by appname", "category": "stats", "level": 1, "now": 1701398612000,"start_ts":"-1000d", "fields": "xx日志:appname:xx"}
{"input": "nginx日志，统计最近1小时平均访问时长", "output": "starttime=\"-1h\" appname:nginx | stats avg(nginx.req_time)", "category": "stats", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 访问时长:nginx.req_time"}
{"input": "nginx日志，统计最近1小时最大访问时长", "output": "starttime=\"-1h\" appname:nginx | stats max(nginx.req_time)", "category": "stats", "level": 1, "now": 1701847165000,"start_ts":"-1000d", "fields": "nginx日志:appname:nginx 访问时长:nginx.req_time"}
{"input": "统计apache日志趋势，按apache.status字段做分组，15分钟一个间隔", "output": "appname:apache |bucket timestamp span=15m as ts |stats count() by apache.status,ts", "category": "bucket", "level": 1, "now": 1701731427000,"start_ts":"-10d", "fields": "apache日志:appname:apache"}
